{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.1337868480725624,
  "eval_steps": 500,
  "global_step": 5500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01030715316429602,
      "grad_norm": 2.0828049182891846,
      "learning_rate": 4.8e-05,
      "loss": 2.8848,
      "step": 50
    },
    {
      "epoch": 0.02061430632859204,
      "grad_norm": 2.6984825134277344,
      "learning_rate": 9.800000000000001e-05,
      "loss": 1.3316,
      "step": 100
    },
    {
      "epoch": 0.030921459492888066,
      "grad_norm": 1.9541840553283691,
      "learning_rate": 0.000148,
      "loss": 1.0077,
      "step": 150
    },
    {
      "epoch": 0.04122861265718408,
      "grad_norm": 1.5692940950393677,
      "learning_rate": 0.00019800000000000002,
      "loss": 0.6735,
      "step": 200
    },
    {
      "epoch": 0.05153576582148011,
      "grad_norm": 1.4348764419555664,
      "learning_rate": 0.000248,
      "loss": 0.5096,
      "step": 250
    },
    {
      "epoch": 0.06184291898577613,
      "grad_norm": 1.47340726852417,
      "learning_rate": 0.000298,
      "loss": 0.5195,
      "step": 300
    },
    {
      "epoch": 0.07215007215007214,
      "grad_norm": 1.5993212461471558,
      "learning_rate": 0.000348,
      "loss": 0.4814,
      "step": 350
    },
    {
      "epoch": 0.08245722531436817,
      "grad_norm": 1.0021660327911377,
      "learning_rate": 0.000398,
      "loss": 0.4317,
      "step": 400
    },
    {
      "epoch": 0.09276437847866419,
      "grad_norm": 1.177679419517517,
      "learning_rate": 0.000448,
      "loss": 0.4856,
      "step": 450
    },
    {
      "epoch": 0.10307153164296022,
      "grad_norm": 1.3836790323257446,
      "learning_rate": 0.000498,
      "loss": 0.4428,
      "step": 500
    },
    {
      "epoch": 0.11337868480725624,
      "grad_norm": 1.7914283275604248,
      "learning_rate": 0.0004956363636363637,
      "loss": 0.479,
      "step": 550
    },
    {
      "epoch": 0.12368583797155226,
      "grad_norm": 1.5237536430358887,
      "learning_rate": 0.0004910909090909091,
      "loss": 0.4573,
      "step": 600
    },
    {
      "epoch": 0.13399299113584828,
      "grad_norm": 1.1237435340881348,
      "learning_rate": 0.00048654545454545456,
      "loss": 0.404,
      "step": 650
    },
    {
      "epoch": 0.1443001443001443,
      "grad_norm": 1.0885850191116333,
      "learning_rate": 0.000482,
      "loss": 0.4291,
      "step": 700
    },
    {
      "epoch": 0.15460729746444032,
      "grad_norm": 1.144952416419983,
      "learning_rate": 0.00047745454545454545,
      "loss": 0.4311,
      "step": 750
    },
    {
      "epoch": 0.16491445062873633,
      "grad_norm": 0.9737036228179932,
      "learning_rate": 0.0004729090909090909,
      "loss": 0.4528,
      "step": 800
    },
    {
      "epoch": 0.17522160379303237,
      "grad_norm": 1.922758936882019,
      "learning_rate": 0.0004683636363636364,
      "loss": 0.4259,
      "step": 850
    },
    {
      "epoch": 0.18552875695732837,
      "grad_norm": 1.3870055675506592,
      "learning_rate": 0.00046381818181818183,
      "loss": 0.4416,
      "step": 900
    },
    {
      "epoch": 0.1958359101216244,
      "grad_norm": 1.6452114582061768,
      "learning_rate": 0.0004592727272727273,
      "loss": 0.4063,
      "step": 950
    },
    {
      "epoch": 0.20614306328592044,
      "grad_norm": 0.937842845916748,
      "learning_rate": 0.0004547272727272727,
      "loss": 0.4161,
      "step": 1000
    },
    {
      "epoch": 0.21645021645021645,
      "grad_norm": 1.2152420282363892,
      "learning_rate": 0.0004501818181818182,
      "loss": 0.4324,
      "step": 1050
    },
    {
      "epoch": 0.22675736961451248,
      "grad_norm": 2.061384439468384,
      "learning_rate": 0.00044563636363636366,
      "loss": 0.4445,
      "step": 1100
    },
    {
      "epoch": 0.2370645227788085,
      "grad_norm": 1.3671696186065674,
      "learning_rate": 0.0004410909090909091,
      "loss": 0.4346,
      "step": 1150
    },
    {
      "epoch": 0.24737167594310452,
      "grad_norm": 1.0603969097137451,
      "learning_rate": 0.0004365454545454546,
      "loss": 0.4287,
      "step": 1200
    },
    {
      "epoch": 0.25767882910740053,
      "grad_norm": 1.1273633241653442,
      "learning_rate": 0.000432,
      "loss": 0.3855,
      "step": 1250
    },
    {
      "epoch": 0.26798598227169657,
      "grad_norm": 1.1242297887802124,
      "learning_rate": 0.0004274545454545455,
      "loss": 0.3784,
      "step": 1300
    },
    {
      "epoch": 0.2782931354359926,
      "grad_norm": 1.3314319849014282,
      "learning_rate": 0.0004229090909090909,
      "loss": 0.3733,
      "step": 1350
    },
    {
      "epoch": 0.2886002886002886,
      "grad_norm": 1.050687313079834,
      "learning_rate": 0.00041836363636363637,
      "loss": 0.3787,
      "step": 1400
    },
    {
      "epoch": 0.2989074417645846,
      "grad_norm": 1.2502217292785645,
      "learning_rate": 0.0004138181818181818,
      "loss": 0.3767,
      "step": 1450
    },
    {
      "epoch": 0.30921459492888065,
      "grad_norm": 1.386946678161621,
      "learning_rate": 0.0004092727272727273,
      "loss": 0.3821,
      "step": 1500
    },
    {
      "epoch": 0.3195217480931767,
      "grad_norm": 1.0658541917800903,
      "learning_rate": 0.00040472727272727275,
      "loss": 0.3799,
      "step": 1550
    },
    {
      "epoch": 0.32982890125747266,
      "grad_norm": 1.5130937099456787,
      "learning_rate": 0.0004001818181818182,
      "loss": 0.3896,
      "step": 1600
    },
    {
      "epoch": 0.3401360544217687,
      "grad_norm": 1.2951409816741943,
      "learning_rate": 0.00039563636363636363,
      "loss": 0.358,
      "step": 1650
    },
    {
      "epoch": 0.35044320758606473,
      "grad_norm": 1.149279236793518,
      "learning_rate": 0.00039109090909090913,
      "loss": 0.3888,
      "step": 1700
    },
    {
      "epoch": 0.36075036075036077,
      "grad_norm": 1.0152249336242676,
      "learning_rate": 0.0003865454545454545,
      "loss": 0.3675,
      "step": 1750
    },
    {
      "epoch": 0.37105751391465674,
      "grad_norm": 2.027949094772339,
      "learning_rate": 0.000382,
      "loss": 0.3895,
      "step": 1800
    },
    {
      "epoch": 0.3813646670789528,
      "grad_norm": 1.7667394876480103,
      "learning_rate": 0.00037745454545454546,
      "loss": 0.3657,
      "step": 1850
    },
    {
      "epoch": 0.3916718202432488,
      "grad_norm": 1.3091682195663452,
      "learning_rate": 0.0003729090909090909,
      "loss": 0.3685,
      "step": 1900
    },
    {
      "epoch": 0.40197897340754485,
      "grad_norm": 1.9059885740280151,
      "learning_rate": 0.00036836363636363634,
      "loss": 0.3482,
      "step": 1950
    },
    {
      "epoch": 0.4122861265718409,
      "grad_norm": 1.3428462743759155,
      "learning_rate": 0.00036381818181818184,
      "loss": 0.3621,
      "step": 2000
    },
    {
      "epoch": 0.42259327973613686,
      "grad_norm": 0.9777273535728455,
      "learning_rate": 0.0003592727272727273,
      "loss": 0.3554,
      "step": 2050
    },
    {
      "epoch": 0.4329004329004329,
      "grad_norm": 1.6832828521728516,
      "learning_rate": 0.0003547272727272727,
      "loss": 0.3369,
      "step": 2100
    },
    {
      "epoch": 0.44320758606472893,
      "grad_norm": 0.8535405397415161,
      "learning_rate": 0.0003501818181818182,
      "loss": 0.3475,
      "step": 2150
    },
    {
      "epoch": 0.45351473922902497,
      "grad_norm": 1.232762336730957,
      "learning_rate": 0.00034563636363636366,
      "loss": 0.336,
      "step": 2200
    },
    {
      "epoch": 0.46382189239332094,
      "grad_norm": 1.4716391563415527,
      "learning_rate": 0.0003410909090909091,
      "loss": 0.3408,
      "step": 2250
    },
    {
      "epoch": 0.474129045557617,
      "grad_norm": 1.7491559982299805,
      "learning_rate": 0.00033654545454545455,
      "loss": 0.3428,
      "step": 2300
    },
    {
      "epoch": 0.484436198721913,
      "grad_norm": 1.4655380249023438,
      "learning_rate": 0.00033200000000000005,
      "loss": 0.3382,
      "step": 2350
    },
    {
      "epoch": 0.49474335188620905,
      "grad_norm": 1.8550478219985962,
      "learning_rate": 0.00032745454545454544,
      "loss": 0.3379,
      "step": 2400
    },
    {
      "epoch": 0.5050505050505051,
      "grad_norm": 1.285152554512024,
      "learning_rate": 0.00032290909090909093,
      "loss": 0.3309,
      "step": 2450
    },
    {
      "epoch": 0.5153576582148011,
      "grad_norm": 1.3149021863937378,
      "learning_rate": 0.0003183636363636364,
      "loss": 0.3007,
      "step": 2500
    },
    {
      "epoch": 0.525664811379097,
      "grad_norm": 1.3000088930130005,
      "learning_rate": 0.0003138181818181818,
      "loss": 0.3511,
      "step": 2550
    },
    {
      "epoch": 0.5359719645433931,
      "grad_norm": 1.1672391891479492,
      "learning_rate": 0.00030927272727272726,
      "loss": 0.3137,
      "step": 2600
    },
    {
      "epoch": 0.5462791177076891,
      "grad_norm": 1.446348786354065,
      "learning_rate": 0.00030472727272727276,
      "loss": 0.3486,
      "step": 2650
    },
    {
      "epoch": 0.5565862708719852,
      "grad_norm": 1.2033271789550781,
      "learning_rate": 0.00030018181818181815,
      "loss": 0.3182,
      "step": 2700
    },
    {
      "epoch": 0.5668934240362812,
      "grad_norm": 1.6455484628677368,
      "learning_rate": 0.00029563636363636364,
      "loss": 0.303,
      "step": 2750
    },
    {
      "epoch": 0.5772005772005772,
      "grad_norm": 1.1507468223571777,
      "learning_rate": 0.0002910909090909091,
      "loss": 0.2931,
      "step": 2800
    },
    {
      "epoch": 0.5875077303648732,
      "grad_norm": 0.766877293586731,
      "learning_rate": 0.00028654545454545453,
      "loss": 0.3336,
      "step": 2850
    },
    {
      "epoch": 0.5978148835291692,
      "grad_norm": 1.2564352750778198,
      "learning_rate": 0.00028199999999999997,
      "loss": 0.3131,
      "step": 2900
    },
    {
      "epoch": 0.6081220366934653,
      "grad_norm": 1.7314453125,
      "learning_rate": 0.00027745454545454547,
      "loss": 0.3242,
      "step": 2950
    },
    {
      "epoch": 0.6184291898577613,
      "grad_norm": 0.7546097636222839,
      "learning_rate": 0.00027290909090909096,
      "loss": 0.3302,
      "step": 3000
    },
    {
      "epoch": 0.6287363430220573,
      "grad_norm": 2.1374335289001465,
      "learning_rate": 0.00026836363636363635,
      "loss": 0.3326,
      "step": 3050
    },
    {
      "epoch": 0.6390434961863534,
      "grad_norm": 1.0676562786102295,
      "learning_rate": 0.00026381818181818185,
      "loss": 0.3189,
      "step": 3100
    },
    {
      "epoch": 0.6493506493506493,
      "grad_norm": 1.9986302852630615,
      "learning_rate": 0.0002592727272727273,
      "loss": 0.3032,
      "step": 3150
    },
    {
      "epoch": 0.6596578025149453,
      "grad_norm": 1.4945069551467896,
      "learning_rate": 0.00025472727272727273,
      "loss": 0.3243,
      "step": 3200
    },
    {
      "epoch": 0.6699649556792414,
      "grad_norm": 1.3853424787521362,
      "learning_rate": 0.0002501818181818182,
      "loss": 0.2881,
      "step": 3250
    },
    {
      "epoch": 0.6802721088435374,
      "grad_norm": 1.150389313697815,
      "learning_rate": 0.0002456363636363636,
      "loss": 0.313,
      "step": 3300
    },
    {
      "epoch": 0.6905792620078335,
      "grad_norm": 0.7896440625190735,
      "learning_rate": 0.0002410909090909091,
      "loss": 0.3111,
      "step": 3350
    },
    {
      "epoch": 0.7008864151721295,
      "grad_norm": 1.425160527229309,
      "learning_rate": 0.00023654545454545456,
      "loss": 0.3,
      "step": 3400
    },
    {
      "epoch": 0.7111935683364254,
      "grad_norm": 1.4251493215560913,
      "learning_rate": 0.00023200000000000003,
      "loss": 0.3062,
      "step": 3450
    },
    {
      "epoch": 0.7215007215007215,
      "grad_norm": 1.5692250728607178,
      "learning_rate": 0.00022745454545454547,
      "loss": 0.3047,
      "step": 3500
    },
    {
      "epoch": 0.7318078746650175,
      "grad_norm": 1.6278350353240967,
      "learning_rate": 0.00022290909090909091,
      "loss": 0.3083,
      "step": 3550
    },
    {
      "epoch": 0.7421150278293135,
      "grad_norm": 1.3724249601364136,
      "learning_rate": 0.00021836363636363638,
      "loss": 0.3221,
      "step": 3600
    },
    {
      "epoch": 0.7524221809936096,
      "grad_norm": 1.3860193490982056,
      "learning_rate": 0.00021381818181818183,
      "loss": 0.293,
      "step": 3650
    },
    {
      "epoch": 0.7627293341579056,
      "grad_norm": 1.230220913887024,
      "learning_rate": 0.00020927272727272727,
      "loss": 0.2853,
      "step": 3700
    },
    {
      "epoch": 0.7730364873222016,
      "grad_norm": 1.3530066013336182,
      "learning_rate": 0.00020472727272727274,
      "loss": 0.3037,
      "step": 3750
    },
    {
      "epoch": 0.7833436404864976,
      "grad_norm": 1.0293954610824585,
      "learning_rate": 0.00020018181818181818,
      "loss": 0.2867,
      "step": 3800
    },
    {
      "epoch": 0.7936507936507936,
      "grad_norm": 1.0892187356948853,
      "learning_rate": 0.00019563636363636365,
      "loss": 0.3024,
      "step": 3850
    },
    {
      "epoch": 0.8039579468150897,
      "grad_norm": 1.2023699283599854,
      "learning_rate": 0.0001910909090909091,
      "loss": 0.3036,
      "step": 3900
    },
    {
      "epoch": 0.8142650999793857,
      "grad_norm": 1.0347005128860474,
      "learning_rate": 0.00018654545454545454,
      "loss": 0.2861,
      "step": 3950
    },
    {
      "epoch": 0.8245722531436818,
      "grad_norm": 1.0966968536376953,
      "learning_rate": 0.000182,
      "loss": 0.3026,
      "step": 4000
    },
    {
      "epoch": 0.8348794063079777,
      "grad_norm": 1.5563913583755493,
      "learning_rate": 0.00017745454545454545,
      "loss": 0.3103,
      "step": 4050
    },
    {
      "epoch": 0.8451865594722737,
      "grad_norm": 1.5752872228622437,
      "learning_rate": 0.00017290909090909092,
      "loss": 0.2641,
      "step": 4100
    },
    {
      "epoch": 0.8554937126365698,
      "grad_norm": 1.119610071182251,
      "learning_rate": 0.00016836363636363636,
      "loss": 0.2805,
      "step": 4150
    },
    {
      "epoch": 0.8658008658008658,
      "grad_norm": 0.7199214100837708,
      "learning_rate": 0.0001638181818181818,
      "loss": 0.2841,
      "step": 4200
    },
    {
      "epoch": 0.8761080189651618,
      "grad_norm": 1.2849640846252441,
      "learning_rate": 0.00015927272727272727,
      "loss": 0.3028,
      "step": 4250
    },
    {
      "epoch": 0.8864151721294579,
      "grad_norm": 1.3619929552078247,
      "learning_rate": 0.00015472727272727274,
      "loss": 0.277,
      "step": 4300
    },
    {
      "epoch": 0.8967223252937538,
      "grad_norm": 1.5518178939819336,
      "learning_rate": 0.00015018181818181819,
      "loss": 0.316,
      "step": 4350
    },
    {
      "epoch": 0.9070294784580499,
      "grad_norm": 1.4857532978057861,
      "learning_rate": 0.00014563636363636366,
      "loss": 0.2732,
      "step": 4400
    },
    {
      "epoch": 0.9173366316223459,
      "grad_norm": 0.8715622425079346,
      "learning_rate": 0.0001410909090909091,
      "loss": 0.276,
      "step": 4450
    },
    {
      "epoch": 0.9276437847866419,
      "grad_norm": 1.4139940738677979,
      "learning_rate": 0.00013654545454545457,
      "loss": 0.295,
      "step": 4500
    },
    {
      "epoch": 0.937950937950938,
      "grad_norm": 1.4050897359848022,
      "learning_rate": 0.000132,
      "loss": 0.255,
      "step": 4550
    },
    {
      "epoch": 0.948258091115234,
      "grad_norm": 1.1319767236709595,
      "learning_rate": 0.00012745454545454545,
      "loss": 0.2965,
      "step": 4600
    },
    {
      "epoch": 0.95856524427953,
      "grad_norm": 1.0495274066925049,
      "learning_rate": 0.00012290909090909092,
      "loss": 0.2679,
      "step": 4650
    },
    {
      "epoch": 0.968872397443826,
      "grad_norm": 1.380758285522461,
      "learning_rate": 0.00011836363636363637,
      "loss": 0.2868,
      "step": 4700
    },
    {
      "epoch": 0.979179550608122,
      "grad_norm": 1.347545862197876,
      "learning_rate": 0.00011381818181818182,
      "loss": 0.2779,
      "step": 4750
    },
    {
      "epoch": 0.9894867037724181,
      "grad_norm": 1.0656075477600098,
      "learning_rate": 0.00010927272727272728,
      "loss": 0.2935,
      "step": 4800
    },
    {
      "epoch": 0.9997938569367141,
      "grad_norm": 0.9914343953132629,
      "learning_rate": 0.00010472727272727272,
      "loss": 0.2844,
      "step": 4850
    },
    {
      "epoch": 1.0101010101010102,
      "grad_norm": 0.9030446410179138,
      "learning_rate": 0.00010018181818181818,
      "loss": 0.2101,
      "step": 4900
    },
    {
      "epoch": 1.0204081632653061,
      "grad_norm": 1.4072380065917969,
      "learning_rate": 9.563636363636363e-05,
      "loss": 0.2179,
      "step": 4950
    },
    {
      "epoch": 1.0307153164296021,
      "grad_norm": 3.092202663421631,
      "learning_rate": 9.10909090909091e-05,
      "loss": 0.1955,
      "step": 5000
    },
    {
      "epoch": 1.041022469593898,
      "grad_norm": 0.897141695022583,
      "learning_rate": 8.654545454545456e-05,
      "loss": 0.1971,
      "step": 5050
    },
    {
      "epoch": 1.051329622758194,
      "grad_norm": 1.1891807317733765,
      "learning_rate": 8.2e-05,
      "loss": 0.2078,
      "step": 5100
    },
    {
      "epoch": 1.0616367759224903,
      "grad_norm": 1.011184811592102,
      "learning_rate": 7.745454545454546e-05,
      "loss": 0.2136,
      "step": 5150
    },
    {
      "epoch": 1.0719439290867863,
      "grad_norm": 1.2648454904556274,
      "learning_rate": 7.290909090909091e-05,
      "loss": 0.2164,
      "step": 5200
    },
    {
      "epoch": 1.0822510822510822,
      "grad_norm": 0.7710185050964355,
      "learning_rate": 6.836363636363637e-05,
      "loss": 0.2059,
      "step": 5250
    },
    {
      "epoch": 1.0925582354153782,
      "grad_norm": 0.9289422035217285,
      "learning_rate": 6.381818181818181e-05,
      "loss": 0.1889,
      "step": 5300
    },
    {
      "epoch": 1.1028653885796742,
      "grad_norm": 0.9467470645904541,
      "learning_rate": 5.9272727272727275e-05,
      "loss": 0.2082,
      "step": 5350
    },
    {
      "epoch": 1.1131725417439704,
      "grad_norm": 0.8796716928482056,
      "learning_rate": 5.472727272727273e-05,
      "loss": 0.1875,
      "step": 5400
    },
    {
      "epoch": 1.1234796949082664,
      "grad_norm": 1.0215126276016235,
      "learning_rate": 5.018181818181818e-05,
      "loss": 0.2268,
      "step": 5450
    },
    {
      "epoch": 1.1337868480725624,
      "grad_norm": 1.0644203424453735,
      "learning_rate": 4.563636363636364e-05,
      "loss": 0.2009,
      "step": 5500
    }
  ],
  "logging_steps": 50,
  "max_steps": 6000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.292110406148096e+19,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
