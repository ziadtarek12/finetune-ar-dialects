[
  {
    "loss": 2.8848,
    "grad_norm": 2.0828049182891846,
    "learning_rate": 4.8e-05,
    "epoch": 0.01030715316429602,
    "step": 50
  },
  {
    "loss": 1.3316,
    "grad_norm": 2.6984825134277344,
    "learning_rate": 9.800000000000001e-05,
    "epoch": 0.02061430632859204,
    "step": 100
  },
  {
    "loss": 1.0077,
    "grad_norm": 1.9541840553283691,
    "learning_rate": 0.000148,
    "epoch": 0.030921459492888066,
    "step": 150
  },
  {
    "loss": 0.6735,
    "grad_norm": 1.5692940950393677,
    "learning_rate": 0.00019800000000000002,
    "epoch": 0.04122861265718408,
    "step": 200
  },
  {
    "loss": 0.5096,
    "grad_norm": 1.4348764419555664,
    "learning_rate": 0.000248,
    "epoch": 0.05153576582148011,
    "step": 250
  },
  {
    "loss": 0.5195,
    "grad_norm": 1.47340726852417,
    "learning_rate": 0.000298,
    "epoch": 0.06184291898577613,
    "step": 300
  },
  {
    "loss": 0.4814,
    "grad_norm": 1.5993212461471558,
    "learning_rate": 0.000348,
    "epoch": 0.07215007215007214,
    "step": 350
  },
  {
    "loss": 0.4317,
    "grad_norm": 1.0021660327911377,
    "learning_rate": 0.000398,
    "epoch": 0.08245722531436817,
    "step": 400
  },
  {
    "loss": 0.4856,
    "grad_norm": 1.177679419517517,
    "learning_rate": 0.000448,
    "epoch": 0.09276437847866419,
    "step": 450
  },
  {
    "loss": 0.4428,
    "grad_norm": 1.3836790323257446,
    "learning_rate": 0.000498,
    "epoch": 0.10307153164296022,
    "step": 500
  },
  {
    "loss": 0.479,
    "grad_norm": 1.7914283275604248,
    "learning_rate": 0.0004956363636363637,
    "epoch": 0.11337868480725624,
    "step": 550
  },
  {
    "loss": 0.4573,
    "grad_norm": 1.5237536430358887,
    "learning_rate": 0.0004910909090909091,
    "epoch": 0.12368583797155226,
    "step": 600
  },
  {
    "loss": 0.404,
    "grad_norm": 1.1237435340881348,
    "learning_rate": 0.00048654545454545456,
    "epoch": 0.13399299113584828,
    "step": 650
  },
  {
    "loss": 0.4291,
    "grad_norm": 1.0885850191116333,
    "learning_rate": 0.000482,
    "epoch": 0.1443001443001443,
    "step": 700
  },
  {
    "loss": 0.4311,
    "grad_norm": 1.144952416419983,
    "learning_rate": 0.00047745454545454545,
    "epoch": 0.15460729746444032,
    "step": 750
  },
  {
    "loss": 0.4528,
    "grad_norm": 0.9737036228179932,
    "learning_rate": 0.0004729090909090909,
    "epoch": 0.16491445062873633,
    "step": 800
  },
  {
    "loss": 0.4259,
    "grad_norm": 1.922758936882019,
    "learning_rate": 0.0004683636363636364,
    "epoch": 0.17522160379303237,
    "step": 850
  },
  {
    "loss": 0.4416,
    "grad_norm": 1.3870055675506592,
    "learning_rate": 0.00046381818181818183,
    "epoch": 0.18552875695732837,
    "step": 900
  },
  {
    "loss": 0.4063,
    "grad_norm": 1.6452114582061768,
    "learning_rate": 0.0004592727272727273,
    "epoch": 0.1958359101216244,
    "step": 950
  },
  {
    "loss": 0.4161,
    "grad_norm": 0.937842845916748,
    "learning_rate": 0.0004547272727272727,
    "epoch": 0.20614306328592044,
    "step": 1000
  },
  {
    "loss": 0.4324,
    "grad_norm": 1.2152420282363892,
    "learning_rate": 0.0004501818181818182,
    "epoch": 0.21645021645021645,
    "step": 1050
  },
  {
    "loss": 0.4445,
    "grad_norm": 2.061384439468384,
    "learning_rate": 0.00044563636363636366,
    "epoch": 0.22675736961451248,
    "step": 1100
  },
  {
    "loss": 0.4346,
    "grad_norm": 1.3671696186065674,
    "learning_rate": 0.0004410909090909091,
    "epoch": 0.2370645227788085,
    "step": 1150
  },
  {
    "loss": 0.4287,
    "grad_norm": 1.0603969097137451,
    "learning_rate": 0.0004365454545454546,
    "epoch": 0.24737167594310452,
    "step": 1200
  },
  {
    "loss": 0.3855,
    "grad_norm": 1.1273633241653442,
    "learning_rate": 0.000432,
    "epoch": 0.25767882910740053,
    "step": 1250
  },
  {
    "loss": 0.3784,
    "grad_norm": 1.1242297887802124,
    "learning_rate": 0.0004274545454545455,
    "epoch": 0.26798598227169657,
    "step": 1300
  },
  {
    "loss": 0.3733,
    "grad_norm": 1.3314319849014282,
    "learning_rate": 0.0004229090909090909,
    "epoch": 0.2782931354359926,
    "step": 1350
  },
  {
    "loss": 0.3787,
    "grad_norm": 1.050687313079834,
    "learning_rate": 0.00041836363636363637,
    "epoch": 0.2886002886002886,
    "step": 1400
  },
  {
    "loss": 0.3767,
    "grad_norm": 1.2502217292785645,
    "learning_rate": 0.0004138181818181818,
    "epoch": 0.2989074417645846,
    "step": 1450
  },
  {
    "loss": 0.3821,
    "grad_norm": 1.386946678161621,
    "learning_rate": 0.0004092727272727273,
    "epoch": 0.30921459492888065,
    "step": 1500
  },
  {
    "loss": 0.3799,
    "grad_norm": 1.0658541917800903,
    "learning_rate": 0.00040472727272727275,
    "epoch": 0.3195217480931767,
    "step": 1550
  },
  {
    "loss": 0.3896,
    "grad_norm": 1.5130937099456787,
    "learning_rate": 0.0004001818181818182,
    "epoch": 0.32982890125747266,
    "step": 1600
  },
  {
    "loss": 0.358,
    "grad_norm": 1.2951409816741943,
    "learning_rate": 0.00039563636363636363,
    "epoch": 0.3401360544217687,
    "step": 1650
  },
  {
    "loss": 0.3888,
    "grad_norm": 1.149279236793518,
    "learning_rate": 0.00039109090909090913,
    "epoch": 0.35044320758606473,
    "step": 1700
  },
  {
    "loss": 0.3675,
    "grad_norm": 1.0152249336242676,
    "learning_rate": 0.0003865454545454545,
    "epoch": 0.36075036075036077,
    "step": 1750
  },
  {
    "loss": 0.3895,
    "grad_norm": 2.027949094772339,
    "learning_rate": 0.000382,
    "epoch": 0.37105751391465674,
    "step": 1800
  },
  {
    "loss": 0.3657,
    "grad_norm": 1.7667394876480103,
    "learning_rate": 0.00037745454545454546,
    "epoch": 0.3813646670789528,
    "step": 1850
  },
  {
    "loss": 0.3685,
    "grad_norm": 1.3091682195663452,
    "learning_rate": 0.0003729090909090909,
    "epoch": 0.3916718202432488,
    "step": 1900
  },
  {
    "loss": 0.3482,
    "grad_norm": 1.9059885740280151,
    "learning_rate": 0.00036836363636363634,
    "epoch": 0.40197897340754485,
    "step": 1950
  },
  {
    "loss": 0.3621,
    "grad_norm": 1.3428462743759155,
    "learning_rate": 0.00036381818181818184,
    "epoch": 0.4122861265718409,
    "step": 2000
  },
  {
    "loss": 0.3554,
    "grad_norm": 0.9777273535728455,
    "learning_rate": 0.0003592727272727273,
    "epoch": 0.42259327973613686,
    "step": 2050
  },
  {
    "loss": 0.3369,
    "grad_norm": 1.6832828521728516,
    "learning_rate": 0.0003547272727272727,
    "epoch": 0.4329004329004329,
    "step": 2100
  },
  {
    "loss": 0.3475,
    "grad_norm": 0.8535405397415161,
    "learning_rate": 0.0003501818181818182,
    "epoch": 0.44320758606472893,
    "step": 2150
  },
  {
    "loss": 0.336,
    "grad_norm": 1.232762336730957,
    "learning_rate": 0.00034563636363636366,
    "epoch": 0.45351473922902497,
    "step": 2200
  },
  {
    "loss": 0.3408,
    "grad_norm": 1.4716391563415527,
    "learning_rate": 0.0003410909090909091,
    "epoch": 0.46382189239332094,
    "step": 2250
  },
  {
    "loss": 0.3428,
    "grad_norm": 1.7491559982299805,
    "learning_rate": 0.00033654545454545455,
    "epoch": 0.474129045557617,
    "step": 2300
  },
  {
    "loss": 0.3382,
    "grad_norm": 1.4655380249023438,
    "learning_rate": 0.00033200000000000005,
    "epoch": 0.484436198721913,
    "step": 2350
  },
  {
    "loss": 0.3379,
    "grad_norm": 1.8550478219985962,
    "learning_rate": 0.00032745454545454544,
    "epoch": 0.49474335188620905,
    "step": 2400
  },
  {
    "loss": 0.3309,
    "grad_norm": 1.285152554512024,
    "learning_rate": 0.00032290909090909093,
    "epoch": 0.5050505050505051,
    "step": 2450
  },
  {
    "loss": 0.3007,
    "grad_norm": 1.3149021863937378,
    "learning_rate": 0.0003183636363636364,
    "epoch": 0.5153576582148011,
    "step": 2500
  },
  {
    "loss": 0.3511,
    "grad_norm": 1.3000088930130005,
    "learning_rate": 0.0003138181818181818,
    "epoch": 0.525664811379097,
    "step": 2550
  },
  {
    "loss": 0.3137,
    "grad_norm": 1.1672391891479492,
    "learning_rate": 0.00030927272727272726,
    "epoch": 0.5359719645433931,
    "step": 2600
  },
  {
    "loss": 0.3486,
    "grad_norm": 1.446348786354065,
    "learning_rate": 0.00030472727272727276,
    "epoch": 0.5462791177076891,
    "step": 2650
  },
  {
    "loss": 0.3182,
    "grad_norm": 1.2033271789550781,
    "learning_rate": 0.00030018181818181815,
    "epoch": 0.5565862708719852,
    "step": 2700
  },
  {
    "loss": 0.303,
    "grad_norm": 1.6455484628677368,
    "learning_rate": 0.00029563636363636364,
    "epoch": 0.5668934240362812,
    "step": 2750
  },
  {
    "loss": 0.2931,
    "grad_norm": 1.1507468223571777,
    "learning_rate": 0.0002910909090909091,
    "epoch": 0.5772005772005772,
    "step": 2800
  },
  {
    "loss": 0.3336,
    "grad_norm": 0.766877293586731,
    "learning_rate": 0.00028654545454545453,
    "epoch": 0.5875077303648732,
    "step": 2850
  },
  {
    "loss": 0.3131,
    "grad_norm": 1.2564352750778198,
    "learning_rate": 0.00028199999999999997,
    "epoch": 0.5978148835291692,
    "step": 2900
  },
  {
    "loss": 0.3242,
    "grad_norm": 1.7314453125,
    "learning_rate": 0.00027745454545454547,
    "epoch": 0.6081220366934653,
    "step": 2950
  },
  {
    "loss": 0.3302,
    "grad_norm": 0.7546097636222839,
    "learning_rate": 0.00027290909090909096,
    "epoch": 0.6184291898577613,
    "step": 3000
  },
  {
    "loss": 0.3326,
    "grad_norm": 2.1374335289001465,
    "learning_rate": 0.00026836363636363635,
    "epoch": 0.6287363430220573,
    "step": 3050
  },
  {
    "loss": 0.3189,
    "grad_norm": 1.0676562786102295,
    "learning_rate": 0.00026381818181818185,
    "epoch": 0.6390434961863534,
    "step": 3100
  },
  {
    "loss": 0.3032,
    "grad_norm": 1.9986302852630615,
    "learning_rate": 0.0002592727272727273,
    "epoch": 0.6493506493506493,
    "step": 3150
  },
  {
    "loss": 0.3243,
    "grad_norm": 1.4945069551467896,
    "learning_rate": 0.00025472727272727273,
    "epoch": 0.6596578025149453,
    "step": 3200
  },
  {
    "loss": 0.2881,
    "grad_norm": 1.3853424787521362,
    "learning_rate": 0.0002501818181818182,
    "epoch": 0.6699649556792414,
    "step": 3250
  },
  {
    "loss": 0.313,
    "grad_norm": 1.150389313697815,
    "learning_rate": 0.0002456363636363636,
    "epoch": 0.6802721088435374,
    "step": 3300
  },
  {
    "loss": 0.3111,
    "grad_norm": 0.7896440625190735,
    "learning_rate": 0.0002410909090909091,
    "epoch": 0.6905792620078335,
    "step": 3350
  },
  {
    "loss": 0.3,
    "grad_norm": 1.425160527229309,
    "learning_rate": 0.00023654545454545456,
    "epoch": 0.7008864151721295,
    "step": 3400
  },
  {
    "loss": 0.3062,
    "grad_norm": 1.4251493215560913,
    "learning_rate": 0.00023200000000000003,
    "epoch": 0.7111935683364254,
    "step": 3450
  },
  {
    "loss": 0.3047,
    "grad_norm": 1.5692250728607178,
    "learning_rate": 0.00022745454545454547,
    "epoch": 0.7215007215007215,
    "step": 3500
  },
  {
    "loss": 0.3083,
    "grad_norm": 1.6278350353240967,
    "learning_rate": 0.00022290909090909091,
    "epoch": 0.7318078746650175,
    "step": 3550
  },
  {
    "loss": 0.3221,
    "grad_norm": 1.3724249601364136,
    "learning_rate": 0.00021836363636363638,
    "epoch": 0.7421150278293135,
    "step": 3600
  },
  {
    "loss": 0.293,
    "grad_norm": 1.3860193490982056,
    "learning_rate": 0.00021381818181818183,
    "epoch": 0.7524221809936096,
    "step": 3650
  },
  {
    "loss": 0.2853,
    "grad_norm": 1.230220913887024,
    "learning_rate": 0.00020927272727272727,
    "epoch": 0.7627293341579056,
    "step": 3700
  },
  {
    "loss": 0.3037,
    "grad_norm": 1.3530066013336182,
    "learning_rate": 0.00020472727272727274,
    "epoch": 0.7730364873222016,
    "step": 3750
  },
  {
    "loss": 0.2867,
    "grad_norm": 1.0293954610824585,
    "learning_rate": 0.00020018181818181818,
    "epoch": 0.7833436404864976,
    "step": 3800
  },
  {
    "loss": 0.3024,
    "grad_norm": 1.0892187356948853,
    "learning_rate": 0.00019563636363636365,
    "epoch": 0.7936507936507936,
    "step": 3850
  },
  {
    "loss": 0.3036,
    "grad_norm": 1.2023699283599854,
    "learning_rate": 0.0001910909090909091,
    "epoch": 0.8039579468150897,
    "step": 3900
  },
  {
    "loss": 0.2861,
    "grad_norm": 1.0347005128860474,
    "learning_rate": 0.00018654545454545454,
    "epoch": 0.8142650999793857,
    "step": 3950
  },
  {
    "loss": 0.3026,
    "grad_norm": 1.0966968536376953,
    "learning_rate": 0.000182,
    "epoch": 0.8245722531436818,
    "step": 4000
  },
  {
    "loss": 0.3103,
    "grad_norm": 1.5563913583755493,
    "learning_rate": 0.00017745454545454545,
    "epoch": 0.8348794063079777,
    "step": 4050
  },
  {
    "loss": 0.2641,
    "grad_norm": 1.5752872228622437,
    "learning_rate": 0.00017290909090909092,
    "epoch": 0.8451865594722737,
    "step": 4100
  },
  {
    "loss": 0.2805,
    "grad_norm": 1.119610071182251,
    "learning_rate": 0.00016836363636363636,
    "epoch": 0.8554937126365698,
    "step": 4150
  },
  {
    "loss": 0.2841,
    "grad_norm": 0.7199214100837708,
    "learning_rate": 0.0001638181818181818,
    "epoch": 0.8658008658008658,
    "step": 4200
  },
  {
    "loss": 0.3028,
    "grad_norm": 1.2849640846252441,
    "learning_rate": 0.00015927272727272727,
    "epoch": 0.8761080189651618,
    "step": 4250
  },
  {
    "loss": 0.277,
    "grad_norm": 1.3619929552078247,
    "learning_rate": 0.00015472727272727274,
    "epoch": 0.8864151721294579,
    "step": 4300
  },
  {
    "loss": 0.316,
    "grad_norm": 1.5518178939819336,
    "learning_rate": 0.00015018181818181819,
    "epoch": 0.8967223252937538,
    "step": 4350
  },
  {
    "loss": 0.2732,
    "grad_norm": 1.4857532978057861,
    "learning_rate": 0.00014563636363636366,
    "epoch": 0.9070294784580499,
    "step": 4400
  },
  {
    "loss": 0.276,
    "grad_norm": 0.8715622425079346,
    "learning_rate": 0.0001410909090909091,
    "epoch": 0.9173366316223459,
    "step": 4450
  },
  {
    "loss": 0.295,
    "grad_norm": 1.4139940738677979,
    "learning_rate": 0.00013654545454545457,
    "epoch": 0.9276437847866419,
    "step": 4500
  },
  {
    "loss": 0.255,
    "grad_norm": 1.4050897359848022,
    "learning_rate": 0.000132,
    "epoch": 0.937950937950938,
    "step": 4550
  },
  {
    "loss": 0.2965,
    "grad_norm": 1.1319767236709595,
    "learning_rate": 0.00012745454545454545,
    "epoch": 0.948258091115234,
    "step": 4600
  },
  {
    "loss": 0.2679,
    "grad_norm": 1.0495274066925049,
    "learning_rate": 0.00012290909090909092,
    "epoch": 0.95856524427953,
    "step": 4650
  },
  {
    "loss": 0.2868,
    "grad_norm": 1.380758285522461,
    "learning_rate": 0.00011836363636363637,
    "epoch": 0.968872397443826,
    "step": 4700
  },
  {
    "loss": 0.2779,
    "grad_norm": 1.347545862197876,
    "learning_rate": 0.00011381818181818182,
    "epoch": 0.979179550608122,
    "step": 4750
  },
  {
    "loss": 0.2935,
    "grad_norm": 1.0656075477600098,
    "learning_rate": 0.00010927272727272728,
    "epoch": 0.9894867037724181,
    "step": 4800
  },
  {
    "loss": 0.2844,
    "grad_norm": 0.9914343953132629,
    "learning_rate": 0.00010472727272727272,
    "epoch": 0.9997938569367141,
    "step": 4850
  },
  {
    "loss": 0.2101,
    "grad_norm": 0.9030446410179138,
    "learning_rate": 0.00010018181818181818,
    "epoch": 1.0101010101010102,
    "step": 4900
  },
  {
    "loss": 0.2179,
    "grad_norm": 1.4072380065917969,
    "learning_rate": 9.563636363636363e-05,
    "epoch": 1.0204081632653061,
    "step": 4950
  },
  {
    "loss": 0.1955,
    "grad_norm": 3.092202663421631,
    "learning_rate": 9.10909090909091e-05,
    "epoch": 1.0307153164296021,
    "step": 5000
  },
  {
    "loss": 0.1971,
    "grad_norm": 0.897141695022583,
    "learning_rate": 8.654545454545456e-05,
    "epoch": 1.041022469593898,
    "step": 5050
  },
  {
    "loss": 0.2078,
    "grad_norm": 1.1891807317733765,
    "learning_rate": 8.2e-05,
    "epoch": 1.051329622758194,
    "step": 5100
  },
  {
    "loss": 0.2136,
    "grad_norm": 1.011184811592102,
    "learning_rate": 7.745454545454546e-05,
    "epoch": 1.0616367759224903,
    "step": 5150
  },
  {
    "loss": 0.2164,
    "grad_norm": 1.2648454904556274,
    "learning_rate": 7.290909090909091e-05,
    "epoch": 1.0719439290867863,
    "step": 5200
  },
  {
    "loss": 0.2059,
    "grad_norm": 0.7710185050964355,
    "learning_rate": 6.836363636363637e-05,
    "epoch": 1.0822510822510822,
    "step": 5250
  },
  {
    "loss": 0.1889,
    "grad_norm": 0.9289422035217285,
    "learning_rate": 6.381818181818181e-05,
    "epoch": 1.0925582354153782,
    "step": 5300
  },
  {
    "loss": 0.2082,
    "grad_norm": 0.9467470645904541,
    "learning_rate": 5.9272727272727275e-05,
    "epoch": 1.1028653885796742,
    "step": 5350
  },
  {
    "loss": 0.1875,
    "grad_norm": 0.8796716928482056,
    "learning_rate": 5.472727272727273e-05,
    "epoch": 1.1131725417439704,
    "step": 5400
  },
  {
    "loss": 0.2268,
    "grad_norm": 1.0215126276016235,
    "learning_rate": 5.018181818181818e-05,
    "epoch": 1.1234796949082664,
    "step": 5450
  },
  {
    "loss": 0.2009,
    "grad_norm": 1.0644203424453735,
    "learning_rate": 4.563636363636364e-05,
    "epoch": 1.1337868480725624,
    "step": 5500
  },
  {
    "loss": 0.2044,
    "grad_norm": 1.0726615190505981,
    "learning_rate": 4.1090909090909086e-05,
    "epoch": 1.1440940012368583,
    "step": 5550
  },
  {
    "loss": 0.2179,
    "grad_norm": 0.8633792400360107,
    "learning_rate": 3.654545454545455e-05,
    "epoch": 1.1544011544011543,
    "step": 5600
  },
  {
    "loss": 0.2056,
    "grad_norm": 1.1996947526931763,
    "learning_rate": 3.2e-05,
    "epoch": 1.1647083075654505,
    "step": 5650
  },
  {
    "loss": 0.2006,
    "grad_norm": 0.7571372389793396,
    "learning_rate": 2.7454545454545455e-05,
    "epoch": 1.1750154607297465,
    "step": 5700
  },
  {
    "loss": 0.194,
    "grad_norm": 1.2288771867752075,
    "learning_rate": 2.290909090909091e-05,
    "epoch": 1.1853226138940425,
    "step": 5750
  },
  {
    "loss": 0.2027,
    "grad_norm": 1.4232823848724365,
    "learning_rate": 1.8363636363636364e-05,
    "epoch": 1.1956297670583385,
    "step": 5800
  },
  {
    "loss": 0.2013,
    "grad_norm": 1.7807483673095703,
    "learning_rate": 1.3818181818181818e-05,
    "epoch": 1.2059369202226344,
    "step": 5850
  },
  {
    "loss": 0.186,
    "grad_norm": 1.1241053342819214,
    "learning_rate": 9.272727272727273e-06,
    "epoch": 1.2162440733869304,
    "step": 5900
  },
  {
    "loss": 0.1907,
    "grad_norm": 1.0325998067855835,
    "learning_rate": 4.727272727272728e-06,
    "epoch": 1.2265512265512266,
    "step": 5950
  },
  {
    "loss": 0.1972,
    "grad_norm": 1.0252714157104492,
    "learning_rate": 1.818181818181818e-07,
    "epoch": 1.2368583797155226,
    "step": 6000
  },
  {
    "train_runtime": 19477.7963,
    "train_samples_per_second": 2.464,
    "train_steps_per_second": 0.308,
    "total_flos": 1.409582998020096e+19,
    "train_loss": 0.35878331995010376,
    "epoch": 1.2368583797155226,
    "step": 6000
  }
]