{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9096117122851686,
  "eval_steps": 500,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.031826861871419476,
      "grad_norm": 2.1314120292663574,
      "learning_rate": 9.6e-05,
      "loss": 4.1635,
      "step": 50
    },
    {
      "epoch": 0.06365372374283895,
      "grad_norm": 2.2104458808898926,
      "learning_rate": 0.00019600000000000002,
      "loss": 2.3887,
      "step": 100
    },
    {
      "epoch": 0.09548058561425843,
      "grad_norm": 2.7171144485473633,
      "learning_rate": 0.000296,
      "loss": 1.8634,
      "step": 150
    },
    {
      "epoch": 0.1273074474856779,
      "grad_norm": 2.5432987213134766,
      "learning_rate": 0.00039600000000000003,
      "loss": 1.6568,
      "step": 200
    },
    {
      "epoch": 0.15913430935709738,
      "grad_norm": 1.5901707410812378,
      "learning_rate": 0.000496,
      "loss": 1.529,
      "step": 250
    },
    {
      "epoch": 0.19096117122851686,
      "grad_norm": 2.1382341384887695,
      "learning_rate": 0.000596,
      "loss": 1.5246,
      "step": 300
    },
    {
      "epoch": 0.22278803309993633,
      "grad_norm": 1.971246600151062,
      "learning_rate": 0.000696,
      "loss": 1.571,
      "step": 350
    },
    {
      "epoch": 0.2546148949713558,
      "grad_norm": 2.0374183654785156,
      "learning_rate": 0.000796,
      "loss": 1.6077,
      "step": 400
    },
    {
      "epoch": 0.2864417568427753,
      "grad_norm": 2.612983465194702,
      "learning_rate": 0.000896,
      "loss": 1.561,
      "step": 450
    },
    {
      "epoch": 0.31826861871419476,
      "grad_norm": 3.7339484691619873,
      "learning_rate": 0.000996,
      "loss": 1.5952,
      "step": 500
    },
    {
      "epoch": 0.35009548058561424,
      "grad_norm": 4.2569966316223145,
      "learning_rate": 0.0009808,
      "loss": 1.6121,
      "step": 550
    },
    {
      "epoch": 0.3819223424570337,
      "grad_norm": 2.637874126434326,
      "learning_rate": 0.0009608,
      "loss": 1.6629,
      "step": 600
    },
    {
      "epoch": 0.4137492043284532,
      "grad_norm": 3.0513370037078857,
      "learning_rate": 0.0009408,
      "loss": 1.5679,
      "step": 650
    },
    {
      "epoch": 0.44557606619987267,
      "grad_norm": 2.9296295642852783,
      "learning_rate": 0.0009207999999999999,
      "loss": 1.5962,
      "step": 700
    },
    {
      "epoch": 0.47740292807129214,
      "grad_norm": 3.753538131713867,
      "learning_rate": 0.0009008000000000001,
      "loss": 1.7182,
      "step": 750
    },
    {
      "epoch": 0.5092297899427116,
      "grad_norm": 3.3028619289398193,
      "learning_rate": 0.0008808,
      "loss": 1.5845,
      "step": 800
    },
    {
      "epoch": 0.5410566518141311,
      "grad_norm": 2.776803970336914,
      "learning_rate": 0.0008608,
      "loss": 1.5475,
      "step": 850
    },
    {
      "epoch": 0.5728835136855506,
      "grad_norm": 2.326761245727539,
      "learning_rate": 0.0008408000000000001,
      "loss": 1.5769,
      "step": 900
    },
    {
      "epoch": 0.60471037555697,
      "grad_norm": 3.3681960105895996,
      "learning_rate": 0.0008208,
      "loss": 1.5131,
      "step": 950
    },
    {
      "epoch": 0.6365372374283895,
      "grad_norm": 3.245661735534668,
      "learning_rate": 0.0008008,
      "loss": 1.5417,
      "step": 1000
    },
    {
      "epoch": 0.668364099299809,
      "grad_norm": 2.9009368419647217,
      "learning_rate": 0.0007808000000000001,
      "loss": 1.5207,
      "step": 1050
    },
    {
      "epoch": 0.7001909611712285,
      "grad_norm": 2.3682360649108887,
      "learning_rate": 0.0007608000000000001,
      "loss": 1.5935,
      "step": 1100
    },
    {
      "epoch": 0.732017823042648,
      "grad_norm": 2.3727688789367676,
      "learning_rate": 0.0007408,
      "loss": 1.483,
      "step": 1150
    },
    {
      "epoch": 0.7638446849140674,
      "grad_norm": 3.7016117572784424,
      "learning_rate": 0.0007208000000000001,
      "loss": 1.5794,
      "step": 1200
    },
    {
      "epoch": 0.7956715467854869,
      "grad_norm": 3.4132578372955322,
      "learning_rate": 0.0007008,
      "loss": 1.4691,
      "step": 1250
    },
    {
      "epoch": 0.8274984086569064,
      "grad_norm": 3.98140811920166,
      "learning_rate": 0.0006808,
      "loss": 1.4524,
      "step": 1300
    },
    {
      "epoch": 0.8593252705283259,
      "grad_norm": 2.815234661102295,
      "learning_rate": 0.0006608,
      "loss": 1.492,
      "step": 1350
    },
    {
      "epoch": 0.8911521323997453,
      "grad_norm": 2.7509355545043945,
      "learning_rate": 0.0006408000000000001,
      "loss": 1.4859,
      "step": 1400
    },
    {
      "epoch": 0.9229789942711648,
      "grad_norm": 3.2786805629730225,
      "learning_rate": 0.0006208,
      "loss": 1.4465,
      "step": 1450
    },
    {
      "epoch": 0.9548058561425843,
      "grad_norm": 2.5798227787017822,
      "learning_rate": 0.0006008,
      "loss": 1.4921,
      "step": 1500
    },
    {
      "epoch": 0.9866327180140039,
      "grad_norm": 2.7732090950012207,
      "learning_rate": 0.0005808,
      "loss": 1.4365,
      "step": 1550
    },
    {
      "epoch": 1.0184595798854232,
      "grad_norm": 2.4757931232452393,
      "learning_rate": 0.0005608,
      "loss": 1.2678,
      "step": 1600
    },
    {
      "epoch": 1.0502864417568427,
      "grad_norm": 2.7129034996032715,
      "learning_rate": 0.0005407999999999999,
      "loss": 1.2504,
      "step": 1650
    },
    {
      "epoch": 1.0821133036282622,
      "grad_norm": 2.926011323928833,
      "learning_rate": 0.0005208000000000001,
      "loss": 1.1629,
      "step": 1700
    },
    {
      "epoch": 1.1139401654996817,
      "grad_norm": 4.0995097160339355,
      "learning_rate": 0.0005008,
      "loss": 1.2133,
      "step": 1750
    },
    {
      "epoch": 1.1457670273711011,
      "grad_norm": 2.013693332672119,
      "learning_rate": 0.00048080000000000003,
      "loss": 1.2818,
      "step": 1800
    },
    {
      "epoch": 1.1775938892425206,
      "grad_norm": 2.7158055305480957,
      "learning_rate": 0.0004608,
      "loss": 1.2464,
      "step": 1850
    },
    {
      "epoch": 1.20942075111394,
      "grad_norm": 3.693862199783325,
      "learning_rate": 0.00044080000000000004,
      "loss": 1.2616,
      "step": 1900
    },
    {
      "epoch": 1.2412476129853596,
      "grad_norm": 2.356374740600586,
      "learning_rate": 0.00042080000000000004,
      "loss": 1.2765,
      "step": 1950
    },
    {
      "epoch": 1.273074474856779,
      "grad_norm": 2.6313462257385254,
      "learning_rate": 0.0004008,
      "loss": 1.2376,
      "step": 2000
    },
    {
      "epoch": 1.3049013367281985,
      "grad_norm": 2.080808401107788,
      "learning_rate": 0.00038080000000000004,
      "loss": 1.2225,
      "step": 2050
    },
    {
      "epoch": 1.336728198599618,
      "grad_norm": 2.2544105052948,
      "learning_rate": 0.00036080000000000004,
      "loss": 1.2451,
      "step": 2100
    },
    {
      "epoch": 1.3685550604710375,
      "grad_norm": 1.867034912109375,
      "learning_rate": 0.0003408,
      "loss": 1.1693,
      "step": 2150
    },
    {
      "epoch": 1.400381922342457,
      "grad_norm": 2.142573833465576,
      "learning_rate": 0.0003208,
      "loss": 1.259,
      "step": 2200
    },
    {
      "epoch": 1.4322087842138764,
      "grad_norm": 2.3438379764556885,
      "learning_rate": 0.0003008,
      "loss": 1.2942,
      "step": 2250
    },
    {
      "epoch": 1.464035646085296,
      "grad_norm": 2.25262451171875,
      "learning_rate": 0.0002808,
      "loss": 1.2523,
      "step": 2300
    },
    {
      "epoch": 1.4958625079567156,
      "grad_norm": 2.621497392654419,
      "learning_rate": 0.0002608,
      "loss": 1.0884,
      "step": 2350
    },
    {
      "epoch": 1.5276893698281349,
      "grad_norm": 2.7863409519195557,
      "learning_rate": 0.0002408,
      "loss": 1.0734,
      "step": 2400
    },
    {
      "epoch": 1.5595162316995546,
      "grad_norm": 2.151627540588379,
      "learning_rate": 0.0002208,
      "loss": 1.2098,
      "step": 2450
    },
    {
      "epoch": 1.5913430935709738,
      "grad_norm": 2.7271697521209717,
      "learning_rate": 0.0002008,
      "loss": 1.1713,
      "step": 2500
    },
    {
      "epoch": 1.6231699554423935,
      "grad_norm": 2.1881039142608643,
      "learning_rate": 0.0001808,
      "loss": 1.1334,
      "step": 2550
    },
    {
      "epoch": 1.6549968173138128,
      "grad_norm": 2.943446159362793,
      "learning_rate": 0.0001608,
      "loss": 1.1027,
      "step": 2600
    },
    {
      "epoch": 1.6868236791852325,
      "grad_norm": 3.2713587284088135,
      "learning_rate": 0.0001408,
      "loss": 1.1648,
      "step": 2650
    },
    {
      "epoch": 1.7186505410566517,
      "grad_norm": 3.179935932159424,
      "learning_rate": 0.00012080000000000001,
      "loss": 1.0987,
      "step": 2700
    },
    {
      "epoch": 1.7504774029280714,
      "grad_norm": 2.3489503860473633,
      "learning_rate": 0.0001008,
      "loss": 1.1177,
      "step": 2750
    },
    {
      "epoch": 1.7823042647994907,
      "grad_norm": 2.5022623538970947,
      "learning_rate": 8.08e-05,
      "loss": 1.1072,
      "step": 2800
    },
    {
      "epoch": 1.8141311266709104,
      "grad_norm": 1.858527660369873,
      "learning_rate": 6.08e-05,
      "loss": 1.0859,
      "step": 2850
    },
    {
      "epoch": 1.8459579885423296,
      "grad_norm": 2.5263335704803467,
      "learning_rate": 4.08e-05,
      "loss": 1.0899,
      "step": 2900
    },
    {
      "epoch": 1.8777848504137493,
      "grad_norm": 2.317502498626709,
      "learning_rate": 2.08e-05,
      "loss": 1.1628,
      "step": 2950
    },
    {
      "epoch": 1.9096117122851686,
      "grad_norm": 2.1811888217926025,
      "learning_rate": 8.000000000000001e-07,
      "loss": 1.1478,
      "step": 3000
    }
  ],
  "logging_steps": 50,
  "max_steps": 3000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.04718078640128e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
