{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9096117122851686,
  "eval_steps": 500,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.031826861871419476,
      "grad_norm": 2.068079710006714,
      "learning_rate": 9.800000000000001e-05,
      "loss": 4.0932,
      "step": 50
    },
    {
      "epoch": 0.06365372374283895,
      "grad_norm": 2.1193149089813232,
      "learning_rate": 0.00019800000000000002,
      "loss": 2.376,
      "step": 100
    },
    {
      "epoch": 0.09548058561425843,
      "grad_norm": 2.6618711948394775,
      "learning_rate": 0.000298,
      "loss": 1.832,
      "step": 150
    },
    {
      "epoch": 0.1273074474856779,
      "grad_norm": 2.3447039127349854,
      "learning_rate": 0.000398,
      "loss": 1.6526,
      "step": 200
    },
    {
      "epoch": 0.15913430935709738,
      "grad_norm": 1.572648048400879,
      "learning_rate": 0.000498,
      "loss": 1.5297,
      "step": 250
    },
    {
      "epoch": 0.19096117122851686,
      "grad_norm": 1.8869599103927612,
      "learning_rate": 0.000598,
      "loss": 1.5269,
      "step": 300
    },
    {
      "epoch": 0.22278803309993633,
      "grad_norm": 2.2364206314086914,
      "learning_rate": 0.0006979999999999999,
      "loss": 1.5731,
      "step": 350
    },
    {
      "epoch": 0.2546148949713558,
      "grad_norm": 1.8653918504714966,
      "learning_rate": 0.0007980000000000001,
      "loss": 1.6151,
      "step": 400
    },
    {
      "epoch": 0.2864417568427753,
      "grad_norm": 2.442237138748169,
      "learning_rate": 0.000892,
      "loss": 1.9842,
      "step": 450
    },
    {
      "epoch": 0.31826861871419476,
      "grad_norm": 3.1483280658721924,
      "learning_rate": 0.000992,
      "loss": 1.5942,
      "step": 500
    },
    {
      "epoch": 0.35009548058561424,
      "grad_norm": 3.1143200397491455,
      "learning_rate": 0.0009816,
      "loss": 1.5998,
      "step": 550
    },
    {
      "epoch": 0.3819223424570337,
      "grad_norm": 3.0609495639801025,
      "learning_rate": 0.0009616000000000001,
      "loss": 1.6793,
      "step": 600
    },
    {
      "epoch": 0.4137492043284532,
      "grad_norm": 3.066903591156006,
      "learning_rate": 0.0009416,
      "loss": 1.7366,
      "step": 650
    },
    {
      "epoch": 0.44557606619987267,
      "grad_norm": 3.3753437995910645,
      "learning_rate": 0.0009216,
      "loss": 1.6047,
      "step": 700
    },
    {
      "epoch": 0.47740292807129214,
      "grad_norm": 3.515737295150757,
      "learning_rate": 0.0009016,
      "loss": 1.7233,
      "step": 750
    },
    {
      "epoch": 0.5092297899427116,
      "grad_norm": 3.825981855392456,
      "learning_rate": 0.0008816000000000001,
      "loss": 1.5978,
      "step": 800
    },
    {
      "epoch": 0.5410566518141311,
      "grad_norm": 2.422363519668579,
      "learning_rate": 0.0008616,
      "loss": 1.5581,
      "step": 850
    },
    {
      "epoch": 0.5728835136855506,
      "grad_norm": 2.5461504459381104,
      "learning_rate": 0.0008416000000000001,
      "loss": 1.582,
      "step": 900
    },
    {
      "epoch": 0.60471037555697,
      "grad_norm": 3.3671317100524902,
      "learning_rate": 0.0008216,
      "loss": 1.5183,
      "step": 950
    },
    {
      "epoch": 0.6365372374283895,
      "grad_norm": 3.4708869457244873,
      "learning_rate": 0.0008016,
      "loss": 1.5291,
      "step": 1000
    },
    {
      "epoch": 0.668364099299809,
      "grad_norm": 2.4726617336273193,
      "learning_rate": 0.0007816,
      "loss": 1.5306,
      "step": 1050
    },
    {
      "epoch": 0.7001909611712285,
      "grad_norm": 2.4545605182647705,
      "learning_rate": 0.0007616000000000001,
      "loss": 1.5923,
      "step": 1100
    },
    {
      "epoch": 0.732017823042648,
      "grad_norm": 2.1140036582946777,
      "learning_rate": 0.0007416,
      "loss": 1.4839,
      "step": 1150
    },
    {
      "epoch": 0.7638446849140674,
      "grad_norm": 3.284132242202759,
      "learning_rate": 0.0007216000000000001,
      "loss": 1.5892,
      "step": 1200
    },
    {
      "epoch": 0.7956715467854869,
      "grad_norm": 2.6186561584472656,
      "learning_rate": 0.0007016,
      "loss": 1.4585,
      "step": 1250
    },
    {
      "epoch": 0.8274984086569064,
      "grad_norm": 3.4403553009033203,
      "learning_rate": 0.0006816,
      "loss": 1.4588,
      "step": 1300
    },
    {
      "epoch": 0.8593252705283259,
      "grad_norm": 2.6112136840820312,
      "learning_rate": 0.0006615999999999999,
      "loss": 1.4901,
      "step": 1350
    },
    {
      "epoch": 0.8911521323997453,
      "grad_norm": 2.584719181060791,
      "learning_rate": 0.0006416,
      "loss": 1.4946,
      "step": 1400
    },
    {
      "epoch": 0.9229789942711648,
      "grad_norm": 3.177412271499634,
      "learning_rate": 0.0006216,
      "loss": 1.4313,
      "step": 1450
    },
    {
      "epoch": 0.9548058561425843,
      "grad_norm": 2.8063790798187256,
      "learning_rate": 0.0006016,
      "loss": 1.4961,
      "step": 1500
    },
    {
      "epoch": 0.9866327180140039,
      "grad_norm": 4.712013244628906,
      "learning_rate": 0.0005816,
      "loss": 1.4636,
      "step": 1550
    },
    {
      "epoch": 1.0184595798854232,
      "grad_norm": 2.6126997470855713,
      "learning_rate": 0.0005616,
      "loss": 4.7321,
      "step": 1600
    },
    {
      "epoch": 1.0502864417568427,
      "grad_norm": 3.412630081176758,
      "learning_rate": 0.0005415999999999999,
      "loss": 1.2998,
      "step": 1650
    },
    {
      "epoch": 1.0821133036282622,
      "grad_norm": 2.7424678802490234,
      "learning_rate": 0.0005216,
      "loss": 1.195,
      "step": 1700
    },
    {
      "epoch": 1.1139401654996817,
      "grad_norm": 3.5848751068115234,
      "learning_rate": 0.0005016,
      "loss": 1.2218,
      "step": 1750
    },
    {
      "epoch": 1.1457670273711011,
      "grad_norm": 2.7384583950042725,
      "learning_rate": 0.0004816,
      "loss": 1.3046,
      "step": 1800
    },
    {
      "epoch": 1.1775938892425206,
      "grad_norm": 2.96517014503479,
      "learning_rate": 0.0004616,
      "loss": 1.2655,
      "step": 1850
    },
    {
      "epoch": 1.20942075111394,
      "grad_norm": 2.840569019317627,
      "learning_rate": 0.0004416,
      "loss": 1.2773,
      "step": 1900
    },
    {
      "epoch": 1.2412476129853596,
      "grad_norm": 2.274104356765747,
      "learning_rate": 0.0004216,
      "loss": 1.2796,
      "step": 1950
    },
    {
      "epoch": 1.273074474856779,
      "grad_norm": 2.716576099395752,
      "learning_rate": 0.0004016,
      "loss": 1.2557,
      "step": 2000
    },
    {
      "epoch": 1.3049013367281985,
      "grad_norm": 2.3952882289886475,
      "learning_rate": 0.0003816,
      "loss": 1.2361,
      "step": 2050
    },
    {
      "epoch": 1.336728198599618,
      "grad_norm": 2.339120626449585,
      "learning_rate": 0.0003616,
      "loss": 1.2521,
      "step": 2100
    },
    {
      "epoch": 1.3685550604710375,
      "grad_norm": 1.7202666997909546,
      "learning_rate": 0.0003416,
      "loss": 1.1871,
      "step": 2150
    },
    {
      "epoch": 1.400381922342457,
      "grad_norm": 2.300281047821045,
      "learning_rate": 0.0003216,
      "loss": 1.2651,
      "step": 2200
    },
    {
      "epoch": 1.4322087842138764,
      "grad_norm": 2.3316917419433594,
      "learning_rate": 0.00030159999999999996,
      "loss": 1.2877,
      "step": 2250
    },
    {
      "epoch": 1.464035646085296,
      "grad_norm": 2.129770517349243,
      "learning_rate": 0.0002816,
      "loss": 1.2602,
      "step": 2300
    },
    {
      "epoch": 1.4958625079567156,
      "grad_norm": 2.535768985748291,
      "learning_rate": 0.0002616,
      "loss": 1.1199,
      "step": 2350
    },
    {
      "epoch": 1.5276893698281349,
      "grad_norm": 2.796251058578491,
      "learning_rate": 0.00024160000000000002,
      "loss": 1.0819,
      "step": 2400
    },
    {
      "epoch": 1.5595162316995546,
      "grad_norm": 1.9928622245788574,
      "learning_rate": 0.0002216,
      "loss": 1.2256,
      "step": 2450
    },
    {
      "epoch": 1.5913430935709738,
      "grad_norm": 2.5305280685424805,
      "learning_rate": 0.0002016,
      "loss": 1.1779,
      "step": 2500
    },
    {
      "epoch": 1.6231699554423935,
      "grad_norm": 2.4409801959991455,
      "learning_rate": 0.00018160000000000002,
      "loss": 1.1402,
      "step": 2550
    },
    {
      "epoch": 1.6549968173138128,
      "grad_norm": 3.104377508163452,
      "learning_rate": 0.0001616,
      "loss": 1.1137,
      "step": 2600
    },
    {
      "epoch": 1.6868236791852325,
      "grad_norm": 3.3948237895965576,
      "learning_rate": 0.0001416,
      "loss": 1.1848,
      "step": 2650
    },
    {
      "epoch": 1.7186505410566517,
      "grad_norm": 1.9620765447616577,
      "learning_rate": 0.0001216,
      "loss": 1.1042,
      "step": 2700
    },
    {
      "epoch": 1.7504774029280714,
      "grad_norm": 2.440648317337036,
      "learning_rate": 0.0001016,
      "loss": 1.1262,
      "step": 2750
    },
    {
      "epoch": 1.7823042647994907,
      "grad_norm": 2.4610586166381836,
      "learning_rate": 8.16e-05,
      "loss": 1.1311,
      "step": 2800
    },
    {
      "epoch": 1.8141311266709104,
      "grad_norm": 1.8200007677078247,
      "learning_rate": 6.16e-05,
      "loss": 1.1016,
      "step": 2850
    },
    {
      "epoch": 1.8459579885423296,
      "grad_norm": 2.5204851627349854,
      "learning_rate": 4.16e-05,
      "loss": 1.103,
      "step": 2900
    },
    {
      "epoch": 1.8777848504137493,
      "grad_norm": 2.1061391830444336,
      "learning_rate": 2.1600000000000003e-05,
      "loss": 1.1638,
      "step": 2950
    },
    {
      "epoch": 1.9096117122851686,
      "grad_norm": 2.113422155380249,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 1.1559,
      "step": 3000
    }
  ],
  "logging_steps": 50,
  "max_steps": 3000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.04718078640128e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
