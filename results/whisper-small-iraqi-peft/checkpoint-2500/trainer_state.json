{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.5913430935709738,
  "eval_steps": 500,
  "global_step": 2500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.031826861871419476,
      "grad_norm": 1.5820187330245972,
      "learning_rate": 9.800000000000001e-05,
      "loss": 4.0405,
      "step": 50
    },
    {
      "epoch": 0.06365372374283895,
      "grad_norm": 1.904404640197754,
      "learning_rate": 0.00019800000000000002,
      "loss": 2.3521,
      "step": 100
    },
    {
      "epoch": 0.09548058561425843,
      "grad_norm": 1.8472228050231934,
      "learning_rate": 0.000298,
      "loss": 1.8739,
      "step": 150
    },
    {
      "epoch": 0.1273074474856779,
      "grad_norm": 1.809281349182129,
      "learning_rate": 0.000398,
      "loss": 1.6028,
      "step": 200
    },
    {
      "epoch": 0.15913430935709738,
      "grad_norm": 2.4066054821014404,
      "learning_rate": 0.000498,
      "loss": 1.6139,
      "step": 250
    },
    {
      "epoch": 0.19096117122851686,
      "grad_norm": 1.9138623476028442,
      "learning_rate": 0.000598,
      "loss": 1.5428,
      "step": 300
    },
    {
      "epoch": 0.22278803309993633,
      "grad_norm": 2.823643684387207,
      "learning_rate": 0.0006979999999999999,
      "loss": 1.5447,
      "step": 350
    },
    {
      "epoch": 0.2546148949713558,
      "grad_norm": 2.5078649520874023,
      "learning_rate": 0.0007980000000000001,
      "loss": 1.5841,
      "step": 400
    },
    {
      "epoch": 0.2864417568427753,
      "grad_norm": 2.4785566329956055,
      "learning_rate": 0.000898,
      "loss": 1.5721,
      "step": 450
    },
    {
      "epoch": 0.31826861871419476,
      "grad_norm": 2.998387575149536,
      "learning_rate": 0.000998,
      "loss": 1.6398,
      "step": 500
    },
    {
      "epoch": 0.35009548058561424,
      "grad_norm": 3.1361827850341797,
      "learning_rate": 0.0009804,
      "loss": 1.6314,
      "step": 550
    },
    {
      "epoch": 0.3819223424570337,
      "grad_norm": 2.2821602821350098,
      "learning_rate": 0.0009604,
      "loss": 1.6639,
      "step": 600
    },
    {
      "epoch": 0.4137492043284532,
      "grad_norm": 2.718041181564331,
      "learning_rate": 0.0009404,
      "loss": 1.5433,
      "step": 650
    },
    {
      "epoch": 0.44557606619987267,
      "grad_norm": 3.1967644691467285,
      "learning_rate": 0.0009204,
      "loss": 1.5891,
      "step": 700
    },
    {
      "epoch": 0.47740292807129214,
      "grad_norm": 3.449985980987549,
      "learning_rate": 0.0009004,
      "loss": 1.6677,
      "step": 750
    },
    {
      "epoch": 0.5092297899427116,
      "grad_norm": 2.5075254440307617,
      "learning_rate": 0.0008803999999999999,
      "loss": 1.611,
      "step": 800
    },
    {
      "epoch": 0.5410566518141311,
      "grad_norm": 2.6311752796173096,
      "learning_rate": 0.0008604000000000001,
      "loss": 1.5138,
      "step": 850
    },
    {
      "epoch": 0.5728835136855506,
      "grad_norm": 3.1396870613098145,
      "learning_rate": 0.0008404,
      "loss": 1.5476,
      "step": 900
    },
    {
      "epoch": 0.60471037555697,
      "grad_norm": 3.062411308288574,
      "learning_rate": 0.0008204,
      "loss": 1.5499,
      "step": 950
    },
    {
      "epoch": 0.6365372374283895,
      "grad_norm": 2.5829408168792725,
      "learning_rate": 0.0008004,
      "loss": 1.6419,
      "step": 1000
    },
    {
      "epoch": 0.668364099299809,
      "grad_norm": 2.355818510055542,
      "learning_rate": 0.0007804,
      "loss": 1.4325,
      "step": 1050
    },
    {
      "epoch": 0.7001909611712285,
      "grad_norm": 3.6431100368499756,
      "learning_rate": 0.0007603999999999999,
      "loss": 1.5251,
      "step": 1100
    },
    {
      "epoch": 0.732017823042648,
      "grad_norm": 2.214449167251587,
      "learning_rate": 0.0007404,
      "loss": 1.557,
      "step": 1150
    },
    {
      "epoch": 0.7638446849140674,
      "grad_norm": 2.176091432571411,
      "learning_rate": 0.0007204000000000001,
      "loss": 1.5707,
      "step": 1200
    },
    {
      "epoch": 0.7956715467854869,
      "grad_norm": 3.3383936882019043,
      "learning_rate": 0.0007004,
      "loss": 1.554,
      "step": 1250
    },
    {
      "epoch": 0.8274984086569064,
      "grad_norm": 2.1603446006774902,
      "learning_rate": 0.0006804000000000001,
      "loss": 1.5212,
      "step": 1300
    },
    {
      "epoch": 0.8593252705283259,
      "grad_norm": 2.8484110832214355,
      "learning_rate": 0.0006604,
      "loss": 1.5099,
      "step": 1350
    },
    {
      "epoch": 0.8911521323997453,
      "grad_norm": 3.695148468017578,
      "learning_rate": 0.0006408000000000001,
      "loss": 1.4208,
      "step": 1400
    },
    {
      "epoch": 0.9229789942711648,
      "grad_norm": 2.3245561122894287,
      "learning_rate": 0.0006208,
      "loss": 1.4866,
      "step": 1450
    },
    {
      "epoch": 0.9548058561425843,
      "grad_norm": 2.7197930812835693,
      "learning_rate": 0.0006008,
      "loss": 1.4767,
      "step": 1500
    },
    {
      "epoch": 0.9866327180140039,
      "grad_norm": 3.850795269012451,
      "learning_rate": 0.0005808,
      "loss": 1.4354,
      "step": 1550
    },
    {
      "epoch": 1.0184595798854232,
      "grad_norm": 3.3986454010009766,
      "learning_rate": 0.0005608,
      "loss": 1.3696,
      "step": 1600
    },
    {
      "epoch": 1.0502864417568427,
      "grad_norm": 2.23772931098938,
      "learning_rate": 0.0005407999999999999,
      "loss": 1.1955,
      "step": 1650
    },
    {
      "epoch": 1.0821133036282622,
      "grad_norm": 3.4250988960266113,
      "learning_rate": 0.0005208000000000001,
      "loss": 1.2577,
      "step": 1700
    },
    {
      "epoch": 1.1139401654996817,
      "grad_norm": 2.735074281692505,
      "learning_rate": 0.0005008,
      "loss": 1.2379,
      "step": 1750
    },
    {
      "epoch": 1.1457670273711011,
      "grad_norm": 2.4683825969696045,
      "learning_rate": 0.00048080000000000003,
      "loss": 1.2876,
      "step": 1800
    },
    {
      "epoch": 1.1775938892425206,
      "grad_norm": 3.1274940967559814,
      "learning_rate": 0.0004608,
      "loss": 1.1902,
      "step": 1850
    },
    {
      "epoch": 1.20942075111394,
      "grad_norm": 2.1979575157165527,
      "learning_rate": 0.00044080000000000004,
      "loss": 1.2191,
      "step": 1900
    },
    {
      "epoch": 1.2412476129853596,
      "grad_norm": 2.2832889556884766,
      "learning_rate": 0.00042080000000000004,
      "loss": 1.2457,
      "step": 1950
    },
    {
      "epoch": 1.273074474856779,
      "grad_norm": 1.5621610879898071,
      "learning_rate": 0.0004008,
      "loss": 1.2738,
      "step": 2000
    },
    {
      "epoch": 1.3049013367281985,
      "grad_norm": 2.4688303470611572,
      "learning_rate": 0.00038080000000000004,
      "loss": 1.1585,
      "step": 2050
    },
    {
      "epoch": 1.336728198599618,
      "grad_norm": 2.019928455352783,
      "learning_rate": 0.00036080000000000004,
      "loss": 1.1947,
      "step": 2100
    },
    {
      "epoch": 1.3685550604710375,
      "grad_norm": 2.3717539310455322,
      "learning_rate": 0.0003408,
      "loss": 1.138,
      "step": 2150
    },
    {
      "epoch": 1.400381922342457,
      "grad_norm": 2.498134136199951,
      "learning_rate": 0.0003208,
      "loss": 1.2248,
      "step": 2200
    },
    {
      "epoch": 1.4322087842138764,
      "grad_norm": 2.9699833393096924,
      "learning_rate": 0.0003008,
      "loss": 1.2028,
      "step": 2250
    },
    {
      "epoch": 1.464035646085296,
      "grad_norm": 2.4898431301116943,
      "learning_rate": 0.0002808,
      "loss": 1.1785,
      "step": 2300
    },
    {
      "epoch": 1.4958625079567156,
      "grad_norm": 2.557583808898926,
      "learning_rate": 0.0002608,
      "loss": 1.2214,
      "step": 2350
    },
    {
      "epoch": 1.5276893698281349,
      "grad_norm": 2.7180800437927246,
      "learning_rate": 0.0002408,
      "loss": 1.1899,
      "step": 2400
    },
    {
      "epoch": 1.5595162316995546,
      "grad_norm": 2.729390859603882,
      "learning_rate": 0.0002208,
      "loss": 1.2217,
      "step": 2450
    },
    {
      "epoch": 1.5913430935709738,
      "grad_norm": 2.1300339698791504,
      "learning_rate": 0.0002008,
      "loss": 1.1806,
      "step": 2500
    }
  ],
  "logging_steps": 50,
  "max_steps": 3000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.87245486768128e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
