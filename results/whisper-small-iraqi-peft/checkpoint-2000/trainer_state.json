{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.273074474856779,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.031826861871419476,
      "grad_norm": 1.5943409204483032,
      "learning_rate": 9.6e-05,
      "loss": 4.0686,
      "step": 50
    },
    {
      "epoch": 0.06365372374283895,
      "grad_norm": 1.8983619213104248,
      "learning_rate": 0.00019600000000000002,
      "loss": 2.3555,
      "step": 100
    },
    {
      "epoch": 0.09548058561425843,
      "grad_norm": 1.7474476099014282,
      "learning_rate": 0.000296,
      "loss": 1.879,
      "step": 150
    },
    {
      "epoch": 0.1273074474856779,
      "grad_norm": 1.6382814645767212,
      "learning_rate": 0.00039600000000000003,
      "loss": 1.6018,
      "step": 200
    },
    {
      "epoch": 0.15913430935709738,
      "grad_norm": 2.525465488433838,
      "learning_rate": 0.000496,
      "loss": 1.6165,
      "step": 250
    },
    {
      "epoch": 0.19096117122851686,
      "grad_norm": 2.1450462341308594,
      "learning_rate": 0.000596,
      "loss": 1.5403,
      "step": 300
    },
    {
      "epoch": 0.22278803309993633,
      "grad_norm": 2.6311590671539307,
      "learning_rate": 0.000696,
      "loss": 1.5407,
      "step": 350
    },
    {
      "epoch": 0.2546148949713558,
      "grad_norm": 2.304661273956299,
      "learning_rate": 0.000796,
      "loss": 1.5796,
      "step": 400
    },
    {
      "epoch": 0.2864417568427753,
      "grad_norm": 2.0329365730285645,
      "learning_rate": 0.000894,
      "loss": 1.5757,
      "step": 450
    },
    {
      "epoch": 0.31826861871419476,
      "grad_norm": 3.121371030807495,
      "learning_rate": 0.000994,
      "loss": 1.6437,
      "step": 500
    },
    {
      "epoch": 0.35009548058561424,
      "grad_norm": 2.762888193130493,
      "learning_rate": 0.0009812,
      "loss": 1.5997,
      "step": 550
    },
    {
      "epoch": 0.3819223424570337,
      "grad_norm": 2.437708616256714,
      "learning_rate": 0.0009612,
      "loss": 1.6681,
      "step": 600
    },
    {
      "epoch": 0.4137492043284532,
      "grad_norm": 2.715770959854126,
      "learning_rate": 0.0009412000000000001,
      "loss": 1.555,
      "step": 650
    },
    {
      "epoch": 0.44557606619987267,
      "grad_norm": 2.631337881088257,
      "learning_rate": 0.0009212000000000001,
      "loss": 1.5714,
      "step": 700
    },
    {
      "epoch": 0.47740292807129214,
      "grad_norm": 3.9023361206054688,
      "learning_rate": 0.0009012,
      "loss": 1.649,
      "step": 750
    },
    {
      "epoch": 0.5092297899427116,
      "grad_norm": 2.6285359859466553,
      "learning_rate": 0.0008812,
      "loss": 1.5848,
      "step": 800
    },
    {
      "epoch": 0.5410566518141311,
      "grad_norm": 3.590073585510254,
      "learning_rate": 0.0008612,
      "loss": 1.5154,
      "step": 850
    },
    {
      "epoch": 0.5728835136855506,
      "grad_norm": 3.246530532836914,
      "learning_rate": 0.0008412,
      "loss": 1.5554,
      "step": 900
    },
    {
      "epoch": 0.60471037555697,
      "grad_norm": 2.690692186355591,
      "learning_rate": 0.0008212,
      "loss": 1.5448,
      "step": 950
    },
    {
      "epoch": 0.6365372374283895,
      "grad_norm": 2.8881607055664062,
      "learning_rate": 0.0008012000000000001,
      "loss": 1.6429,
      "step": 1000
    },
    {
      "epoch": 0.668364099299809,
      "grad_norm": 2.2572617530822754,
      "learning_rate": 0.0007812,
      "loss": 1.4491,
      "step": 1050
    },
    {
      "epoch": 0.7001909611712285,
      "grad_norm": 3.6326534748077393,
      "learning_rate": 0.0007612,
      "loss": 1.5183,
      "step": 1100
    },
    {
      "epoch": 0.732017823042648,
      "grad_norm": 2.3707926273345947,
      "learning_rate": 0.0007412,
      "loss": 1.5524,
      "step": 1150
    },
    {
      "epoch": 0.7638446849140674,
      "grad_norm": 2.4133715629577637,
      "learning_rate": 0.0007212,
      "loss": 1.5727,
      "step": 1200
    },
    {
      "epoch": 0.7956715467854869,
      "grad_norm": 3.0379152297973633,
      "learning_rate": 0.0007012,
      "loss": 1.5545,
      "step": 1250
    },
    {
      "epoch": 0.8274984086569064,
      "grad_norm": 1.9120861291885376,
      "learning_rate": 0.0006812000000000001,
      "loss": 1.5221,
      "step": 1300
    },
    {
      "epoch": 0.8593252705283259,
      "grad_norm": 3.481346368789673,
      "learning_rate": 0.0006612,
      "loss": 1.5095,
      "step": 1350
    },
    {
      "epoch": 0.8911521323997453,
      "grad_norm": 3.1546502113342285,
      "learning_rate": 0.0006412,
      "loss": 1.3945,
      "step": 1400
    },
    {
      "epoch": 0.9229789942711648,
      "grad_norm": 39.22539520263672,
      "learning_rate": 0.0006216,
      "loss": 5.3018,
      "step": 1450
    },
    {
      "epoch": 0.9548058561425843,
      "grad_norm": 0.7041285634040833,
      "learning_rate": 0.0006016,
      "loss": 4.8649,
      "step": 1500
    },
    {
      "epoch": 0.9866327180140039,
      "grad_norm": 3.460646867752075,
      "learning_rate": 0.0005816,
      "loss": 3.0748,
      "step": 1550
    },
    {
      "epoch": 1.0184595798854232,
      "grad_norm": 3.5177109241485596,
      "learning_rate": 0.0005616,
      "loss": 1.4528,
      "step": 1600
    },
    {
      "epoch": 1.0502864417568427,
      "grad_norm": 2.245285987854004,
      "learning_rate": 0.0005415999999999999,
      "loss": 1.2574,
      "step": 1650
    },
    {
      "epoch": 1.0821133036282622,
      "grad_norm": 5.088410377502441,
      "learning_rate": 0.0005216,
      "loss": 1.3221,
      "step": 1700
    },
    {
      "epoch": 1.1139401654996817,
      "grad_norm": 3.041205406188965,
      "learning_rate": 0.0005016,
      "loss": 1.2959,
      "step": 1750
    },
    {
      "epoch": 1.1457670273711011,
      "grad_norm": 2.8244664669036865,
      "learning_rate": 0.0004816,
      "loss": 1.3446,
      "step": 1800
    },
    {
      "epoch": 1.1775938892425206,
      "grad_norm": 2.8642232418060303,
      "learning_rate": 0.0004616,
      "loss": 1.226,
      "step": 1850
    },
    {
      "epoch": 1.20942075111394,
      "grad_norm": 2.4229557514190674,
      "learning_rate": 0.0004416,
      "loss": 1.2448,
      "step": 1900
    },
    {
      "epoch": 1.2412476129853596,
      "grad_norm": 2.926873207092285,
      "learning_rate": 0.0004216,
      "loss": 1.2737,
      "step": 1950
    },
    {
      "epoch": 1.273074474856779,
      "grad_norm": 1.5307776927947998,
      "learning_rate": 0.0004016,
      "loss": 1.3161,
      "step": 2000
    }
  ],
  "logging_steps": 50,
  "max_steps": 3000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.69772894896128e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
