{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.273074474856779,
  "eval_steps": 500,
  "global_step": 2000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.031826861871419476,
      "grad_norm": 1.611085057258606,
      "learning_rate": 9.6e-05,
      "loss": 4.0485,
      "step": 50
    },
    {
      "epoch": 0.06365372374283895,
      "grad_norm": 1.9300265312194824,
      "learning_rate": 0.00019600000000000002,
      "loss": 2.3584,
      "step": 100
    },
    {
      "epoch": 0.09548058561425843,
      "grad_norm": 1.8525071144104004,
      "learning_rate": 0.000296,
      "loss": 1.8984,
      "step": 150
    },
    {
      "epoch": 0.1273074474856779,
      "grad_norm": 1.6883834600448608,
      "learning_rate": 0.00039600000000000003,
      "loss": 1.6001,
      "step": 200
    },
    {
      "epoch": 0.15913430935709738,
      "grad_norm": 2.50492262840271,
      "learning_rate": 0.000496,
      "loss": 1.6141,
      "step": 250
    },
    {
      "epoch": 0.19096117122851686,
      "grad_norm": 1.921800971031189,
      "learning_rate": 0.000596,
      "loss": 1.5453,
      "step": 300
    },
    {
      "epoch": 0.22278803309993633,
      "grad_norm": 2.8003687858581543,
      "learning_rate": 0.000696,
      "loss": 1.5413,
      "step": 350
    },
    {
      "epoch": 0.2546148949713558,
      "grad_norm": NaN,
      "learning_rate": 0.00079,
      "loss": 2.0748,
      "step": 400
    },
    {
      "epoch": 0.2864417568427753,
      "grad_norm": 3.4802634716033936,
      "learning_rate": 0.0008900000000000001,
      "loss": 7.4272,
      "step": 450
    },
    {
      "epoch": 0.31826861871419476,
      "grad_norm": 1.0975773334503174,
      "learning_rate": 0.00099,
      "loss": 4.574,
      "step": 500
    },
    {
      "epoch": 0.35009548058561424,
      "grad_norm": 0.887409508228302,
      "learning_rate": 0.000982,
      "loss": 4.4379,
      "step": 550
    },
    {
      "epoch": 0.3819223424570337,
      "grad_norm": 2.0327980518341064,
      "learning_rate": 0.000962,
      "loss": 4.4485,
      "step": 600
    },
    {
      "epoch": 0.4137492043284532,
      "grad_norm": 2.105642795562744,
      "learning_rate": 0.000942,
      "loss": 4.3574,
      "step": 650
    },
    {
      "epoch": 0.44557606619987267,
      "grad_norm": 1.355385184288025,
      "learning_rate": 0.0009220000000000001,
      "loss": 4.3451,
      "step": 700
    },
    {
      "epoch": 0.47740292807129214,
      "grad_norm": 0.9521009922027588,
      "learning_rate": 0.000902,
      "loss": 4.2852,
      "step": 750
    },
    {
      "epoch": 0.5092297899427116,
      "grad_norm": 0.7742440104484558,
      "learning_rate": 0.000882,
      "loss": 4.2381,
      "step": 800
    },
    {
      "epoch": 0.5410566518141311,
      "grad_norm": 0.8731873035430908,
      "learning_rate": 0.000862,
      "loss": 4.3818,
      "step": 850
    },
    {
      "epoch": 0.5728835136855506,
      "grad_norm": 0.6480379104614258,
      "learning_rate": 0.000842,
      "loss": 4.2134,
      "step": 900
    },
    {
      "epoch": 0.60471037555697,
      "grad_norm": 0.7972712516784668,
      "learning_rate": 0.0008219999999999999,
      "loss": 4.1811,
      "step": 950
    },
    {
      "epoch": 0.6365372374283895,
      "grad_norm": 0.670138955116272,
      "learning_rate": 0.0008020000000000001,
      "loss": 4.0966,
      "step": 1000
    },
    {
      "epoch": 0.668364099299809,
      "grad_norm": 1.0028945207595825,
      "learning_rate": 0.000782,
      "loss": 4.1028,
      "step": 1050
    },
    {
      "epoch": 0.7001909611712285,
      "grad_norm": 0.8432509899139404,
      "learning_rate": 0.000762,
      "loss": 4.1085,
      "step": 1100
    },
    {
      "epoch": 0.732017823042648,
      "grad_norm": 0.9325047135353088,
      "learning_rate": 0.000742,
      "loss": 3.9875,
      "step": 1150
    },
    {
      "epoch": 0.7638446849140674,
      "grad_norm": 1.0563809871673584,
      "learning_rate": 0.000722,
      "loss": 3.9786,
      "step": 1200
    },
    {
      "epoch": 0.7956715467854869,
      "grad_norm": 0.9181821346282959,
      "learning_rate": 0.0007019999999999999,
      "loss": 3.975,
      "step": 1250
    },
    {
      "epoch": 0.8274984086569064,
      "grad_norm": 1.2548397779464722,
      "learning_rate": 0.0006820000000000001,
      "loss": 3.909,
      "step": 1300
    },
    {
      "epoch": 0.8593252705283259,
      "grad_norm": 1.0012025833129883,
      "learning_rate": 0.000662,
      "loss": 3.8722,
      "step": 1350
    },
    {
      "epoch": 0.8911521323997453,
      "grad_norm": 1.147944450378418,
      "learning_rate": 0.000642,
      "loss": 3.8586,
      "step": 1400
    },
    {
      "epoch": 0.9229789942711648,
      "grad_norm": 24.051029205322266,
      "learning_rate": 0.000622,
      "loss": 3.8884,
      "step": 1450
    },
    {
      "epoch": 0.9548058561425843,
      "grad_norm": 1.1696157455444336,
      "learning_rate": 0.000602,
      "loss": 3.9084,
      "step": 1500
    },
    {
      "epoch": 0.9866327180140039,
      "grad_norm": 1.4156063795089722,
      "learning_rate": 0.0005819999999999999,
      "loss": 3.8504,
      "step": 1550
    },
    {
      "epoch": 1.0184595798854232,
      "grad_norm": 1.3064062595367432,
      "learning_rate": 0.0005620000000000001,
      "loss": 3.7309,
      "step": 1600
    },
    {
      "epoch": 1.0502864417568427,
      "grad_norm": 1.1466727256774902,
      "learning_rate": 0.0005420000000000001,
      "loss": 3.7712,
      "step": 1650
    },
    {
      "epoch": 1.0821133036282622,
      "grad_norm": 1.1081433296203613,
      "learning_rate": 0.000522,
      "loss": 3.7503,
      "step": 1700
    },
    {
      "epoch": 1.1139401654996817,
      "grad_norm": 1.1547672748565674,
      "learning_rate": 0.0005020000000000001,
      "loss": 3.7524,
      "step": 1750
    },
    {
      "epoch": 1.1457670273711011,
      "grad_norm": 1.1653021574020386,
      "learning_rate": 0.000482,
      "loss": 3.6554,
      "step": 1800
    },
    {
      "epoch": 1.1775938892425206,
      "grad_norm": 1.207334280014038,
      "learning_rate": 0.000462,
      "loss": 3.645,
      "step": 1850
    },
    {
      "epoch": 1.20942075111394,
      "grad_norm": 1.0975010395050049,
      "learning_rate": 0.000442,
      "loss": 3.6151,
      "step": 1900
    },
    {
      "epoch": 1.2412476129853596,
      "grad_norm": 1.2215875387191772,
      "learning_rate": 0.000422,
      "loss": 3.6658,
      "step": 1950
    },
    {
      "epoch": 1.273074474856779,
      "grad_norm": 0.9549890160560608,
      "learning_rate": 0.000402,
      "loss": 3.6338,
      "step": 2000
    }
  ],
  "logging_steps": 50,
  "max_steps": 3000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.69772894896128e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
