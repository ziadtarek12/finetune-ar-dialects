[
  {
    "loss": 4.3134,
    "grad_norm": 2.7976720333099365,
    "learning_rate": 9.6e-05,
    "epoch": 0.01849112426035503,
    "step": 50
  },
  {
    "loss": 2.4012,
    "grad_norm": 2.151355743408203,
    "learning_rate": 0.00019600000000000002,
    "epoch": 0.03698224852071006,
    "step": 100
  },
  {
    "loss": 1.8227,
    "grad_norm": 2.023808240890503,
    "learning_rate": 0.000296,
    "epoch": 0.05547337278106509,
    "step": 150
  },
  {
    "loss": 1.5713,
    "grad_norm": 2.073826789855957,
    "learning_rate": 0.00039600000000000003,
    "epoch": 0.07396449704142012,
    "step": 200
  },
  {
    "loss": 1.6317,
    "grad_norm": 2.0432043075561523,
    "learning_rate": 0.000496,
    "epoch": 0.09245562130177515,
    "step": 250
  },
  {
    "loss": 1.5324,
    "grad_norm": 2.4722559452056885,
    "learning_rate": 0.000596,
    "epoch": 0.11094674556213018,
    "step": 300
  },
  {
    "loss": 1.5081,
    "grad_norm": 2.4057281017303467,
    "learning_rate": 0.000696,
    "epoch": 0.1294378698224852,
    "step": 350
  },
  {
    "loss": 1.4497,
    "grad_norm": 3.16078519821167,
    "learning_rate": 0.000796,
    "epoch": 0.14792899408284024,
    "step": 400
  },
  {
    "loss": 1.5521,
    "grad_norm": 2.8102798461914062,
    "learning_rate": 0.000896,
    "epoch": 0.16642011834319526,
    "step": 450
  },
  {
    "loss": 1.6399,
    "grad_norm": 2.536130666732788,
    "learning_rate": 0.000996,
    "epoch": 0.1849112426035503,
    "step": 500
  },
  {
    "loss": 1.6521,
    "grad_norm": 3.4523141384124756,
    "learning_rate": 0.0009862857142857143,
    "epoch": 0.20340236686390534,
    "step": 550
  },
  {
    "loss": 1.5898,
    "grad_norm": 3.5822482109069824,
    "learning_rate": 0.000972,
    "epoch": 0.22189349112426035,
    "step": 600
  },
  {
    "loss": 1.6351,
    "grad_norm": 3.7636935710906982,
    "learning_rate": 0.0009577142857142858,
    "epoch": 0.2403846153846154,
    "step": 650
  },
  {
    "loss": 1.6387,
    "grad_norm": 2.8418917655944824,
    "learning_rate": 0.0009434285714285714,
    "epoch": 0.2588757396449704,
    "step": 700
  },
  {
    "loss": 1.6003,
    "grad_norm": 2.9332752227783203,
    "learning_rate": 0.0009291428571428572,
    "epoch": 0.27736686390532544,
    "step": 750
  },
  {
    "loss": 1.5091,
    "grad_norm": 3.1715898513793945,
    "learning_rate": 0.0009148571428571428,
    "epoch": 0.2958579881656805,
    "step": 800
  },
  {
    "loss": 1.5764,
    "grad_norm": 3.1560285091400146,
    "learning_rate": 0.0009005714285714286,
    "epoch": 0.3143491124260355,
    "step": 850
  },
  {
    "loss": 1.6068,
    "grad_norm": 3.018925666809082,
    "learning_rate": 0.0008862857142857142,
    "epoch": 0.3328402366863905,
    "step": 900
  },
  {
    "loss": 1.464,
    "grad_norm": 2.921642541885376,
    "learning_rate": 0.000872,
    "epoch": 0.35133136094674555,
    "step": 950
  },
  {
    "loss": 1.4703,
    "grad_norm": 3.7011539936065674,
    "learning_rate": 0.0008577142857142858,
    "epoch": 0.3698224852071006,
    "step": 1000
  },
  {
    "loss": 1.5806,
    "grad_norm": 3.271251916885376,
    "learning_rate": 0.0008434285714285715,
    "epoch": 0.38831360946745563,
    "step": 1050
  },
  {
    "loss": 1.5126,
    "grad_norm": 2.855271577835083,
    "learning_rate": 0.0008291428571428572,
    "epoch": 0.4068047337278107,
    "step": 1100
  },
  {
    "loss": 1.5719,
    "grad_norm": 3.048367738723755,
    "learning_rate": 0.0008148571428571429,
    "epoch": 0.42529585798816566,
    "step": 1150
  },
  {
    "loss": 1.602,
    "grad_norm": 2.67396879196167,
    "learning_rate": 0.0008005714285714286,
    "epoch": 0.4437869822485207,
    "step": 1200
  },
  {
    "loss": 1.5395,
    "grad_norm": 2.9074501991271973,
    "learning_rate": 0.0007862857142857143,
    "epoch": 0.46227810650887574,
    "step": 1250
  },
  {
    "loss": 1.6061,
    "grad_norm": 3.29079008102417,
    "learning_rate": 0.000772,
    "epoch": 0.4807692307692308,
    "step": 1300
  },
  {
    "loss": 1.5607,
    "grad_norm": 3.044417381286621,
    "learning_rate": 0.0007577142857142857,
    "epoch": 0.4992603550295858,
    "step": 1350
  },
  {
    "loss": 1.4633,
    "grad_norm": 2.895867347717285,
    "learning_rate": 0.0007434285714285714,
    "epoch": 0.5177514792899408,
    "step": 1400
  },
  {
    "loss": 1.5142,
    "grad_norm": 3.0643701553344727,
    "learning_rate": 0.0007291428571428571,
    "epoch": 0.5362426035502958,
    "step": 1450
  },
  {
    "loss": 1.5791,
    "grad_norm": 2.7345492839813232,
    "learning_rate": 0.0007148571428571428,
    "epoch": 0.5547337278106509,
    "step": 1500
  },
  {
    "loss": 1.4776,
    "grad_norm": 3.3671696186065674,
    "learning_rate": 0.0007005714285714287,
    "epoch": 0.5732248520710059,
    "step": 1550
  },
  {
    "loss": 1.348,
    "grad_norm": 2.2888295650482178,
    "learning_rate": 0.0006862857142857143,
    "epoch": 0.591715976331361,
    "step": 1600
  },
  {
    "loss": 1.5805,
    "grad_norm": 3.4559097290039062,
    "learning_rate": 0.0006720000000000001,
    "epoch": 0.610207100591716,
    "step": 1650
  },
  {
    "loss": 1.5188,
    "grad_norm": 3.948923110961914,
    "learning_rate": 0.0006577142857142857,
    "epoch": 0.628698224852071,
    "step": 1700
  },
  {
    "loss": 1.5158,
    "grad_norm": 3.229353666305542,
    "learning_rate": 0.0006434285714285715,
    "epoch": 0.647189349112426,
    "step": 1750
  },
  {
    "loss": 1.3871,
    "grad_norm": 3.1202046871185303,
    "learning_rate": 0.0006291428571428571,
    "epoch": 0.665680473372781,
    "step": 1800
  },
  {
    "loss": 1.4062,
    "grad_norm": 3.3111515045166016,
    "learning_rate": 0.0006148571428571429,
    "epoch": 0.6841715976331361,
    "step": 1850
  },
  {
    "loss": 1.4881,
    "grad_norm": 2.993668794631958,
    "learning_rate": 0.0006005714285714285,
    "epoch": 0.7026627218934911,
    "step": 1900
  },
  {
    "loss": 1.4474,
    "grad_norm": 2.9445605278015137,
    "learning_rate": 0.0005862857142857143,
    "epoch": 0.7211538461538461,
    "step": 1950
  },
  {
    "loss": 1.4619,
    "grad_norm": 3.076227903366089,
    "learning_rate": 0.0005719999999999999,
    "epoch": 0.7396449704142012,
    "step": 2000
  },
  {
    "loss": 1.5023,
    "grad_norm": 2.282149314880371,
    "learning_rate": 0.0005577142857142857,
    "epoch": 0.7581360946745562,
    "step": 2050
  },
  {
    "loss": 1.42,
    "grad_norm": 2.3912572860717773,
    "learning_rate": 0.0005434285714285714,
    "epoch": 0.7766272189349113,
    "step": 2100
  },
  {
    "loss": 1.4103,
    "grad_norm": 2.8569419384002686,
    "learning_rate": 0.0005291428571428571,
    "epoch": 0.7951183431952663,
    "step": 2150
  },
  {
    "loss": 1.4502,
    "grad_norm": 3.159327745437622,
    "learning_rate": 0.000514857142857143,
    "epoch": 0.8136094674556213,
    "step": 2200
  },
  {
    "loss": 1.4673,
    "grad_norm": 2.5226731300354004,
    "learning_rate": 0.0005005714285714286,
    "epoch": 0.8321005917159763,
    "step": 2250
  },
  {
    "loss": 1.391,
    "grad_norm": 2.4161977767944336,
    "learning_rate": 0.00048628571428571427,
    "epoch": 0.8505917159763313,
    "step": 2300
  },
  {
    "loss": 1.4961,
    "grad_norm": 2.420924425125122,
    "learning_rate": 0.000472,
    "epoch": 0.8690828402366864,
    "step": 2350
  },
  {
    "loss": 1.3365,
    "grad_norm": 2.5059635639190674,
    "learning_rate": 0.00045771428571428574,
    "epoch": 0.8875739644970414,
    "step": 2400
  },
  {
    "loss": 1.3864,
    "grad_norm": 3.2006030082702637,
    "learning_rate": 0.00044342857142857145,
    "epoch": 0.9060650887573964,
    "step": 2450
  },
  {
    "loss": 1.4206,
    "grad_norm": 2.5645954608917236,
    "learning_rate": 0.00042914285714285716,
    "epoch": 0.9245562130177515,
    "step": 2500
  },
  {
    "loss": 1.3584,
    "grad_norm": 2.3473267555236816,
    "learning_rate": 0.00041485714285714287,
    "epoch": 0.9430473372781065,
    "step": 2550
  },
  {
    "loss": 1.3935,
    "grad_norm": 3.9825093746185303,
    "learning_rate": 0.0004005714285714286,
    "epoch": 0.9615384615384616,
    "step": 2600
  },
  {
    "loss": 1.3558,
    "grad_norm": 2.5463240146636963,
    "learning_rate": 0.0003862857142857143,
    "epoch": 0.9800295857988166,
    "step": 2650
  },
  {
    "loss": 1.3304,
    "grad_norm": 2.866536855697632,
    "learning_rate": 0.000372,
    "epoch": 0.9985207100591716,
    "step": 2700
  },
  {
    "loss": 1.1231,
    "grad_norm": 2.2250683307647705,
    "learning_rate": 0.0003577142857142857,
    "epoch": 1.0170118343195267,
    "step": 2750
  },
  {
    "loss": 1.1576,
    "grad_norm": 2.6872646808624268,
    "learning_rate": 0.0003434285714285714,
    "epoch": 1.0355029585798816,
    "step": 2800
  },
  {
    "loss": 1.2059,
    "grad_norm": 2.6000449657440186,
    "learning_rate": 0.0003291428571428571,
    "epoch": 1.0539940828402368,
    "step": 2850
  },
  {
    "loss": 1.0918,
    "grad_norm": 2.8199803829193115,
    "learning_rate": 0.0003148571428571428,
    "epoch": 1.0724852071005917,
    "step": 2900
  },
  {
    "loss": 1.17,
    "grad_norm": 2.1340861320495605,
    "learning_rate": 0.00030057142857142853,
    "epoch": 1.0909763313609468,
    "step": 2950
  },
  {
    "loss": 1.187,
    "grad_norm": 2.8569564819335938,
    "learning_rate": 0.0002862857142857143,
    "epoch": 1.1094674556213018,
    "step": 3000
  },
  {
    "loss": 1.1313,
    "grad_norm": 2.839970350265503,
    "learning_rate": 0.00027200000000000005,
    "epoch": 1.1279585798816567,
    "step": 3050
  },
  {
    "loss": 1.1667,
    "grad_norm": 3.0548481941223145,
    "learning_rate": 0.00025771428571428576,
    "epoch": 1.1464497041420119,
    "step": 3100
  },
  {
    "loss": 1.1884,
    "grad_norm": 2.844965696334839,
    "learning_rate": 0.00024342857142857144,
    "epoch": 1.1649408284023668,
    "step": 3150
  },
  {
    "loss": 1.0814,
    "grad_norm": 3.1097705364227295,
    "learning_rate": 0.00022914285714285715,
    "epoch": 1.183431952662722,
    "step": 3200
  },
  {
    "loss": 1.1674,
    "grad_norm": 2.4336514472961426,
    "learning_rate": 0.00021485714285714286,
    "epoch": 1.2019230769230769,
    "step": 3250
  },
  {
    "loss": 1.1175,
    "grad_norm": 2.1893672943115234,
    "learning_rate": 0.00020057142857142856,
    "epoch": 1.220414201183432,
    "step": 3300
  },
  {
    "loss": 1.1034,
    "grad_norm": 2.265367269515991,
    "learning_rate": 0.00018628571428571427,
    "epoch": 1.238905325443787,
    "step": 3350
  },
  {
    "loss": 1.1401,
    "grad_norm": 2.3958168029785156,
    "learning_rate": 0.00017199999999999998,
    "epoch": 1.2573964497041419,
    "step": 3400
  },
  {
    "loss": 1.114,
    "grad_norm": 2.369525671005249,
    "learning_rate": 0.00015771428571428571,
    "epoch": 1.275887573964497,
    "step": 3450
  },
  {
    "loss": 1.1433,
    "grad_norm": 2.6943717002868652,
    "learning_rate": 0.00014342857142857145,
    "epoch": 1.2943786982248522,
    "step": 3500
  },
  {
    "loss": 1.2674,
    "grad_norm": 2.7567033767700195,
    "learning_rate": 0.00012914285714285716,
    "epoch": 1.3128698224852071,
    "step": 3550
  },
  {
    "loss": 1.0853,
    "grad_norm": 2.2344727516174316,
    "learning_rate": 0.00011485714285714285,
    "epoch": 1.331360946745562,
    "step": 3600
  },
  {
    "loss": 1.1001,
    "grad_norm": 2.2974250316619873,
    "learning_rate": 0.00010057142857142857,
    "epoch": 1.3498520710059172,
    "step": 3650
  },
  {
    "loss": 1.1081,
    "grad_norm": 2.100893497467041,
    "learning_rate": 8.628571428571428e-05,
    "epoch": 1.3683431952662721,
    "step": 3700
  },
  {
    "loss": 0.9933,
    "grad_norm": 1.8749562501907349,
    "learning_rate": 7.2e-05,
    "epoch": 1.3868343195266273,
    "step": 3750
  },
  {
    "loss": 1.1661,
    "grad_norm": 2.4774394035339355,
    "learning_rate": 5.771428571428571e-05,
    "epoch": 1.4053254437869822,
    "step": 3800
  },
  {
    "loss": 1.1048,
    "grad_norm": 2.5162899494171143,
    "learning_rate": 4.342857142857143e-05,
    "epoch": 1.4238165680473374,
    "step": 3850
  },
  {
    "loss": 1.1246,
    "grad_norm": 1.8969367742538452,
    "learning_rate": 2.9142857142857146e-05,
    "epoch": 1.4423076923076923,
    "step": 3900
  },
  {
    "loss": 1.123,
    "grad_norm": 2.2918624877929688,
    "learning_rate": 1.4857142857142857e-05,
    "epoch": 1.4607988165680474,
    "step": 3950
  },
  {
    "loss": 1.0432,
    "grad_norm": 1.9997403621673584,
    "learning_rate": 5.714285714285715e-07,
    "epoch": 1.4792899408284024,
    "step": 4000
  },
  {
    "train_runtime": 12621.0659,
    "train_samples_per_second": 2.535,
    "train_steps_per_second": 0.317,
    "total_flos": 9.39692630532096e+18,
    "train_loss": 1.4306284036636352,
    "epoch": 1.4792899408284024,
    "step": 4000
  }
]