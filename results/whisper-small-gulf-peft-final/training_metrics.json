[
  {
    "loss": 4.2889,
    "grad_norm": 2.139329671859741,
    "learning_rate": 9.6e-05,
    "epoch": 0.01849112426035503,
    "step": 50
  },
  {
    "loss": 2.3763,
    "grad_norm": 2.54341459274292,
    "learning_rate": 0.00019600000000000002,
    "epoch": 0.03698224852071006,
    "step": 100
  },
  {
    "loss": 1.8681,
    "grad_norm": 1.8546984195709229,
    "learning_rate": 0.000296,
    "epoch": 0.05547337278106509,
    "step": 150
  },
  {
    "loss": 1.5156,
    "grad_norm": 2.2202508449554443,
    "learning_rate": 0.00039600000000000003,
    "epoch": 0.07396449704142012,
    "step": 200
  },
  {
    "loss": 1.5459,
    "grad_norm": 2.893281936645508,
    "learning_rate": 0.000496,
    "epoch": 0.09245562130177515,
    "step": 250
  },
  {
    "loss": 1.6052,
    "grad_norm": 2.5236055850982666,
    "learning_rate": 0.000596,
    "epoch": 0.11094674556213018,
    "step": 300
  },
  {
    "loss": 1.5168,
    "grad_norm": 2.4035696983337402,
    "learning_rate": 0.000696,
    "epoch": 0.1294378698224852,
    "step": 350
  },
  {
    "loss": 1.5843,
    "grad_norm": 3.361224412918091,
    "learning_rate": 0.000796,
    "epoch": 0.14792899408284024,
    "step": 400
  },
  {
    "loss": 1.5404,
    "grad_norm": 3.392230272293091,
    "learning_rate": 0.000896,
    "epoch": 0.16642011834319526,
    "step": 450
  },
  {
    "loss": 1.5968,
    "grad_norm": 2.7557873725891113,
    "learning_rate": 0.000996,
    "epoch": 0.1849112426035503,
    "step": 500
  },
  {
    "loss": 1.6449,
    "grad_norm": 3.737109661102295,
    "learning_rate": 0.0009862857142857143,
    "epoch": 0.20340236686390534,
    "step": 550
  },
  {
    "loss": 5.949,
    "grad_norm": 2.5864017009735107,
    "learning_rate": 0.0009722857142857144,
    "epoch": 0.22189349112426035,
    "step": 600
  },
  {
    "loss": 4.7568,
    "grad_norm": 0.8002440333366394,
    "learning_rate": 0.000958,
    "epoch": 0.2403846153846154,
    "step": 650
  },
  {
    "loss": 4.516,
    "grad_norm": 1.0704636573791504,
    "learning_rate": 0.0009437142857142858,
    "epoch": 0.2588757396449704,
    "step": 700
  },
  {
    "loss": 4.7004,
    "grad_norm": 1.1755808591842651,
    "learning_rate": 0.0009294285714285714,
    "epoch": 0.27736686390532544,
    "step": 750
  },
  {
    "loss": 4.4192,
    "grad_norm": 6.764094352722168,
    "learning_rate": 0.0009151428571428572,
    "epoch": 0.2958579881656805,
    "step": 800
  },
  {
    "loss": 4.5023,
    "grad_norm": 0.7135828137397766,
    "learning_rate": 0.0009008571428571429,
    "epoch": 0.3143491124260355,
    "step": 850
  },
  {
    "loss": 4.4805,
    "grad_norm": 0.5079736709594727,
    "learning_rate": 0.0008865714285714286,
    "epoch": 0.3328402366863905,
    "step": 900
  },
  {
    "loss": 4.4547,
    "grad_norm": 0.626338541507721,
    "learning_rate": 0.0008722857142857143,
    "epoch": 0.35133136094674555,
    "step": 950
  },
  {
    "loss": 4.4225,
    "grad_norm": 1.0897133350372314,
    "learning_rate": 0.000858,
    "epoch": 0.3698224852071006,
    "step": 1000
  },
  {
    "loss": 4.367,
    "grad_norm": 1.038453221321106,
    "learning_rate": 0.0008437142857142857,
    "epoch": 0.38831360946745563,
    "step": 1050
  },
  {
    "loss": 4.3167,
    "grad_norm": 0.4637073576450348,
    "learning_rate": 0.0008294285714285715,
    "epoch": 0.4068047337278107,
    "step": 1100
  },
  {
    "loss": 4.2663,
    "grad_norm": 0.6874340772628784,
    "learning_rate": 0.0008151428571428572,
    "epoch": 0.42529585798816566,
    "step": 1150
  },
  {
    "loss": 4.286,
    "grad_norm": 0.9960893988609314,
    "learning_rate": 0.0008008571428571429,
    "epoch": 0.4437869822485207,
    "step": 1200
  },
  {
    "loss": 4.2528,
    "grad_norm": 0.9096077084541321,
    "learning_rate": 0.0007865714285714286,
    "epoch": 0.46227810650887574,
    "step": 1250
  },
  {
    "loss": 4.1719,
    "grad_norm": 1.0440490245819092,
    "learning_rate": 0.0007722857142857143,
    "epoch": 0.4807692307692308,
    "step": 1300
  },
  {
    "loss": 4.2492,
    "grad_norm": 0.6599034667015076,
    "learning_rate": 0.000758,
    "epoch": 0.4992603550295858,
    "step": 1350
  },
  {
    "loss": 4.3087,
    "grad_norm": 0.5291833281517029,
    "learning_rate": 0.0007437142857142857,
    "epoch": 0.5177514792899408,
    "step": 1400
  },
  {
    "loss": 4.1131,
    "grad_norm": 0.5502133965492249,
    "learning_rate": 0.0007294285714285714,
    "epoch": 0.5362426035502958,
    "step": 1450
  },
  {
    "loss": 4.1323,
    "grad_norm": 0.6747297048568726,
    "learning_rate": 0.0007151428571428572,
    "epoch": 0.5547337278106509,
    "step": 1500
  },
  {
    "loss": 4.1653,
    "grad_norm": 0.6444752216339111,
    "learning_rate": 0.0007008571428571428,
    "epoch": 0.5732248520710059,
    "step": 1550
  },
  {
    "loss": 4.0932,
    "grad_norm": 0.7364963889122009,
    "learning_rate": 0.0006865714285714286,
    "epoch": 0.591715976331361,
    "step": 1600
  },
  {
    "loss": 4.0465,
    "grad_norm": 0.7052741050720215,
    "learning_rate": 0.0006722857142857142,
    "epoch": 0.610207100591716,
    "step": 1650
  },
  {
    "loss": 4.1106,
    "grad_norm": 0.8971461653709412,
    "learning_rate": 0.0006580000000000001,
    "epoch": 0.628698224852071,
    "step": 1700
  },
  {
    "loss": 4.1266,
    "grad_norm": 0.9606924653053284,
    "learning_rate": 0.0006437142857142857,
    "epoch": 0.647189349112426,
    "step": 1750
  },
  {
    "loss": 4.0634,
    "grad_norm": 0.7525745630264282,
    "learning_rate": 0.0006294285714285715,
    "epoch": 0.665680473372781,
    "step": 1800
  },
  {
    "loss": 4.0632,
    "grad_norm": 1.3010282516479492,
    "learning_rate": 0.0006151428571428571,
    "epoch": 0.6841715976331361,
    "step": 1850
  },
  {
    "loss": 4.0563,
    "grad_norm": 0.8107591867446899,
    "learning_rate": 0.0006008571428571429,
    "epoch": 0.7026627218934911,
    "step": 1900
  },
  {
    "loss": 4.0898,
    "grad_norm": 0.6952799558639526,
    "learning_rate": 0.0005865714285714285,
    "epoch": 0.7211538461538461,
    "step": 1950
  },
  {
    "loss": 3.9165,
    "grad_norm": 0.77445387840271,
    "learning_rate": 0.0005722857142857143,
    "epoch": 0.7396449704142012,
    "step": 2000
  },
  {
    "loss": 3.9802,
    "grad_norm": 0.9588878154754639,
    "learning_rate": 0.000558,
    "epoch": 0.7581360946745562,
    "step": 2050
  },
  {
    "loss": 3.9721,
    "grad_norm": 0.951789915561676,
    "learning_rate": 0.0005437142857142857,
    "epoch": 0.7766272189349113,
    "step": 2100
  },
  {
    "loss": 3.9819,
    "grad_norm": 0.8906616568565369,
    "learning_rate": 0.0005294285714285715,
    "epoch": 0.7951183431952663,
    "step": 2150
  },
  {
    "loss": 3.8412,
    "grad_norm": 0.7331544160842896,
    "learning_rate": 0.0005151428571428571,
    "epoch": 0.8136094674556213,
    "step": 2200
  },
  {
    "loss": 3.9268,
    "grad_norm": 1.2214711904525757,
    "learning_rate": 0.000500857142857143,
    "epoch": 0.8321005917159763,
    "step": 2250
  },
  {
    "loss": 3.935,
    "grad_norm": 1.4302918910980225,
    "learning_rate": 0.0004865714285714286,
    "epoch": 0.8505917159763313,
    "step": 2300
  },
  {
    "loss": 3.8724,
    "grad_norm": 1.2224657535552979,
    "learning_rate": 0.0004722857142857143,
    "epoch": 0.8690828402366864,
    "step": 2350
  },
  {
    "loss": 3.8117,
    "grad_norm": 1.0091257095336914,
    "learning_rate": 0.000458,
    "epoch": 0.8875739644970414,
    "step": 2400
  },
  {
    "loss": 3.8798,
    "grad_norm": 0.9130988717079163,
    "learning_rate": 0.00044371428571428573,
    "epoch": 0.9060650887573964,
    "step": 2450
  },
  {
    "loss": 3.8976,
    "grad_norm": 0.9045617580413818,
    "learning_rate": 0.00042942857142857144,
    "epoch": 0.9245562130177515,
    "step": 2500
  },
  {
    "loss": 3.8301,
    "grad_norm": 0.8402710556983948,
    "learning_rate": 0.00041514285714285714,
    "epoch": 0.9430473372781065,
    "step": 2550
  },
  {
    "loss": 3.7488,
    "grad_norm": 1.22017502784729,
    "learning_rate": 0.00040085714285714285,
    "epoch": 0.9615384615384616,
    "step": 2600
  },
  {
    "loss": 3.7355,
    "grad_norm": 1.1525758504867554,
    "learning_rate": 0.00038657142857142856,
    "epoch": 0.9800295857988166,
    "step": 2650
  },
  {
    "loss": 3.8233,
    "grad_norm": 1.034459114074707,
    "learning_rate": 0.00037228571428571427,
    "epoch": 0.9985207100591716,
    "step": 2700
  },
  {
    "loss": 3.8091,
    "grad_norm": 1.1131923198699951,
    "learning_rate": 0.000358,
    "epoch": 1.0170118343195267,
    "step": 2750
  },
  {
    "loss": 3.7503,
    "grad_norm": 1.1559356451034546,
    "learning_rate": 0.0003437142857142857,
    "epoch": 1.0355029585798816,
    "step": 2800
  },
  {
    "loss": 3.7274,
    "grad_norm": 1.019183874130249,
    "learning_rate": 0.0003294285714285714,
    "epoch": 1.0539940828402368,
    "step": 2850
  },
  {
    "loss": 3.749,
    "grad_norm": 1.0302072763442993,
    "learning_rate": 0.00031514285714285715,
    "epoch": 1.0724852071005917,
    "step": 2900
  },
  {
    "loss": 3.7588,
    "grad_norm": 1.4316284656524658,
    "learning_rate": 0.00030085714285714286,
    "epoch": 1.0909763313609468,
    "step": 2950
  },
  {
    "loss": 3.7295,
    "grad_norm": 1.128604531288147,
    "learning_rate": 0.00028657142857142857,
    "epoch": 1.1094674556213018,
    "step": 3000
  },
  {
    "loss": 3.7032,
    "grad_norm": 1.360980749130249,
    "learning_rate": 0.00027228571428571433,
    "epoch": 1.1279585798816567,
    "step": 3050
  },
  {
    "loss": 3.7256,
    "grad_norm": 1.1789228916168213,
    "learning_rate": 0.00025800000000000004,
    "epoch": 1.1464497041420119,
    "step": 3100
  },
  {
    "loss": 3.6926,
    "grad_norm": 1.6099028587341309,
    "learning_rate": 0.00024371428571428572,
    "epoch": 1.1649408284023668,
    "step": 3150
  },
  {
    "loss": 3.5833,
    "grad_norm": 1.5421669483184814,
    "learning_rate": 0.00022942857142857143,
    "epoch": 1.183431952662722,
    "step": 3200
  },
  {
    "loss": 3.6298,
    "grad_norm": 1.5999561548233032,
    "learning_rate": 0.00021514285714285713,
    "epoch": 1.2019230769230769,
    "step": 3250
  },
  {
    "loss": 3.6877,
    "grad_norm": 1.2049634456634521,
    "learning_rate": 0.00020085714285714284,
    "epoch": 1.220414201183432,
    "step": 3300
  },
  {
    "loss": 3.6691,
    "grad_norm": 1.2501542568206787,
    "learning_rate": 0.00018657142857142858,
    "epoch": 1.238905325443787,
    "step": 3350
  },
  {
    "loss": 3.6438,
    "grad_norm": 1.4001212120056152,
    "learning_rate": 0.00017228571428571428,
    "epoch": 1.2573964497041419,
    "step": 3400
  },
  {
    "loss": 3.6526,
    "grad_norm": 1.1432819366455078,
    "learning_rate": 0.000158,
    "epoch": 1.275887573964497,
    "step": 3450
  },
  {
    "loss": 3.6511,
    "grad_norm": 1.2681879997253418,
    "learning_rate": 0.00014371428571428573,
    "epoch": 1.2943786982248522,
    "step": 3500
  },
  {
    "loss": 3.6575,
    "grad_norm": 1.559036374092102,
    "learning_rate": 0.00012942857142857143,
    "epoch": 1.3128698224852071,
    "step": 3550
  },
  {
    "loss": 3.6251,
    "grad_norm": 1.3481554985046387,
    "learning_rate": 0.00011514285714285714,
    "epoch": 1.331360946745562,
    "step": 3600
  },
  {
    "loss": 3.6033,
    "grad_norm": 1.4008933305740356,
    "learning_rate": 0.00010085714285714285,
    "epoch": 1.3498520710059172,
    "step": 3650
  },
  {
    "loss": 3.5786,
    "grad_norm": 1.271599531173706,
    "learning_rate": 8.657142857142858e-05,
    "epoch": 1.3683431952662721,
    "step": 3700
  },
  {
    "loss": 3.5511,
    "grad_norm": 1.2689597606658936,
    "learning_rate": 7.228571428571429e-05,
    "epoch": 1.3868343195266273,
    "step": 3750
  },
  {
    "loss": 3.6142,
    "grad_norm": 1.1030174493789673,
    "learning_rate": 5.800000000000001e-05,
    "epoch": 1.4053254437869822,
    "step": 3800
  },
  {
    "loss": 3.5979,
    "grad_norm": 1.126649022102356,
    "learning_rate": 4.3714285714285715e-05,
    "epoch": 1.4238165680473374,
    "step": 3850
  },
  {
    "loss": 3.5947,
    "grad_norm": 1.2049154043197632,
    "learning_rate": 2.942857142857143e-05,
    "epoch": 1.4423076923076923,
    "step": 3900
  },
  {
    "loss": 3.5361,
    "grad_norm": 1.2178632020950317,
    "learning_rate": 1.5142857142857144e-05,
    "epoch": 1.4607988165680474,
    "step": 3950
  },
  {
    "loss": 3.5508,
    "grad_norm": 1.229236125946045,
    "learning_rate": 8.571428571428571e-07,
    "epoch": 1.4792899408284024,
    "step": 4000
  },
  {
    "train_runtime": 12071.6494,
    "train_samples_per_second": 2.651,
    "train_steps_per_second": 0.331,
    "total_flos": 9.39692630532096e+18,
    "train_loss": 3.697360921859741,
    "epoch": 1.4792899408284024,
    "step": 4000
  }
]