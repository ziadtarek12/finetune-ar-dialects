[
  {
    "loss": 4.1077,
    "grad_norm": 2.5135021209716797,
    "learning_rate": 9.6e-05,
    "epoch": 0.01849112426035503,
    "step": 50
  },
  {
    "loss": 2.3889,
    "grad_norm": 2.414389133453369,
    "learning_rate": 0.00019600000000000002,
    "epoch": 0.03698224852071006,
    "step": 100
  },
  {
    "loss": 1.8236,
    "grad_norm": 1.8450292348861694,
    "learning_rate": 0.000296,
    "epoch": 0.05547337278106509,
    "step": 150
  },
  {
    "loss": 1.5923,
    "grad_norm": 1.9283413887023926,
    "learning_rate": 0.00039600000000000003,
    "epoch": 0.07396449704142012,
    "step": 200
  },
  {
    "loss": 1.5833,
    "grad_norm": 1.8352285623550415,
    "learning_rate": 0.000496,
    "epoch": 0.09245562130177515,
    "step": 250
  },
  {
    "loss": 1.5391,
    "grad_norm": 2.766484022140503,
    "learning_rate": 0.000596,
    "epoch": 0.11094674556213018,
    "step": 300
  },
  {
    "loss": 1.469,
    "grad_norm": 2.6429243087768555,
    "learning_rate": 0.000696,
    "epoch": 0.1294378698224852,
    "step": 350
  },
  {
    "loss": 1.5352,
    "grad_norm": 2.3023459911346436,
    "learning_rate": 0.000796,
    "epoch": 0.14792899408284024,
    "step": 400
  },
  {
    "loss": 1.515,
    "grad_norm": 2.242004632949829,
    "learning_rate": 0.000896,
    "epoch": 0.16642011834319526,
    "step": 450
  },
  {
    "loss": 1.5265,
    "grad_norm": 2.8887784481048584,
    "learning_rate": 0.000996,
    "epoch": 0.1849112426035503,
    "step": 500
  },
  {
    "loss": 1.5787,
    "grad_norm": 2.6067559719085693,
    "learning_rate": 0.0009808,
    "epoch": 0.20340236686390534,
    "step": 550
  },
  {
    "loss": 1.6495,
    "grad_norm": 2.979931354522705,
    "learning_rate": 0.0009608,
    "epoch": 0.22189349112426035,
    "step": 600
  },
  {
    "loss": 1.6079,
    "grad_norm": 3.722513437271118,
    "learning_rate": 0.0009408,
    "epoch": 0.2403846153846154,
    "step": 650
  },
  {
    "loss": 1.651,
    "grad_norm": 3.9260571002960205,
    "learning_rate": 0.0009207999999999999,
    "epoch": 0.2588757396449704,
    "step": 700
  },
  {
    "loss": 1.6425,
    "grad_norm": 3.5593202114105225,
    "learning_rate": 0.0009008000000000001,
    "epoch": 0.27736686390532544,
    "step": 750
  },
  {
    "loss": 1.6249,
    "grad_norm": 2.318086624145508,
    "learning_rate": 0.0008808,
    "epoch": 0.2958579881656805,
    "step": 800
  },
  {
    "loss": 1.6141,
    "grad_norm": 3.5114381313323975,
    "learning_rate": 0.0008608,
    "epoch": 0.3143491124260355,
    "step": 850
  },
  {
    "loss": 1.613,
    "grad_norm": 2.771540403366089,
    "learning_rate": 0.0008408000000000001,
    "epoch": 0.3328402366863905,
    "step": 900
  },
  {
    "loss": 1.6625,
    "grad_norm": 2.931422710418701,
    "learning_rate": 0.0008208,
    "epoch": 0.35133136094674555,
    "step": 950
  },
  {
    "loss": 1.4864,
    "grad_norm": 3.2886955738067627,
    "learning_rate": 0.0008008,
    "epoch": 0.3698224852071006,
    "step": 1000
  },
  {
    "loss": 1.507,
    "grad_norm": 2.7941648960113525,
    "learning_rate": 0.0007808000000000001,
    "epoch": 0.38831360946745563,
    "step": 1050
  },
  {
    "loss": 1.5283,
    "grad_norm": 3.249941349029541,
    "learning_rate": 0.0007608000000000001,
    "epoch": 0.4068047337278107,
    "step": 1100
  },
  {
    "loss": 1.52,
    "grad_norm": 3.1116068363189697,
    "learning_rate": 0.0007408,
    "epoch": 0.42529585798816566,
    "step": 1150
  },
  {
    "loss": 1.5558,
    "grad_norm": 3.0149123668670654,
    "learning_rate": 0.0007208000000000001,
    "epoch": 0.4437869822485207,
    "step": 1200
  },
  {
    "loss": 1.5873,
    "grad_norm": 1.9210789203643799,
    "learning_rate": 0.0007008,
    "epoch": 0.46227810650887574,
    "step": 1250
  },
  {
    "loss": 1.5103,
    "grad_norm": 2.432528495788574,
    "learning_rate": 0.0006808,
    "epoch": 0.4807692307692308,
    "step": 1300
  },
  {
    "loss": 1.4488,
    "grad_norm": 2.258881092071533,
    "learning_rate": 0.0006608,
    "epoch": 0.4992603550295858,
    "step": 1350
  },
  {
    "loss": 1.447,
    "grad_norm": 2.5752832889556885,
    "learning_rate": 0.0006408000000000001,
    "epoch": 0.5177514792899408,
    "step": 1400
  },
  {
    "loss": 1.5675,
    "grad_norm": 2.845524549484253,
    "learning_rate": 0.0006208,
    "epoch": 0.5362426035502958,
    "step": 1450
  },
  {
    "loss": 1.4039,
    "grad_norm": 2.3335609436035156,
    "learning_rate": 0.0006008,
    "epoch": 0.5547337278106509,
    "step": 1500
  },
  {
    "loss": 1.4325,
    "grad_norm": 3.415415048599243,
    "learning_rate": 0.0005808,
    "epoch": 0.5732248520710059,
    "step": 1550
  },
  {
    "loss": 1.324,
    "grad_norm": 3.3803870677948,
    "learning_rate": 0.0005608,
    "epoch": 0.591715976331361,
    "step": 1600
  },
  {
    "loss": 1.4599,
    "grad_norm": 2.9891395568847656,
    "learning_rate": 0.0005407999999999999,
    "epoch": 0.610207100591716,
    "step": 1650
  },
  {
    "loss": 1.4294,
    "grad_norm": 2.412048101425171,
    "learning_rate": 0.0005208000000000001,
    "epoch": 0.628698224852071,
    "step": 1700
  },
  {
    "loss": 1.4174,
    "grad_norm": 2.8656961917877197,
    "learning_rate": 0.0005008,
    "epoch": 0.647189349112426,
    "step": 1750
  },
  {
    "loss": 1.4122,
    "grad_norm": 2.240359306335449,
    "learning_rate": 0.00048080000000000003,
    "epoch": 0.665680473372781,
    "step": 1800
  },
  {
    "loss": 1.4151,
    "grad_norm": 3.421665668487549,
    "learning_rate": 0.0004608,
    "epoch": 0.6841715976331361,
    "step": 1850
  },
  {
    "loss": 1.4114,
    "grad_norm": 2.5694267749786377,
    "learning_rate": 0.00044080000000000004,
    "epoch": 0.7026627218934911,
    "step": 1900
  },
  {
    "loss": 1.4125,
    "grad_norm": 3.0295305252075195,
    "learning_rate": 0.00042080000000000004,
    "epoch": 0.7211538461538461,
    "step": 1950
  },
  {
    "loss": 1.4185,
    "grad_norm": 3.361912727355957,
    "learning_rate": 0.0004008,
    "epoch": 0.7396449704142012,
    "step": 2000
  },
  {
    "loss": 1.3634,
    "grad_norm": 2.7190604209899902,
    "learning_rate": 0.00038080000000000004,
    "epoch": 0.7581360946745562,
    "step": 2050
  },
  {
    "loss": 1.3324,
    "grad_norm": 2.265929698944092,
    "learning_rate": 0.00036080000000000004,
    "epoch": 0.7766272189349113,
    "step": 2100
  },
  {
    "loss": 1.3139,
    "grad_norm": 2.3288681507110596,
    "learning_rate": 0.0003408,
    "epoch": 0.7951183431952663,
    "step": 2150
  },
  {
    "loss": 1.3363,
    "grad_norm": 3.4124326705932617,
    "learning_rate": 0.0003208,
    "epoch": 0.8136094674556213,
    "step": 2200
  },
  {
    "loss": 1.3495,
    "grad_norm": 2.0955216884613037,
    "learning_rate": 0.0003008,
    "epoch": 0.8321005917159763,
    "step": 2250
  },
  {
    "loss": 1.444,
    "grad_norm": 2.3402469158172607,
    "learning_rate": 0.0002808,
    "epoch": 0.8505917159763313,
    "step": 2300
  },
  {
    "loss": 1.3453,
    "grad_norm": 2.816692590713501,
    "learning_rate": 0.0002608,
    "epoch": 0.8690828402366864,
    "step": 2350
  },
  {
    "loss": 1.24,
    "grad_norm": 2.7529361248016357,
    "learning_rate": 0.0002408,
    "epoch": 0.8875739644970414,
    "step": 2400
  },
  {
    "loss": 1.2993,
    "grad_norm": 2.0742361545562744,
    "learning_rate": 0.0002208,
    "epoch": 0.9060650887573964,
    "step": 2450
  },
  {
    "loss": 1.2632,
    "grad_norm": 2.5813894271850586,
    "learning_rate": 0.0002008,
    "epoch": 0.9245562130177515,
    "step": 2500
  },
  {
    "loss": 1.2747,
    "grad_norm": 2.873992681503296,
    "learning_rate": 0.0001808,
    "epoch": 0.9430473372781065,
    "step": 2550
  },
  {
    "loss": 1.4123,
    "grad_norm": 2.09901762008667,
    "learning_rate": 0.0001608,
    "epoch": 0.9615384615384616,
    "step": 2600
  },
  {
    "loss": 1.3381,
    "grad_norm": 2.934760570526123,
    "learning_rate": 0.0001408,
    "epoch": 0.9800295857988166,
    "step": 2650
  },
  {
    "loss": 1.2996,
    "grad_norm": 2.823829412460327,
    "learning_rate": 0.00012080000000000001,
    "epoch": 0.9985207100591716,
    "step": 2700
  },
  {
    "loss": 1.0758,
    "grad_norm": 1.8017033338546753,
    "learning_rate": 0.0001008,
    "epoch": 1.0170118343195267,
    "step": 2750
  },
  {
    "loss": 1.1078,
    "grad_norm": 2.738128185272217,
    "learning_rate": 8.08e-05,
    "epoch": 1.0355029585798816,
    "step": 2800
  },
  {
    "loss": 1.0951,
    "grad_norm": 1.914818286895752,
    "learning_rate": 6.08e-05,
    "epoch": 1.0539940828402368,
    "step": 2850
  },
  {
    "loss": 1.0948,
    "grad_norm": 2.360713481903076,
    "learning_rate": 4.08e-05,
    "epoch": 1.0724852071005917,
    "step": 2900
  },
  {
    "loss": 1.0751,
    "grad_norm": 1.7086504697799683,
    "learning_rate": 2.08e-05,
    "epoch": 1.0909763313609468,
    "step": 2950
  },
  {
    "loss": 1.0945,
    "grad_norm": 2.117192029953003,
    "learning_rate": 8.000000000000001e-07,
    "epoch": 1.1094674556213018,
    "step": 3000
  },
  {
    "train_runtime": 9500.4829,
    "train_samples_per_second": 2.526,
    "train_steps_per_second": 0.316,
    "total_flos": 7.04747446788096e+18,
    "train_loss": 1.49291748046875,
    "epoch": 1.1094674556213018,
    "step": 3000
  }
]