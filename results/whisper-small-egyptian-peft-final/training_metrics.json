[
  {
    "loss": 3.6974,
    "grad_norm": 2.2622597217559814,
    "learning_rate": 9.800000000000001e-05,
    "epoch": 0.02256317689530686,
    "step": 50
  },
  {
    "loss": 2.0484,
    "grad_norm": 1.5158708095550537,
    "learning_rate": 0.00019800000000000002,
    "epoch": 0.04512635379061372,
    "step": 100
  },
  {
    "loss": 1.5394,
    "grad_norm": 2.3727328777313232,
    "learning_rate": 0.000298,
    "epoch": 0.06768953068592058,
    "step": 150
  },
  {
    "loss": 1.3747,
    "grad_norm": 1.5839418172836304,
    "learning_rate": 0.000398,
    "epoch": 0.09025270758122744,
    "step": 200
  },
  {
    "loss": 1.3463,
    "grad_norm": 1.8424339294433594,
    "learning_rate": 0.000498,
    "epoch": 0.11281588447653429,
    "step": 250
  },
  {
    "loss": 1.313,
    "grad_norm": 2.780456781387329,
    "learning_rate": 0.000598,
    "epoch": 0.13537906137184116,
    "step": 300
  },
  {
    "loss": 1.4319,
    "grad_norm": 2.2812228202819824,
    "learning_rate": 0.0006979999999999999,
    "epoch": 0.157942238267148,
    "step": 350
  },
  {
    "loss": 1.4515,
    "grad_norm": 1.8533415794372559,
    "learning_rate": 0.0007980000000000001,
    "epoch": 0.18050541516245489,
    "step": 400
  },
  {
    "loss": 1.3573,
    "grad_norm": 2.81703782081604,
    "learning_rate": 0.000898,
    "epoch": 0.20306859205776173,
    "step": 450
  },
  {
    "loss": 1.4036,
    "grad_norm": 2.03812837600708,
    "learning_rate": 0.000998,
    "epoch": 0.22563176895306858,
    "step": 500
  },
  {
    "loss": 1.4798,
    "grad_norm": NaN,
    "learning_rate": 0.0009808,
    "epoch": 0.24819494584837545,
    "step": 550
  },
  {
    "loss": 4.7035,
    "grad_norm": 1.8459527492523193,
    "learning_rate": 0.0009616000000000001,
    "epoch": 0.27075812274368233,
    "step": 600
  },
  {
    "loss": 5.1049,
    "grad_norm": 2.571441650390625,
    "learning_rate": 0.0009416,
    "epoch": 0.2933212996389892,
    "step": 650
  },
  {
    "loss": 4.5063,
    "grad_norm": 15.331327438354492,
    "learning_rate": 0.0009216,
    "epoch": 0.315884476534296,
    "step": 700
  },
  {
    "loss": 2.3623,
    "grad_norm": 2.897597074508667,
    "learning_rate": 0.0009016,
    "epoch": 0.33844765342960287,
    "step": 750
  },
  {
    "loss": 1.5897,
    "grad_norm": 3.1161415576934814,
    "learning_rate": 0.0008816000000000001,
    "epoch": 0.36101083032490977,
    "step": 800
  },
  {
    "loss": 1.4369,
    "grad_norm": 3.206965923309326,
    "learning_rate": 0.0008616,
    "epoch": 0.3835740072202166,
    "step": 850
  },
  {
    "loss": 1.4107,
    "grad_norm": 2.8059308528900146,
    "learning_rate": 0.0008416000000000001,
    "epoch": 0.40613718411552346,
    "step": 900
  },
  {
    "loss": 1.4919,
    "grad_norm": 2.8243467807769775,
    "learning_rate": 0.0008216,
    "epoch": 0.4287003610108303,
    "step": 950
  },
  {
    "loss": 1.4181,
    "grad_norm": 2.720207691192627,
    "learning_rate": 0.0008016,
    "epoch": 0.45126353790613716,
    "step": 1000
  },
  {
    "loss": 1.3007,
    "grad_norm": 3.178632974624634,
    "learning_rate": 0.0007816,
    "epoch": 0.47382671480144406,
    "step": 1050
  },
  {
    "loss": 1.3924,
    "grad_norm": 2.674037456512451,
    "learning_rate": 0.0007616000000000001,
    "epoch": 0.4963898916967509,
    "step": 1100
  },
  {
    "loss": 1.4218,
    "grad_norm": 3.436951160430908,
    "learning_rate": 0.0007416,
    "epoch": 0.5189530685920578,
    "step": 1150
  },
  {
    "loss": 1.3773,
    "grad_norm": 2.486635446548462,
    "learning_rate": 0.0007216000000000001,
    "epoch": 0.5415162454873647,
    "step": 1200
  },
  {
    "loss": 1.4256,
    "grad_norm": 2.215585231781006,
    "learning_rate": 0.0007016,
    "epoch": 0.5640794223826715,
    "step": 1250
  },
  {
    "loss": 1.3593,
    "grad_norm": 2.486828088760376,
    "learning_rate": 0.0006816,
    "epoch": 0.5866425992779783,
    "step": 1300
  },
  {
    "loss": 1.4089,
    "grad_norm": 2.2968132495880127,
    "learning_rate": 0.0006615999999999999,
    "epoch": 0.6092057761732852,
    "step": 1350
  },
  {
    "loss": 1.326,
    "grad_norm": 2.4819250106811523,
    "learning_rate": 0.0006416,
    "epoch": 0.631768953068592,
    "step": 1400
  },
  {
    "loss": 1.342,
    "grad_norm": 2.68572998046875,
    "learning_rate": 0.0006216,
    "epoch": 0.6543321299638989,
    "step": 1450
  },
  {
    "loss": 1.3282,
    "grad_norm": 2.50616455078125,
    "learning_rate": 0.0006016,
    "epoch": 0.6768953068592057,
    "step": 1500
  },
  {
    "loss": 1.3227,
    "grad_norm": 3.611708879470825,
    "learning_rate": 0.0005816,
    "epoch": 0.6994584837545126,
    "step": 1550
  },
  {
    "loss": 1.3129,
    "grad_norm": 4.113799571990967,
    "learning_rate": 0.0005616,
    "epoch": 0.7220216606498195,
    "step": 1600
  },
  {
    "loss": 1.2717,
    "grad_norm": 2.6202313899993896,
    "learning_rate": 0.0005415999999999999,
    "epoch": 0.7445848375451264,
    "step": 1650
  },
  {
    "loss": 1.2292,
    "grad_norm": 2.7645013332366943,
    "learning_rate": 0.0005216,
    "epoch": 0.7671480144404332,
    "step": 1700
  },
  {
    "loss": 1.2843,
    "grad_norm": 2.631326913833618,
    "learning_rate": 0.0005016,
    "epoch": 0.7897111913357401,
    "step": 1750
  },
  {
    "loss": 1.2805,
    "grad_norm": 5.5582661628723145,
    "learning_rate": 0.0004816,
    "epoch": 0.8122743682310469,
    "step": 1800
  },
  {
    "loss": 1.237,
    "grad_norm": 2.7237753868103027,
    "learning_rate": 0.0004616,
    "epoch": 0.8348375451263538,
    "step": 1850
  },
  {
    "loss": 1.2745,
    "grad_norm": 3.344560384750366,
    "learning_rate": 0.0004416,
    "epoch": 0.8574007220216606,
    "step": 1900
  },
  {
    "loss": 1.2384,
    "grad_norm": 2.4744343757629395,
    "learning_rate": 0.0004216,
    "epoch": 0.8799638989169675,
    "step": 1950
  },
  {
    "loss": 1.2739,
    "grad_norm": 2.786327362060547,
    "learning_rate": 0.0004016,
    "epoch": 0.9025270758122743,
    "step": 2000
  },
  {
    "loss": 1.2908,
    "grad_norm": 2.844301223754883,
    "learning_rate": 0.0003816,
    "epoch": 0.9250902527075813,
    "step": 2050
  },
  {
    "loss": 1.1852,
    "grad_norm": 2.506518602371216,
    "learning_rate": 0.0003616,
    "epoch": 0.9476534296028881,
    "step": 2100
  },
  {
    "loss": 1.156,
    "grad_norm": 2.2793524265289307,
    "learning_rate": 0.0003416,
    "epoch": 0.970216606498195,
    "step": 2150
  },
  {
    "loss": 1.2015,
    "grad_norm": 2.453449010848999,
    "learning_rate": 0.0003216,
    "epoch": 0.9927797833935018,
    "step": 2200
  },
  {
    "loss": 1.0872,
    "grad_norm": 2.4470369815826416,
    "learning_rate": 0.00030159999999999996,
    "epoch": 1.0153429602888087,
    "step": 2250
  },
  {
    "loss": 0.9936,
    "grad_norm": 2.9050393104553223,
    "learning_rate": 0.0002816,
    "epoch": 1.0379061371841156,
    "step": 2300
  },
  {
    "loss": 0.9975,
    "grad_norm": 2.584419012069702,
    "learning_rate": 0.0002616,
    "epoch": 1.0604693140794224,
    "step": 2350
  },
  {
    "loss": 1.0969,
    "grad_norm": 2.3814241886138916,
    "learning_rate": 0.00024160000000000002,
    "epoch": 1.0830324909747293,
    "step": 2400
  },
  {
    "loss": 1.0255,
    "grad_norm": 2.7306323051452637,
    "learning_rate": 0.0002216,
    "epoch": 1.105595667870036,
    "step": 2450
  },
  {
    "loss": 0.9918,
    "grad_norm": 2.2542669773101807,
    "learning_rate": 0.0002016,
    "epoch": 1.128158844765343,
    "step": 2500
  },
  {
    "loss": 0.9875,
    "grad_norm": 2.0287294387817383,
    "learning_rate": 0.00018160000000000002,
    "epoch": 1.1507220216606497,
    "step": 2550
  },
  {
    "loss": 1.0415,
    "grad_norm": 2.7842025756835938,
    "learning_rate": 0.0001616,
    "epoch": 1.1732851985559567,
    "step": 2600
  },
  {
    "loss": 0.9881,
    "grad_norm": 2.177034854888916,
    "learning_rate": 0.0001416,
    "epoch": 1.1958483754512637,
    "step": 2650
  },
  {
    "loss": 1.0123,
    "grad_norm": 2.2443153858184814,
    "learning_rate": 0.0001216,
    "epoch": 1.2184115523465704,
    "step": 2700
  },
  {
    "loss": 0.989,
    "grad_norm": 1.9304568767547607,
    "learning_rate": 0.0001016,
    "epoch": 1.2409747292418774,
    "step": 2750
  },
  {
    "loss": 1.0383,
    "grad_norm": 2.336491584777832,
    "learning_rate": 8.16e-05,
    "epoch": 1.263537906137184,
    "step": 2800
  },
  {
    "loss": 0.9621,
    "grad_norm": 2.069566488265991,
    "learning_rate": 6.16e-05,
    "epoch": 1.286101083032491,
    "step": 2850
  },
  {
    "loss": 1.0208,
    "grad_norm": 2.4158034324645996,
    "learning_rate": 4.16e-05,
    "epoch": 1.3086642599277978,
    "step": 2900
  },
  {
    "loss": 0.9675,
    "grad_norm": 2.234405040740967,
    "learning_rate": 2.1600000000000003e-05,
    "epoch": 1.3312274368231047,
    "step": 2950
  },
  {
    "loss": 1.0097,
    "grad_norm": 1.989022135734558,
    "learning_rate": 1.6000000000000001e-06,
    "epoch": 1.3537906137184115,
    "step": 3000
  },
  {
    "train_runtime": 9724.1053,
    "train_samples_per_second": 2.468,
    "train_steps_per_second": 0.309,
    "total_flos": 7.04776814936064e+18,
    "train_loss": 1.4986355730692547,
    "epoch": 1.3537906137184115,
    "step": 3000
  }
]