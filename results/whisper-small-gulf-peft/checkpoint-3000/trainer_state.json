{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.1094674556213018,
  "eval_steps": 500,
  "global_step": 3000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01849112426035503,
      "grad_norm": 2.5135021209716797,
      "learning_rate": 9.6e-05,
      "loss": 4.1077,
      "step": 50
    },
    {
      "epoch": 0.03698224852071006,
      "grad_norm": 2.414389133453369,
      "learning_rate": 0.00019600000000000002,
      "loss": 2.3889,
      "step": 100
    },
    {
      "epoch": 0.05547337278106509,
      "grad_norm": 1.8450292348861694,
      "learning_rate": 0.000296,
      "loss": 1.8236,
      "step": 150
    },
    {
      "epoch": 0.07396449704142012,
      "grad_norm": 1.9283413887023926,
      "learning_rate": 0.00039600000000000003,
      "loss": 1.5923,
      "step": 200
    },
    {
      "epoch": 0.09245562130177515,
      "grad_norm": 1.8352285623550415,
      "learning_rate": 0.000496,
      "loss": 1.5833,
      "step": 250
    },
    {
      "epoch": 0.11094674556213018,
      "grad_norm": 2.766484022140503,
      "learning_rate": 0.000596,
      "loss": 1.5391,
      "step": 300
    },
    {
      "epoch": 0.1294378698224852,
      "grad_norm": 2.6429243087768555,
      "learning_rate": 0.000696,
      "loss": 1.469,
      "step": 350
    },
    {
      "epoch": 0.14792899408284024,
      "grad_norm": 2.3023459911346436,
      "learning_rate": 0.000796,
      "loss": 1.5352,
      "step": 400
    },
    {
      "epoch": 0.16642011834319526,
      "grad_norm": 2.242004632949829,
      "learning_rate": 0.000896,
      "loss": 1.515,
      "step": 450
    },
    {
      "epoch": 0.1849112426035503,
      "grad_norm": 2.8887784481048584,
      "learning_rate": 0.000996,
      "loss": 1.5265,
      "step": 500
    },
    {
      "epoch": 0.20340236686390534,
      "grad_norm": 2.6067559719085693,
      "learning_rate": 0.0009808,
      "loss": 1.5787,
      "step": 550
    },
    {
      "epoch": 0.22189349112426035,
      "grad_norm": 2.979931354522705,
      "learning_rate": 0.0009608,
      "loss": 1.6495,
      "step": 600
    },
    {
      "epoch": 0.2403846153846154,
      "grad_norm": 3.722513437271118,
      "learning_rate": 0.0009408,
      "loss": 1.6079,
      "step": 650
    },
    {
      "epoch": 0.2588757396449704,
      "grad_norm": 3.9260571002960205,
      "learning_rate": 0.0009207999999999999,
      "loss": 1.651,
      "step": 700
    },
    {
      "epoch": 0.27736686390532544,
      "grad_norm": 3.5593202114105225,
      "learning_rate": 0.0009008000000000001,
      "loss": 1.6425,
      "step": 750
    },
    {
      "epoch": 0.2958579881656805,
      "grad_norm": 2.318086624145508,
      "learning_rate": 0.0008808,
      "loss": 1.6249,
      "step": 800
    },
    {
      "epoch": 0.3143491124260355,
      "grad_norm": 3.5114381313323975,
      "learning_rate": 0.0008608,
      "loss": 1.6141,
      "step": 850
    },
    {
      "epoch": 0.3328402366863905,
      "grad_norm": 2.771540403366089,
      "learning_rate": 0.0008408000000000001,
      "loss": 1.613,
      "step": 900
    },
    {
      "epoch": 0.35133136094674555,
      "grad_norm": 2.931422710418701,
      "learning_rate": 0.0008208,
      "loss": 1.6625,
      "step": 950
    },
    {
      "epoch": 0.3698224852071006,
      "grad_norm": 3.2886955738067627,
      "learning_rate": 0.0008008,
      "loss": 1.4864,
      "step": 1000
    },
    {
      "epoch": 0.38831360946745563,
      "grad_norm": 2.7941648960113525,
      "learning_rate": 0.0007808000000000001,
      "loss": 1.507,
      "step": 1050
    },
    {
      "epoch": 0.4068047337278107,
      "grad_norm": 3.249941349029541,
      "learning_rate": 0.0007608000000000001,
      "loss": 1.5283,
      "step": 1100
    },
    {
      "epoch": 0.42529585798816566,
      "grad_norm": 3.1116068363189697,
      "learning_rate": 0.0007408,
      "loss": 1.52,
      "step": 1150
    },
    {
      "epoch": 0.4437869822485207,
      "grad_norm": 3.0149123668670654,
      "learning_rate": 0.0007208000000000001,
      "loss": 1.5558,
      "step": 1200
    },
    {
      "epoch": 0.46227810650887574,
      "grad_norm": 1.9210789203643799,
      "learning_rate": 0.0007008,
      "loss": 1.5873,
      "step": 1250
    },
    {
      "epoch": 0.4807692307692308,
      "grad_norm": 2.432528495788574,
      "learning_rate": 0.0006808,
      "loss": 1.5103,
      "step": 1300
    },
    {
      "epoch": 0.4992603550295858,
      "grad_norm": 2.258881092071533,
      "learning_rate": 0.0006608,
      "loss": 1.4488,
      "step": 1350
    },
    {
      "epoch": 0.5177514792899408,
      "grad_norm": 2.5752832889556885,
      "learning_rate": 0.0006408000000000001,
      "loss": 1.447,
      "step": 1400
    },
    {
      "epoch": 0.5362426035502958,
      "grad_norm": 2.845524549484253,
      "learning_rate": 0.0006208,
      "loss": 1.5675,
      "step": 1450
    },
    {
      "epoch": 0.5547337278106509,
      "grad_norm": 2.3335609436035156,
      "learning_rate": 0.0006008,
      "loss": 1.4039,
      "step": 1500
    },
    {
      "epoch": 0.5732248520710059,
      "grad_norm": 3.415415048599243,
      "learning_rate": 0.0005808,
      "loss": 1.4325,
      "step": 1550
    },
    {
      "epoch": 0.591715976331361,
      "grad_norm": 3.3803870677948,
      "learning_rate": 0.0005608,
      "loss": 1.324,
      "step": 1600
    },
    {
      "epoch": 0.610207100591716,
      "grad_norm": 2.9891395568847656,
      "learning_rate": 0.0005407999999999999,
      "loss": 1.4599,
      "step": 1650
    },
    {
      "epoch": 0.628698224852071,
      "grad_norm": 2.412048101425171,
      "learning_rate": 0.0005208000000000001,
      "loss": 1.4294,
      "step": 1700
    },
    {
      "epoch": 0.647189349112426,
      "grad_norm": 2.8656961917877197,
      "learning_rate": 0.0005008,
      "loss": 1.4174,
      "step": 1750
    },
    {
      "epoch": 0.665680473372781,
      "grad_norm": 2.240359306335449,
      "learning_rate": 0.00048080000000000003,
      "loss": 1.4122,
      "step": 1800
    },
    {
      "epoch": 0.6841715976331361,
      "grad_norm": 3.421665668487549,
      "learning_rate": 0.0004608,
      "loss": 1.4151,
      "step": 1850
    },
    {
      "epoch": 0.7026627218934911,
      "grad_norm": 2.5694267749786377,
      "learning_rate": 0.00044080000000000004,
      "loss": 1.4114,
      "step": 1900
    },
    {
      "epoch": 0.7211538461538461,
      "grad_norm": 3.0295305252075195,
      "learning_rate": 0.00042080000000000004,
      "loss": 1.4125,
      "step": 1950
    },
    {
      "epoch": 0.7396449704142012,
      "grad_norm": 3.361912727355957,
      "learning_rate": 0.0004008,
      "loss": 1.4185,
      "step": 2000
    },
    {
      "epoch": 0.7581360946745562,
      "grad_norm": 2.7190604209899902,
      "learning_rate": 0.00038080000000000004,
      "loss": 1.3634,
      "step": 2050
    },
    {
      "epoch": 0.7766272189349113,
      "grad_norm": 2.265929698944092,
      "learning_rate": 0.00036080000000000004,
      "loss": 1.3324,
      "step": 2100
    },
    {
      "epoch": 0.7951183431952663,
      "grad_norm": 2.3288681507110596,
      "learning_rate": 0.0003408,
      "loss": 1.3139,
      "step": 2150
    },
    {
      "epoch": 0.8136094674556213,
      "grad_norm": 3.4124326705932617,
      "learning_rate": 0.0003208,
      "loss": 1.3363,
      "step": 2200
    },
    {
      "epoch": 0.8321005917159763,
      "grad_norm": 2.0955216884613037,
      "learning_rate": 0.0003008,
      "loss": 1.3495,
      "step": 2250
    },
    {
      "epoch": 0.8505917159763313,
      "grad_norm": 2.3402469158172607,
      "learning_rate": 0.0002808,
      "loss": 1.444,
      "step": 2300
    },
    {
      "epoch": 0.8690828402366864,
      "grad_norm": 2.816692590713501,
      "learning_rate": 0.0002608,
      "loss": 1.3453,
      "step": 2350
    },
    {
      "epoch": 0.8875739644970414,
      "grad_norm": 2.7529361248016357,
      "learning_rate": 0.0002408,
      "loss": 1.24,
      "step": 2400
    },
    {
      "epoch": 0.9060650887573964,
      "grad_norm": 2.0742361545562744,
      "learning_rate": 0.0002208,
      "loss": 1.2993,
      "step": 2450
    },
    {
      "epoch": 0.9245562130177515,
      "grad_norm": 2.5813894271850586,
      "learning_rate": 0.0002008,
      "loss": 1.2632,
      "step": 2500
    },
    {
      "epoch": 0.9430473372781065,
      "grad_norm": 2.873992681503296,
      "learning_rate": 0.0001808,
      "loss": 1.2747,
      "step": 2550
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 2.09901762008667,
      "learning_rate": 0.0001608,
      "loss": 1.4123,
      "step": 2600
    },
    {
      "epoch": 0.9800295857988166,
      "grad_norm": 2.934760570526123,
      "learning_rate": 0.0001408,
      "loss": 1.3381,
      "step": 2650
    },
    {
      "epoch": 0.9985207100591716,
      "grad_norm": 2.823829412460327,
      "learning_rate": 0.00012080000000000001,
      "loss": 1.2996,
      "step": 2700
    },
    {
      "epoch": 1.0170118343195267,
      "grad_norm": 1.8017033338546753,
      "learning_rate": 0.0001008,
      "loss": 1.0758,
      "step": 2750
    },
    {
      "epoch": 1.0355029585798816,
      "grad_norm": 2.738128185272217,
      "learning_rate": 8.08e-05,
      "loss": 1.1078,
      "step": 2800
    },
    {
      "epoch": 1.0539940828402368,
      "grad_norm": 1.914818286895752,
      "learning_rate": 6.08e-05,
      "loss": 1.0951,
      "step": 2850
    },
    {
      "epoch": 1.0724852071005917,
      "grad_norm": 2.360713481903076,
      "learning_rate": 4.08e-05,
      "loss": 1.0948,
      "step": 2900
    },
    {
      "epoch": 1.0909763313609468,
      "grad_norm": 1.7086504697799683,
      "learning_rate": 2.08e-05,
      "loss": 1.0751,
      "step": 2950
    },
    {
      "epoch": 1.1094674556213018,
      "grad_norm": 2.117192029953003,
      "learning_rate": 8.000000000000001e-07,
      "loss": 1.0945,
      "step": 3000
    }
  ],
  "logging_steps": 50,
  "max_steps": 3000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 7.04747446788096e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
