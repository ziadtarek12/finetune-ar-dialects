{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.2943786982248522,
  "eval_steps": 500,
  "global_step": 3500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01849112426035503,
      "grad_norm": 2.139329671859741,
      "learning_rate": 9.6e-05,
      "loss": 4.2889,
      "step": 50
    },
    {
      "epoch": 0.03698224852071006,
      "grad_norm": 2.54341459274292,
      "learning_rate": 0.00019600000000000002,
      "loss": 2.3763,
      "step": 100
    },
    {
      "epoch": 0.05547337278106509,
      "grad_norm": 1.8546984195709229,
      "learning_rate": 0.000296,
      "loss": 1.8681,
      "step": 150
    },
    {
      "epoch": 0.07396449704142012,
      "grad_norm": 2.2202508449554443,
      "learning_rate": 0.00039600000000000003,
      "loss": 1.5156,
      "step": 200
    },
    {
      "epoch": 0.09245562130177515,
      "grad_norm": 2.893281936645508,
      "learning_rate": 0.000496,
      "loss": 1.5459,
      "step": 250
    },
    {
      "epoch": 0.11094674556213018,
      "grad_norm": 2.5236055850982666,
      "learning_rate": 0.000596,
      "loss": 1.6052,
      "step": 300
    },
    {
      "epoch": 0.1294378698224852,
      "grad_norm": 2.4035696983337402,
      "learning_rate": 0.000696,
      "loss": 1.5168,
      "step": 350
    },
    {
      "epoch": 0.14792899408284024,
      "grad_norm": 3.361224412918091,
      "learning_rate": 0.000796,
      "loss": 1.5843,
      "step": 400
    },
    {
      "epoch": 0.16642011834319526,
      "grad_norm": 3.392230272293091,
      "learning_rate": 0.000896,
      "loss": 1.5404,
      "step": 450
    },
    {
      "epoch": 0.1849112426035503,
      "grad_norm": 2.7557873725891113,
      "learning_rate": 0.000996,
      "loss": 1.5968,
      "step": 500
    },
    {
      "epoch": 0.20340236686390534,
      "grad_norm": 3.737109661102295,
      "learning_rate": 0.0009862857142857143,
      "loss": 1.6449,
      "step": 550
    },
    {
      "epoch": 0.22189349112426035,
      "grad_norm": 2.5864017009735107,
      "learning_rate": 0.0009722857142857144,
      "loss": 5.949,
      "step": 600
    },
    {
      "epoch": 0.2403846153846154,
      "grad_norm": 0.8002440333366394,
      "learning_rate": 0.000958,
      "loss": 4.7568,
      "step": 650
    },
    {
      "epoch": 0.2588757396449704,
      "grad_norm": 1.0704636573791504,
      "learning_rate": 0.0009437142857142858,
      "loss": 4.516,
      "step": 700
    },
    {
      "epoch": 0.27736686390532544,
      "grad_norm": 1.1755808591842651,
      "learning_rate": 0.0009294285714285714,
      "loss": 4.7004,
      "step": 750
    },
    {
      "epoch": 0.2958579881656805,
      "grad_norm": 6.764094352722168,
      "learning_rate": 0.0009151428571428572,
      "loss": 4.4192,
      "step": 800
    },
    {
      "epoch": 0.3143491124260355,
      "grad_norm": 0.7135828137397766,
      "learning_rate": 0.0009008571428571429,
      "loss": 4.5023,
      "step": 850
    },
    {
      "epoch": 0.3328402366863905,
      "grad_norm": 0.5079736709594727,
      "learning_rate": 0.0008865714285714286,
      "loss": 4.4805,
      "step": 900
    },
    {
      "epoch": 0.35133136094674555,
      "grad_norm": 0.626338541507721,
      "learning_rate": 0.0008722857142857143,
      "loss": 4.4547,
      "step": 950
    },
    {
      "epoch": 0.3698224852071006,
      "grad_norm": 1.0897133350372314,
      "learning_rate": 0.000858,
      "loss": 4.4225,
      "step": 1000
    },
    {
      "epoch": 0.38831360946745563,
      "grad_norm": 1.038453221321106,
      "learning_rate": 0.0008437142857142857,
      "loss": 4.367,
      "step": 1050
    },
    {
      "epoch": 0.4068047337278107,
      "grad_norm": 0.4637073576450348,
      "learning_rate": 0.0008294285714285715,
      "loss": 4.3167,
      "step": 1100
    },
    {
      "epoch": 0.42529585798816566,
      "grad_norm": 0.6874340772628784,
      "learning_rate": 0.0008151428571428572,
      "loss": 4.2663,
      "step": 1150
    },
    {
      "epoch": 0.4437869822485207,
      "grad_norm": 0.9960893988609314,
      "learning_rate": 0.0008008571428571429,
      "loss": 4.286,
      "step": 1200
    },
    {
      "epoch": 0.46227810650887574,
      "grad_norm": 0.9096077084541321,
      "learning_rate": 0.0007865714285714286,
      "loss": 4.2528,
      "step": 1250
    },
    {
      "epoch": 0.4807692307692308,
      "grad_norm": 1.0440490245819092,
      "learning_rate": 0.0007722857142857143,
      "loss": 4.1719,
      "step": 1300
    },
    {
      "epoch": 0.4992603550295858,
      "grad_norm": 0.6599034667015076,
      "learning_rate": 0.000758,
      "loss": 4.2492,
      "step": 1350
    },
    {
      "epoch": 0.5177514792899408,
      "grad_norm": 0.5291833281517029,
      "learning_rate": 0.0007437142857142857,
      "loss": 4.3087,
      "step": 1400
    },
    {
      "epoch": 0.5362426035502958,
      "grad_norm": 0.5502133965492249,
      "learning_rate": 0.0007294285714285714,
      "loss": 4.1131,
      "step": 1450
    },
    {
      "epoch": 0.5547337278106509,
      "grad_norm": 0.6747297048568726,
      "learning_rate": 0.0007151428571428572,
      "loss": 4.1323,
      "step": 1500
    },
    {
      "epoch": 0.5732248520710059,
      "grad_norm": 0.6444752216339111,
      "learning_rate": 0.0007008571428571428,
      "loss": 4.1653,
      "step": 1550
    },
    {
      "epoch": 0.591715976331361,
      "grad_norm": 0.7364963889122009,
      "learning_rate": 0.0006865714285714286,
      "loss": 4.0932,
      "step": 1600
    },
    {
      "epoch": 0.610207100591716,
      "grad_norm": 0.7052741050720215,
      "learning_rate": 0.0006722857142857142,
      "loss": 4.0465,
      "step": 1650
    },
    {
      "epoch": 0.628698224852071,
      "grad_norm": 0.8971461653709412,
      "learning_rate": 0.0006580000000000001,
      "loss": 4.1106,
      "step": 1700
    },
    {
      "epoch": 0.647189349112426,
      "grad_norm": 0.9606924653053284,
      "learning_rate": 0.0006437142857142857,
      "loss": 4.1266,
      "step": 1750
    },
    {
      "epoch": 0.665680473372781,
      "grad_norm": 0.7525745630264282,
      "learning_rate": 0.0006294285714285715,
      "loss": 4.0634,
      "step": 1800
    },
    {
      "epoch": 0.6841715976331361,
      "grad_norm": 1.3010282516479492,
      "learning_rate": 0.0006151428571428571,
      "loss": 4.0632,
      "step": 1850
    },
    {
      "epoch": 0.7026627218934911,
      "grad_norm": 0.8107591867446899,
      "learning_rate": 0.0006008571428571429,
      "loss": 4.0563,
      "step": 1900
    },
    {
      "epoch": 0.7211538461538461,
      "grad_norm": 0.6952799558639526,
      "learning_rate": 0.0005865714285714285,
      "loss": 4.0898,
      "step": 1950
    },
    {
      "epoch": 0.7396449704142012,
      "grad_norm": 0.77445387840271,
      "learning_rate": 0.0005722857142857143,
      "loss": 3.9165,
      "step": 2000
    },
    {
      "epoch": 0.7581360946745562,
      "grad_norm": 0.9588878154754639,
      "learning_rate": 0.000558,
      "loss": 3.9802,
      "step": 2050
    },
    {
      "epoch": 0.7766272189349113,
      "grad_norm": 0.951789915561676,
      "learning_rate": 0.0005437142857142857,
      "loss": 3.9721,
      "step": 2100
    },
    {
      "epoch": 0.7951183431952663,
      "grad_norm": 0.8906616568565369,
      "learning_rate": 0.0005294285714285715,
      "loss": 3.9819,
      "step": 2150
    },
    {
      "epoch": 0.8136094674556213,
      "grad_norm": 0.7331544160842896,
      "learning_rate": 0.0005151428571428571,
      "loss": 3.8412,
      "step": 2200
    },
    {
      "epoch": 0.8321005917159763,
      "grad_norm": 1.2214711904525757,
      "learning_rate": 0.000500857142857143,
      "loss": 3.9268,
      "step": 2250
    },
    {
      "epoch": 0.8505917159763313,
      "grad_norm": 1.4302918910980225,
      "learning_rate": 0.0004865714285714286,
      "loss": 3.935,
      "step": 2300
    },
    {
      "epoch": 0.8690828402366864,
      "grad_norm": 1.2224657535552979,
      "learning_rate": 0.0004722857142857143,
      "loss": 3.8724,
      "step": 2350
    },
    {
      "epoch": 0.8875739644970414,
      "grad_norm": 1.0091257095336914,
      "learning_rate": 0.000458,
      "loss": 3.8117,
      "step": 2400
    },
    {
      "epoch": 0.9060650887573964,
      "grad_norm": 0.9130988717079163,
      "learning_rate": 0.00044371428571428573,
      "loss": 3.8798,
      "step": 2450
    },
    {
      "epoch": 0.9245562130177515,
      "grad_norm": 0.9045617580413818,
      "learning_rate": 0.00042942857142857144,
      "loss": 3.8976,
      "step": 2500
    },
    {
      "epoch": 0.9430473372781065,
      "grad_norm": 0.8402710556983948,
      "learning_rate": 0.00041514285714285714,
      "loss": 3.8301,
      "step": 2550
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 1.22017502784729,
      "learning_rate": 0.00040085714285714285,
      "loss": 3.7488,
      "step": 2600
    },
    {
      "epoch": 0.9800295857988166,
      "grad_norm": 1.1525758504867554,
      "learning_rate": 0.00038657142857142856,
      "loss": 3.7355,
      "step": 2650
    },
    {
      "epoch": 0.9985207100591716,
      "grad_norm": 1.034459114074707,
      "learning_rate": 0.00037228571428571427,
      "loss": 3.8233,
      "step": 2700
    },
    {
      "epoch": 1.0170118343195267,
      "grad_norm": 1.1131923198699951,
      "learning_rate": 0.000358,
      "loss": 3.8091,
      "step": 2750
    },
    {
      "epoch": 1.0355029585798816,
      "grad_norm": 1.1559356451034546,
      "learning_rate": 0.0003437142857142857,
      "loss": 3.7503,
      "step": 2800
    },
    {
      "epoch": 1.0539940828402368,
      "grad_norm": 1.019183874130249,
      "learning_rate": 0.0003294285714285714,
      "loss": 3.7274,
      "step": 2850
    },
    {
      "epoch": 1.0724852071005917,
      "grad_norm": 1.0302072763442993,
      "learning_rate": 0.00031514285714285715,
      "loss": 3.749,
      "step": 2900
    },
    {
      "epoch": 1.0909763313609468,
      "grad_norm": 1.4316284656524658,
      "learning_rate": 0.00030085714285714286,
      "loss": 3.7588,
      "step": 2950
    },
    {
      "epoch": 1.1094674556213018,
      "grad_norm": 1.128604531288147,
      "learning_rate": 0.00028657142857142857,
      "loss": 3.7295,
      "step": 3000
    },
    {
      "epoch": 1.1279585798816567,
      "grad_norm": 1.360980749130249,
      "learning_rate": 0.00027228571428571433,
      "loss": 3.7032,
      "step": 3050
    },
    {
      "epoch": 1.1464497041420119,
      "grad_norm": 1.1789228916168213,
      "learning_rate": 0.00025800000000000004,
      "loss": 3.7256,
      "step": 3100
    },
    {
      "epoch": 1.1649408284023668,
      "grad_norm": 1.6099028587341309,
      "learning_rate": 0.00024371428571428572,
      "loss": 3.6926,
      "step": 3150
    },
    {
      "epoch": 1.183431952662722,
      "grad_norm": 1.5421669483184814,
      "learning_rate": 0.00022942857142857143,
      "loss": 3.5833,
      "step": 3200
    },
    {
      "epoch": 1.2019230769230769,
      "grad_norm": 1.5999561548233032,
      "learning_rate": 0.00021514285714285713,
      "loss": 3.6298,
      "step": 3250
    },
    {
      "epoch": 1.220414201183432,
      "grad_norm": 1.2049634456634521,
      "learning_rate": 0.00020085714285714284,
      "loss": 3.6877,
      "step": 3300
    },
    {
      "epoch": 1.238905325443787,
      "grad_norm": 1.2501542568206787,
      "learning_rate": 0.00018657142857142858,
      "loss": 3.6691,
      "step": 3350
    },
    {
      "epoch": 1.2573964497041419,
      "grad_norm": 1.4001212120056152,
      "learning_rate": 0.00017228571428571428,
      "loss": 3.6438,
      "step": 3400
    },
    {
      "epoch": 1.275887573964497,
      "grad_norm": 1.1432819366455078,
      "learning_rate": 0.000158,
      "loss": 3.6526,
      "step": 3450
    },
    {
      "epoch": 1.2943786982248522,
      "grad_norm": 1.2681879997253418,
      "learning_rate": 0.00014371428571428573,
      "loss": 3.6511,
      "step": 3500
    }
  ],
  "logging_steps": 50,
  "max_steps": 4000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.22220038660096e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
