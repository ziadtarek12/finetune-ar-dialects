{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.2943786982248522,
  "eval_steps": 500,
  "global_step": 3500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01849112426035503,
      "grad_norm": 2.8875467777252197,
      "learning_rate": 9.6e-05,
      "loss": 4.3345,
      "step": 50
    },
    {
      "epoch": 0.03698224852071006,
      "grad_norm": 2.1142578125,
      "learning_rate": 0.00019600000000000002,
      "loss": 2.4014,
      "step": 100
    },
    {
      "epoch": 0.05547337278106509,
      "grad_norm": 1.9055860042572021,
      "learning_rate": 0.000296,
      "loss": 1.7949,
      "step": 150
    },
    {
      "epoch": 0.07396449704142012,
      "grad_norm": 2.021397590637207,
      "learning_rate": 0.00039600000000000003,
      "loss": 1.5624,
      "step": 200
    },
    {
      "epoch": 0.09245562130177515,
      "grad_norm": 1.814786434173584,
      "learning_rate": 0.000496,
      "loss": 1.6276,
      "step": 250
    },
    {
      "epoch": 0.11094674556213018,
      "grad_norm": 2.3397538661956787,
      "learning_rate": 0.000596,
      "loss": 1.5304,
      "step": 300
    },
    {
      "epoch": 0.1294378698224852,
      "grad_norm": 2.235201597213745,
      "learning_rate": 0.000696,
      "loss": 1.5104,
      "step": 350
    },
    {
      "epoch": 0.14792899408284024,
      "grad_norm": 2.8320870399475098,
      "learning_rate": 0.000796,
      "loss": 1.4491,
      "step": 400
    },
    {
      "epoch": 0.16642011834319526,
      "grad_norm": 2.9227588176727295,
      "learning_rate": 0.000896,
      "loss": 1.5403,
      "step": 450
    },
    {
      "epoch": 0.1849112426035503,
      "grad_norm": 3.181398391723633,
      "learning_rate": 0.000996,
      "loss": 1.6348,
      "step": 500
    },
    {
      "epoch": 0.20340236686390534,
      "grad_norm": 4.298783302307129,
      "learning_rate": 0.0009862857142857143,
      "loss": 1.6506,
      "step": 550
    },
    {
      "epoch": 0.22189349112426035,
      "grad_norm": 3.6316769123077393,
      "learning_rate": 0.000972,
      "loss": 1.5939,
      "step": 600
    },
    {
      "epoch": 0.2403846153846154,
      "grad_norm": 3.6951539516448975,
      "learning_rate": 0.0009577142857142858,
      "loss": 1.6381,
      "step": 650
    },
    {
      "epoch": 0.2588757396449704,
      "grad_norm": 3.9220662117004395,
      "learning_rate": 0.0009434285714285714,
      "loss": 1.6257,
      "step": 700
    },
    {
      "epoch": 0.27736686390532544,
      "grad_norm": 2.6304967403411865,
      "learning_rate": 0.0009291428571428572,
      "loss": 1.5907,
      "step": 750
    },
    {
      "epoch": 0.2958579881656805,
      "grad_norm": 3.0797526836395264,
      "learning_rate": 0.0009148571428571428,
      "loss": 1.4874,
      "step": 800
    },
    {
      "epoch": 0.3143491124260355,
      "grad_norm": 2.7748937606811523,
      "learning_rate": 0.0009005714285714286,
      "loss": 1.5635,
      "step": 850
    },
    {
      "epoch": 0.3328402366863905,
      "grad_norm": 2.840930223464966,
      "learning_rate": 0.0008862857142857142,
      "loss": 1.6023,
      "step": 900
    },
    {
      "epoch": 0.35133136094674555,
      "grad_norm": 2.9684410095214844,
      "learning_rate": 0.000872,
      "loss": 1.4832,
      "step": 950
    },
    {
      "epoch": 0.3698224852071006,
      "grad_norm": 3.8386120796203613,
      "learning_rate": 0.0008577142857142858,
      "loss": 1.4694,
      "step": 1000
    },
    {
      "epoch": 0.38831360946745563,
      "grad_norm": 2.9375903606414795,
      "learning_rate": 0.0008434285714285715,
      "loss": 1.5888,
      "step": 1050
    },
    {
      "epoch": 0.4068047337278107,
      "grad_norm": 2.869663953781128,
      "learning_rate": 0.0008291428571428572,
      "loss": 1.5099,
      "step": 1100
    },
    {
      "epoch": 0.42529585798816566,
      "grad_norm": 2.9877541065216064,
      "learning_rate": 0.0008148571428571429,
      "loss": 1.5718,
      "step": 1150
    },
    {
      "epoch": 0.4437869822485207,
      "grad_norm": 2.642646312713623,
      "learning_rate": 0.0008005714285714286,
      "loss": 1.5993,
      "step": 1200
    },
    {
      "epoch": 0.46227810650887574,
      "grad_norm": 3.037926197052002,
      "learning_rate": 0.0007862857142857143,
      "loss": 1.5307,
      "step": 1250
    },
    {
      "epoch": 0.4807692307692308,
      "grad_norm": 3.474991798400879,
      "learning_rate": 0.000772,
      "loss": 1.6174,
      "step": 1300
    },
    {
      "epoch": 0.4992603550295858,
      "grad_norm": 2.9905846118927,
      "learning_rate": 0.0007577142857142857,
      "loss": 1.5743,
      "step": 1350
    },
    {
      "epoch": 0.5177514792899408,
      "grad_norm": 2.9668571949005127,
      "learning_rate": 0.0007434285714285714,
      "loss": 1.4611,
      "step": 1400
    },
    {
      "epoch": 0.5362426035502958,
      "grad_norm": 2.9201693534851074,
      "learning_rate": 0.0007291428571428571,
      "loss": 1.5033,
      "step": 1450
    },
    {
      "epoch": 0.5547337278106509,
      "grad_norm": 3.575946092605591,
      "learning_rate": 0.0007148571428571428,
      "loss": 1.5934,
      "step": 1500
    },
    {
      "epoch": 0.5732248520710059,
      "grad_norm": 3.121283531188965,
      "learning_rate": 0.0007005714285714287,
      "loss": 1.4641,
      "step": 1550
    },
    {
      "epoch": 0.591715976331361,
      "grad_norm": 2.5498721599578857,
      "learning_rate": 0.0006862857142857143,
      "loss": 1.359,
      "step": 1600
    },
    {
      "epoch": 0.610207100591716,
      "grad_norm": 3.1384503841400146,
      "learning_rate": 0.0006720000000000001,
      "loss": 1.5636,
      "step": 1650
    },
    {
      "epoch": 0.628698224852071,
      "grad_norm": 2.718327283859253,
      "learning_rate": 0.0006577142857142857,
      "loss": 1.517,
      "step": 1700
    },
    {
      "epoch": 0.647189349112426,
      "grad_norm": 2.9255270957946777,
      "learning_rate": 0.0006434285714285715,
      "loss": 1.5202,
      "step": 1750
    },
    {
      "epoch": 0.665680473372781,
      "grad_norm": 2.9592647552490234,
      "learning_rate": 0.0006291428571428571,
      "loss": 1.3976,
      "step": 1800
    },
    {
      "epoch": 0.6841715976331361,
      "grad_norm": 2.6160452365875244,
      "learning_rate": 0.0006148571428571429,
      "loss": 1.4237,
      "step": 1850
    },
    {
      "epoch": 0.7026627218934911,
      "grad_norm": 2.9103565216064453,
      "learning_rate": 0.0006005714285714285,
      "loss": 1.4916,
      "step": 1900
    },
    {
      "epoch": 0.7211538461538461,
      "grad_norm": 2.581535816192627,
      "learning_rate": 0.0005862857142857143,
      "loss": 1.4757,
      "step": 1950
    },
    {
      "epoch": 0.7396449704142012,
      "grad_norm": 2.5764739513397217,
      "learning_rate": 0.0005719999999999999,
      "loss": 1.4431,
      "step": 2000
    },
    {
      "epoch": 0.7581360946745562,
      "grad_norm": 1.959789514541626,
      "learning_rate": 0.0005577142857142857,
      "loss": 1.5161,
      "step": 2050
    },
    {
      "epoch": 0.7766272189349113,
      "grad_norm": 2.2439067363739014,
      "learning_rate": 0.0005434285714285714,
      "loss": 1.4299,
      "step": 2100
    },
    {
      "epoch": 0.7951183431952663,
      "grad_norm": 2.816039800643921,
      "learning_rate": 0.0005291428571428571,
      "loss": 1.4164,
      "step": 2150
    },
    {
      "epoch": 0.8136094674556213,
      "grad_norm": 2.9702351093292236,
      "learning_rate": 0.000514857142857143,
      "loss": 1.4372,
      "step": 2200
    },
    {
      "epoch": 0.8321005917159763,
      "grad_norm": 2.7187910079956055,
      "learning_rate": 0.0005005714285714286,
      "loss": 1.4464,
      "step": 2250
    },
    {
      "epoch": 0.8505917159763313,
      "grad_norm": 2.060778856277466,
      "learning_rate": 0.00048628571428571427,
      "loss": 1.3922,
      "step": 2300
    },
    {
      "epoch": 0.8690828402366864,
      "grad_norm": 2.145066261291504,
      "learning_rate": 0.000472,
      "loss": 1.5026,
      "step": 2350
    },
    {
      "epoch": 0.8875739644970414,
      "grad_norm": 2.521533727645874,
      "learning_rate": 0.00045771428571428574,
      "loss": 1.3312,
      "step": 2400
    },
    {
      "epoch": 0.9060650887573964,
      "grad_norm": 2.570042610168457,
      "learning_rate": 0.00044342857142857145,
      "loss": 1.3718,
      "step": 2450
    },
    {
      "epoch": 0.9245562130177515,
      "grad_norm": 2.329378366470337,
      "learning_rate": 0.00042914285714285716,
      "loss": 1.4122,
      "step": 2500
    },
    {
      "epoch": 0.9430473372781065,
      "grad_norm": 2.6339077949523926,
      "learning_rate": 0.00041485714285714287,
      "loss": 1.3594,
      "step": 2550
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 3.665897846221924,
      "learning_rate": 0.0004005714285714286,
      "loss": 1.3976,
      "step": 2600
    },
    {
      "epoch": 0.9800295857988166,
      "grad_norm": 2.5362513065338135,
      "learning_rate": 0.0003862857142857143,
      "loss": 1.3461,
      "step": 2650
    },
    {
      "epoch": 0.9985207100591716,
      "grad_norm": 2.6735198497772217,
      "learning_rate": 0.000372,
      "loss": 1.3353,
      "step": 2700
    },
    {
      "epoch": 1.0170118343195267,
      "grad_norm": 2.4722838401794434,
      "learning_rate": 0.0003577142857142857,
      "loss": 1.1292,
      "step": 2750
    },
    {
      "epoch": 1.0355029585798816,
      "grad_norm": 2.1541056632995605,
      "learning_rate": 0.0003434285714285714,
      "loss": 1.1469,
      "step": 2800
    },
    {
      "epoch": 1.0539940828402368,
      "grad_norm": 2.5514702796936035,
      "learning_rate": 0.0003291428571428571,
      "loss": 1.2115,
      "step": 2850
    },
    {
      "epoch": 1.0724852071005917,
      "grad_norm": 2.3930439949035645,
      "learning_rate": 0.0003148571428571428,
      "loss": 1.0955,
      "step": 2900
    },
    {
      "epoch": 1.0909763313609468,
      "grad_norm": 2.0598251819610596,
      "learning_rate": 0.00030057142857142853,
      "loss": 1.1836,
      "step": 2950
    },
    {
      "epoch": 1.1094674556213018,
      "grad_norm": 2.365687131881714,
      "learning_rate": 0.0002862857142857143,
      "loss": 1.1723,
      "step": 3000
    },
    {
      "epoch": 1.1279585798816567,
      "grad_norm": 2.6361658573150635,
      "learning_rate": 0.00027200000000000005,
      "loss": 1.1259,
      "step": 3050
    },
    {
      "epoch": 1.1464497041420119,
      "grad_norm": 2.826704502105713,
      "learning_rate": 0.00025771428571428576,
      "loss": 1.1704,
      "step": 3100
    },
    {
      "epoch": 1.1649408284023668,
      "grad_norm": 2.924588680267334,
      "learning_rate": 0.00024342857142857144,
      "loss": 1.1978,
      "step": 3150
    },
    {
      "epoch": 1.183431952662722,
      "grad_norm": 5.669443607330322,
      "learning_rate": 0.00022914285714285715,
      "loss": 1.0845,
      "step": 3200
    },
    {
      "epoch": 1.2019230769230769,
      "grad_norm": 2.14084529876709,
      "learning_rate": 0.00021485714285714286,
      "loss": 1.1607,
      "step": 3250
    },
    {
      "epoch": 1.220414201183432,
      "grad_norm": 2.1758036613464355,
      "learning_rate": 0.00020057142857142856,
      "loss": 1.1229,
      "step": 3300
    },
    {
      "epoch": 1.238905325443787,
      "grad_norm": 2.026763439178467,
      "learning_rate": 0.00018628571428571427,
      "loss": 1.1004,
      "step": 3350
    },
    {
      "epoch": 1.2573964497041419,
      "grad_norm": 2.480483055114746,
      "learning_rate": 0.00017199999999999998,
      "loss": 1.1385,
      "step": 3400
    },
    {
      "epoch": 1.275887573964497,
      "grad_norm": 2.000908613204956,
      "learning_rate": 0.00015771428571428571,
      "loss": 1.1013,
      "step": 3450
    },
    {
      "epoch": 1.2943786982248522,
      "grad_norm": 2.5763800144195557,
      "learning_rate": 0.00014342857142857145,
      "loss": 1.1388,
      "step": 3500
    }
  ],
  "logging_steps": 50,
  "max_steps": 4000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 8.22220038660096e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
