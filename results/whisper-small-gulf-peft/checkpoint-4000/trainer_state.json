{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.4792899408284024,
  "eval_steps": 500,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.01849112426035503,
      "grad_norm": 2.1713998317718506,
      "learning_rate": 9.800000000000001e-05,
      "loss": 4.2044,
      "step": 50
    },
    {
      "epoch": 0.03698224852071006,
      "grad_norm": 2.586599826812744,
      "learning_rate": 0.00019800000000000002,
      "loss": 2.3636,
      "step": 100
    },
    {
      "epoch": 0.05547337278106509,
      "grad_norm": 1.9866324663162231,
      "learning_rate": 0.000298,
      "loss": 1.8369,
      "step": 150
    },
    {
      "epoch": 0.07396449704142012,
      "grad_norm": 2.1588399410247803,
      "learning_rate": 0.000398,
      "loss": 1.5151,
      "step": 200
    },
    {
      "epoch": 0.09245562130177515,
      "grad_norm": 2.9873623847961426,
      "learning_rate": 0.000498,
      "loss": 1.5448,
      "step": 250
    },
    {
      "epoch": 0.11094674556213018,
      "grad_norm": 2.1954336166381836,
      "learning_rate": 0.000598,
      "loss": 1.6068,
      "step": 300
    },
    {
      "epoch": 0.1294378698224852,
      "grad_norm": 2.385751724243164,
      "learning_rate": 0.0006979999999999999,
      "loss": 1.5123,
      "step": 350
    },
    {
      "epoch": 0.14792899408284024,
      "grad_norm": 4.528987884521484,
      "learning_rate": 0.0007980000000000001,
      "loss": 1.5746,
      "step": 400
    },
    {
      "epoch": 0.16642011834319526,
      "grad_norm": 2.717930793762207,
      "learning_rate": 0.000898,
      "loss": 1.5336,
      "step": 450
    },
    {
      "epoch": 0.1849112426035503,
      "grad_norm": 2.5775814056396484,
      "learning_rate": 0.000998,
      "loss": 1.5801,
      "step": 500
    },
    {
      "epoch": 0.20340236686390534,
      "grad_norm": 3.167787551879883,
      "learning_rate": 0.0009860000000000001,
      "loss": 1.6419,
      "step": 550
    },
    {
      "epoch": 0.22189349112426035,
      "grad_norm": 2.850950002670288,
      "learning_rate": 0.0009717142857142858,
      "loss": 1.4964,
      "step": 600
    },
    {
      "epoch": 0.2403846153846154,
      "grad_norm": 2.238482713699341,
      "learning_rate": 0.0009574285714285714,
      "loss": 1.6129,
      "step": 650
    },
    {
      "epoch": 0.2588757396449704,
      "grad_norm": 2.7542335987091064,
      "learning_rate": 0.0009431428571428572,
      "loss": 1.6106,
      "step": 700
    },
    {
      "epoch": 0.27736686390532544,
      "grad_norm": 2.572042226791382,
      "learning_rate": 0.0009288571428571428,
      "loss": 1.6561,
      "step": 750
    },
    {
      "epoch": 0.2958579881656805,
      "grad_norm": 3.0645430088043213,
      "learning_rate": 0.0009145714285714287,
      "loss": 1.5149,
      "step": 800
    },
    {
      "epoch": 0.3143491124260355,
      "grad_norm": 3.9934098720550537,
      "learning_rate": 0.0009002857142857143,
      "loss": 1.5707,
      "step": 850
    },
    {
      "epoch": 0.3328402366863905,
      "grad_norm": 4.047370433807373,
      "learning_rate": 0.0008860000000000001,
      "loss": 1.6148,
      "step": 900
    },
    {
      "epoch": 0.35133136094674555,
      "grad_norm": 2.507937431335449,
      "learning_rate": 0.0008717142857142857,
      "loss": 1.608,
      "step": 950
    },
    {
      "epoch": 0.3698224852071006,
      "grad_norm": 3.6749653816223145,
      "learning_rate": 0.0008574285714285715,
      "loss": 1.5695,
      "step": 1000
    },
    {
      "epoch": 0.38831360946745563,
      "grad_norm": 3.008922576904297,
      "learning_rate": 0.0008431428571428572,
      "loss": 1.5952,
      "step": 1050
    },
    {
      "epoch": 0.4068047337278107,
      "grad_norm": 2.2061939239501953,
      "learning_rate": 0.0008288571428571429,
      "loss": 1.4858,
      "step": 1100
    },
    {
      "epoch": 0.42529585798816566,
      "grad_norm": 2.990302562713623,
      "learning_rate": 0.0008145714285714286,
      "loss": 1.5102,
      "step": 1150
    },
    {
      "epoch": 0.4437869822485207,
      "grad_norm": 3.4479126930236816,
      "learning_rate": 0.0008002857142857143,
      "loss": 1.5277,
      "step": 1200
    },
    {
      "epoch": 0.46227810650887574,
      "grad_norm": 2.776834726333618,
      "learning_rate": 0.000786,
      "loss": 1.5043,
      "step": 1250
    },
    {
      "epoch": 0.4807692307692308,
      "grad_norm": 2.9983856678009033,
      "learning_rate": 0.0007717142857142857,
      "loss": 1.5005,
      "step": 1300
    },
    {
      "epoch": 0.4992603550295858,
      "grad_norm": 3.012640953063965,
      "learning_rate": 0.0007574285714285714,
      "loss": 1.5873,
      "step": 1350
    },
    {
      "epoch": 0.5177514792899408,
      "grad_norm": 2.681802988052368,
      "learning_rate": 0.0007431428571428571,
      "loss": 1.523,
      "step": 1400
    },
    {
      "epoch": 0.5362426035502958,
      "grad_norm": 3.017291784286499,
      "learning_rate": 0.0007288571428571429,
      "loss": 1.4465,
      "step": 1450
    },
    {
      "epoch": 0.5547337278106509,
      "grad_norm": 3.297708749771118,
      "learning_rate": 0.0007145714285714286,
      "loss": 1.5544,
      "step": 1500
    },
    {
      "epoch": 0.5732248520710059,
      "grad_norm": 2.8374130725860596,
      "learning_rate": 0.0007002857142857143,
      "loss": 1.506,
      "step": 1550
    },
    {
      "epoch": 0.591715976331361,
      "grad_norm": 2.5988285541534424,
      "learning_rate": 0.0006860000000000001,
      "loss": 1.543,
      "step": 1600
    },
    {
      "epoch": 0.610207100591716,
      "grad_norm": 3.0008645057678223,
      "learning_rate": 0.0006717142857142857,
      "loss": 1.3944,
      "step": 1650
    },
    {
      "epoch": 0.628698224852071,
      "grad_norm": 3.190598249435425,
      "learning_rate": 0.0006574285714285715,
      "loss": 1.4302,
      "step": 1700
    },
    {
      "epoch": 0.647189349112426,
      "grad_norm": 2.2743453979492188,
      "learning_rate": 0.0006431428571428571,
      "loss": 1.5358,
      "step": 1750
    },
    {
      "epoch": 0.665680473372781,
      "grad_norm": 2.8247883319854736,
      "learning_rate": 0.0006288571428571429,
      "loss": 1.4523,
      "step": 1800
    },
    {
      "epoch": 0.6841715976331361,
      "grad_norm": 3.17610502243042,
      "learning_rate": 0.0006145714285714285,
      "loss": 1.5079,
      "step": 1850
    },
    {
      "epoch": 0.7026627218934911,
      "grad_norm": 3.0226500034332275,
      "learning_rate": 0.0006005714285714285,
      "loss": 1.5228,
      "step": 1900
    },
    {
      "epoch": 0.7211538461538461,
      "grad_norm": 2.276406764984131,
      "learning_rate": 0.0005862857142857143,
      "loss": 1.5265,
      "step": 1950
    },
    {
      "epoch": 0.7396449704142012,
      "grad_norm": 2.5396673679351807,
      "learning_rate": 0.0005719999999999999,
      "loss": 1.414,
      "step": 2000
    },
    {
      "epoch": 0.7581360946745562,
      "grad_norm": 2.7979612350463867,
      "learning_rate": 0.0005577142857142857,
      "loss": 1.4443,
      "step": 2050
    },
    {
      "epoch": 0.7766272189349113,
      "grad_norm": 3.3029325008392334,
      "learning_rate": 0.0005434285714285714,
      "loss": 1.4435,
      "step": 2100
    },
    {
      "epoch": 0.7951183431952663,
      "grad_norm": 2.7507777214050293,
      "learning_rate": 0.0005291428571428571,
      "loss": 1.4376,
      "step": 2150
    },
    {
      "epoch": 0.8136094674556213,
      "grad_norm": 2.485419273376465,
      "learning_rate": 0.000514857142857143,
      "loss": 1.3333,
      "step": 2200
    },
    {
      "epoch": 0.8321005917159763,
      "grad_norm": 3.330690860748291,
      "learning_rate": 0.0005005714285714286,
      "loss": 1.374,
      "step": 2250
    },
    {
      "epoch": 0.8505917159763313,
      "grad_norm": 2.3491361141204834,
      "learning_rate": 0.00048628571428571427,
      "loss": 1.3364,
      "step": 2300
    },
    {
      "epoch": 0.8690828402366864,
      "grad_norm": 2.679278612136841,
      "learning_rate": 0.000472,
      "loss": 1.4039,
      "step": 2350
    },
    {
      "epoch": 0.8875739644970414,
      "grad_norm": 2.664642095565796,
      "learning_rate": 0.00045771428571428574,
      "loss": 1.3838,
      "step": 2400
    },
    {
      "epoch": 0.9060650887573964,
      "grad_norm": 3.1716713905334473,
      "learning_rate": 0.00044342857142857145,
      "loss": 1.4015,
      "step": 2450
    },
    {
      "epoch": 0.9245562130177515,
      "grad_norm": 2.3761043548583984,
      "learning_rate": 0.00042914285714285716,
      "loss": 1.4163,
      "step": 2500
    },
    {
      "epoch": 0.9430473372781065,
      "grad_norm": 2.6050281524658203,
      "learning_rate": 0.00041485714285714287,
      "loss": 1.3254,
      "step": 2550
    },
    {
      "epoch": 0.9615384615384616,
      "grad_norm": 3.414196491241455,
      "learning_rate": 0.0004005714285714286,
      "loss": 1.3238,
      "step": 2600
    },
    {
      "epoch": 0.9800295857988166,
      "grad_norm": 2.478019952774048,
      "learning_rate": 0.0003862857142857143,
      "loss": 1.3222,
      "step": 2650
    },
    {
      "epoch": 0.9985207100591716,
      "grad_norm": 2.863140821456909,
      "learning_rate": 0.000372,
      "loss": 1.4084,
      "step": 2700
    },
    {
      "epoch": 1.0170118343195267,
      "grad_norm": 2.250291347503662,
      "learning_rate": 0.0003577142857142857,
      "loss": 1.2372,
      "step": 2750
    },
    {
      "epoch": 1.0355029585798816,
      "grad_norm": 2.1695704460144043,
      "learning_rate": 0.0003434285714285714,
      "loss": 1.1967,
      "step": 2800
    },
    {
      "epoch": 1.0539940828402368,
      "grad_norm": 2.8435378074645996,
      "learning_rate": 0.0003291428571428571,
      "loss": 1.1745,
      "step": 2850
    },
    {
      "epoch": 1.0724852071005917,
      "grad_norm": 2.4051544666290283,
      "learning_rate": 0.0003148571428571428,
      "loss": 1.1863,
      "step": 2900
    },
    {
      "epoch": 1.0909763313609468,
      "grad_norm": 2.3726768493652344,
      "learning_rate": 0.00030057142857142853,
      "loss": 1.1922,
      "step": 2950
    },
    {
      "epoch": 1.1094674556213018,
      "grad_norm": 2.575228452682495,
      "learning_rate": 0.0002862857142857143,
      "loss": 1.148,
      "step": 3000
    },
    {
      "epoch": 1.1279585798816567,
      "grad_norm": 4.566987037658691,
      "learning_rate": 0.00027200000000000005,
      "loss": 1.0878,
      "step": 3050
    },
    {
      "epoch": 1.1464497041420119,
      "grad_norm": 2.585139513015747,
      "learning_rate": 0.00025771428571428576,
      "loss": 1.215,
      "step": 3100
    },
    {
      "epoch": 1.1649408284023668,
      "grad_norm": 2.1572628021240234,
      "learning_rate": 0.00024342857142857144,
      "loss": 1.1012,
      "step": 3150
    },
    {
      "epoch": 1.183431952662722,
      "grad_norm": 2.5806562900543213,
      "learning_rate": 0.00022914285714285715,
      "loss": 1.1252,
      "step": 3200
    },
    {
      "epoch": 1.2019230769230769,
      "grad_norm": 3.0447311401367188,
      "learning_rate": 0.00021485714285714286,
      "loss": 1.1315,
      "step": 3250
    },
    {
      "epoch": 1.220414201183432,
      "grad_norm": 3.355597496032715,
      "learning_rate": 0.00020057142857142856,
      "loss": 1.2183,
      "step": 3300
    },
    {
      "epoch": 1.238905325443787,
      "grad_norm": 2.469393491744995,
      "learning_rate": 0.00018628571428571427,
      "loss": 1.231,
      "step": 3350
    },
    {
      "epoch": 1.2573964497041419,
      "grad_norm": 2.024102210998535,
      "learning_rate": 0.00017199999999999998,
      "loss": 1.1525,
      "step": 3400
    },
    {
      "epoch": 1.275887573964497,
      "grad_norm": 2.087956666946411,
      "learning_rate": 0.00015771428571428571,
      "loss": 1.1129,
      "step": 3450
    },
    {
      "epoch": 1.2943786982248522,
      "grad_norm": 2.5081188678741455,
      "learning_rate": 0.00014342857142857145,
      "loss": 1.1302,
      "step": 3500
    },
    {
      "epoch": 1.3128698224852071,
      "grad_norm": 2.6013455390930176,
      "learning_rate": 0.00012914285714285716,
      "loss": 1.1653,
      "step": 3550
    },
    {
      "epoch": 1.331360946745562,
      "grad_norm": 2.635552406311035,
      "learning_rate": 0.00011485714285714285,
      "loss": 1.0749,
      "step": 3600
    },
    {
      "epoch": 1.3498520710059172,
      "grad_norm": 2.915666341781616,
      "learning_rate": 0.00010057142857142857,
      "loss": 1.0546,
      "step": 3650
    },
    {
      "epoch": 1.3683431952662721,
      "grad_norm": 2.263371467590332,
      "learning_rate": 8.628571428571428e-05,
      "loss": 1.0778,
      "step": 3700
    },
    {
      "epoch": 1.3868343195266273,
      "grad_norm": 2.3469433784484863,
      "learning_rate": 7.2e-05,
      "loss": 1.0634,
      "step": 3750
    },
    {
      "epoch": 1.4053254437869822,
      "grad_norm": 2.465451717376709,
      "learning_rate": 5.771428571428571e-05,
      "loss": 1.1038,
      "step": 3800
    },
    {
      "epoch": 1.4238165680473374,
      "grad_norm": 2.342189073562622,
      "learning_rate": 4.342857142857143e-05,
      "loss": 1.1611,
      "step": 3850
    },
    {
      "epoch": 1.4423076923076923,
      "grad_norm": 2.065277338027954,
      "learning_rate": 2.9142857142857146e-05,
      "loss": 1.117,
      "step": 3900
    },
    {
      "epoch": 1.4607988165680474,
      "grad_norm": 2.290064573287964,
      "learning_rate": 1.4857142857142857e-05,
      "loss": 1.0559,
      "step": 3950
    },
    {
      "epoch": 1.4792899408284024,
      "grad_norm": 1.8943955898284912,
      "learning_rate": 5.714285714285715e-07,
      "loss": 1.0763,
      "step": 4000
    }
  ],
  "logging_steps": 50,
  "max_steps": 4000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 9.39692630532096e+18,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
