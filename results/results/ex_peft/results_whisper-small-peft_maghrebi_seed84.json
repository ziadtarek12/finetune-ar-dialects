{
  "experiment_name": "whisper-small-peft_maghrebi_seed84",
  "model_name": "whisper-small",
  "dialect": "maghrebi",
  "method": "peft",
  "seed": 84,
  "start_time": "2025-09-26 04:54:48",
  "end_time": "2025-09-26 08:26:58",
  "training_time_seconds": 12729.868757009506,
  "peak_memory_mb": 1292.97705078125,
  "total_params": 245273856,
  "trainable_params": 3538944,
  "trainable_percentage": 1.442854145857274,
  "wer": 89.79958890030832,
  "cer": 58.48358912268071,
  "final_loss": 1.5530004577636718,
  "lora_config": {},
  "parameter_efficiency_ratio": 0,
  "memory_efficiency_ratio": 0.007889089055005521,
  "training_efficiency_score": 2.8846707424748526,
  "convergence_step": 0,
  "gradient_norm_stats": {},
  "layer_adaptation_stats": {},
  "performance_per_param": 2.8823318763144257,
  "lora_rank": 0,
  "lora_alpha": 0,
  "lora_dropout": 0,
  "target_modules_count": 0,
  "adapter_weights_norm": 0,
  "base_model_frozen_params": 0,
  "effective_rank": 0,
  "adaptation_magnitude": 0,
  "model_type": "PEFT_LoRA"
}