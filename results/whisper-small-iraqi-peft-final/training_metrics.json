[
  {
    "loss": 4.0485,
    "grad_norm": 1.611085057258606,
    "learning_rate": 9.6e-05,
    "epoch": 0.031826861871419476,
    "step": 50
  },
  {
    "loss": 2.3584,
    "grad_norm": 1.9300265312194824,
    "learning_rate": 0.00019600000000000002,
    "epoch": 0.06365372374283895,
    "step": 100
  },
  {
    "loss": 1.8984,
    "grad_norm": 1.8525071144104004,
    "learning_rate": 0.000296,
    "epoch": 0.09548058561425843,
    "step": 150
  },
  {
    "loss": 1.6001,
    "grad_norm": 1.6883834600448608,
    "learning_rate": 0.00039600000000000003,
    "epoch": 0.1273074474856779,
    "step": 200
  },
  {
    "loss": 1.6141,
    "grad_norm": 2.50492262840271,
    "learning_rate": 0.000496,
    "epoch": 0.15913430935709738,
    "step": 250
  },
  {
    "loss": 1.5453,
    "grad_norm": 1.921800971031189,
    "learning_rate": 0.000596,
    "epoch": 0.19096117122851686,
    "step": 300
  },
  {
    "loss": 1.5413,
    "grad_norm": 2.8003687858581543,
    "learning_rate": 0.000696,
    "epoch": 0.22278803309993633,
    "step": 350
  },
  {
    "loss": 2.0748,
    "grad_norm": NaN,
    "learning_rate": 0.00079,
    "epoch": 0.2546148949713558,
    "step": 400
  },
  {
    "loss": 7.4272,
    "grad_norm": 3.4802634716033936,
    "learning_rate": 0.0008900000000000001,
    "epoch": 0.2864417568427753,
    "step": 450
  },
  {
    "loss": 4.574,
    "grad_norm": 1.0975773334503174,
    "learning_rate": 0.00099,
    "epoch": 0.31826861871419476,
    "step": 500
  },
  {
    "loss": 4.4379,
    "grad_norm": 0.887409508228302,
    "learning_rate": 0.000982,
    "epoch": 0.35009548058561424,
    "step": 550
  },
  {
    "loss": 4.4485,
    "grad_norm": 2.0327980518341064,
    "learning_rate": 0.000962,
    "epoch": 0.3819223424570337,
    "step": 600
  },
  {
    "loss": 4.3574,
    "grad_norm": 2.105642795562744,
    "learning_rate": 0.000942,
    "epoch": 0.4137492043284532,
    "step": 650
  },
  {
    "loss": 4.3451,
    "grad_norm": 1.355385184288025,
    "learning_rate": 0.0009220000000000001,
    "epoch": 0.44557606619987267,
    "step": 700
  },
  {
    "loss": 4.2852,
    "grad_norm": 0.9521009922027588,
    "learning_rate": 0.000902,
    "epoch": 0.47740292807129214,
    "step": 750
  },
  {
    "loss": 4.2381,
    "grad_norm": 0.7742440104484558,
    "learning_rate": 0.000882,
    "epoch": 0.5092297899427116,
    "step": 800
  },
  {
    "loss": 4.3818,
    "grad_norm": 0.8731873035430908,
    "learning_rate": 0.000862,
    "epoch": 0.5410566518141311,
    "step": 850
  },
  {
    "loss": 4.2134,
    "grad_norm": 0.6480379104614258,
    "learning_rate": 0.000842,
    "epoch": 0.5728835136855506,
    "step": 900
  },
  {
    "loss": 4.1811,
    "grad_norm": 0.7972712516784668,
    "learning_rate": 0.0008219999999999999,
    "epoch": 0.60471037555697,
    "step": 950
  },
  {
    "loss": 4.0966,
    "grad_norm": 0.670138955116272,
    "learning_rate": 0.0008020000000000001,
    "epoch": 0.6365372374283895,
    "step": 1000
  },
  {
    "loss": 4.1028,
    "grad_norm": 1.0028945207595825,
    "learning_rate": 0.000782,
    "epoch": 0.668364099299809,
    "step": 1050
  },
  {
    "loss": 4.1085,
    "grad_norm": 0.8432509899139404,
    "learning_rate": 0.000762,
    "epoch": 0.7001909611712285,
    "step": 1100
  },
  {
    "loss": 3.9875,
    "grad_norm": 0.9325047135353088,
    "learning_rate": 0.000742,
    "epoch": 0.732017823042648,
    "step": 1150
  },
  {
    "loss": 3.9786,
    "grad_norm": 1.0563809871673584,
    "learning_rate": 0.000722,
    "epoch": 0.7638446849140674,
    "step": 1200
  },
  {
    "loss": 3.975,
    "grad_norm": 0.9181821346282959,
    "learning_rate": 0.0007019999999999999,
    "epoch": 0.7956715467854869,
    "step": 1250
  },
  {
    "loss": 3.909,
    "grad_norm": 1.2548397779464722,
    "learning_rate": 0.0006820000000000001,
    "epoch": 0.8274984086569064,
    "step": 1300
  },
  {
    "loss": 3.8722,
    "grad_norm": 1.0012025833129883,
    "learning_rate": 0.000662,
    "epoch": 0.8593252705283259,
    "step": 1350
  },
  {
    "loss": 3.8586,
    "grad_norm": 1.147944450378418,
    "learning_rate": 0.000642,
    "epoch": 0.8911521323997453,
    "step": 1400
  },
  {
    "loss": 3.8884,
    "grad_norm": 24.051029205322266,
    "learning_rate": 0.000622,
    "epoch": 0.9229789942711648,
    "step": 1450
  },
  {
    "loss": 3.9084,
    "grad_norm": 1.1696157455444336,
    "learning_rate": 0.000602,
    "epoch": 0.9548058561425843,
    "step": 1500
  },
  {
    "loss": 3.8504,
    "grad_norm": 1.4156063795089722,
    "learning_rate": 0.0005819999999999999,
    "epoch": 0.9866327180140039,
    "step": 1550
  },
  {
    "loss": 3.7309,
    "grad_norm": 1.3064062595367432,
    "learning_rate": 0.0005620000000000001,
    "epoch": 1.0184595798854232,
    "step": 1600
  },
  {
    "loss": 3.7712,
    "grad_norm": 1.1466727256774902,
    "learning_rate": 0.0005420000000000001,
    "epoch": 1.0502864417568427,
    "step": 1650
  },
  {
    "loss": 3.7503,
    "grad_norm": 1.1081433296203613,
    "learning_rate": 0.000522,
    "epoch": 1.0821133036282622,
    "step": 1700
  },
  {
    "loss": 3.7524,
    "grad_norm": 1.1547672748565674,
    "learning_rate": 0.0005020000000000001,
    "epoch": 1.1139401654996817,
    "step": 1750
  },
  {
    "loss": 3.6554,
    "grad_norm": 1.1653021574020386,
    "learning_rate": 0.000482,
    "epoch": 1.1457670273711011,
    "step": 1800
  },
  {
    "loss": 3.645,
    "grad_norm": 1.207334280014038,
    "learning_rate": 0.000462,
    "epoch": 1.1775938892425206,
    "step": 1850
  },
  {
    "loss": 3.6151,
    "grad_norm": 1.0975010395050049,
    "learning_rate": 0.000442,
    "epoch": 1.20942075111394,
    "step": 1900
  },
  {
    "loss": 3.6658,
    "grad_norm": 1.2215875387191772,
    "learning_rate": 0.000422,
    "epoch": 1.2412476129853596,
    "step": 1950
  },
  {
    "loss": 3.6338,
    "grad_norm": 0.9549890160560608,
    "learning_rate": 0.000402,
    "epoch": 1.273074474856779,
    "step": 2000
  },
  {
    "loss": 3.6022,
    "grad_norm": 1.2381536960601807,
    "learning_rate": 0.000382,
    "epoch": 1.3049013367281985,
    "step": 2050
  },
  {
    "loss": 3.5947,
    "grad_norm": 1.1283724308013916,
    "learning_rate": 0.000362,
    "epoch": 1.336728198599618,
    "step": 2100
  },
  {
    "loss": 3.575,
    "grad_norm": 1.408435344696045,
    "learning_rate": 0.000342,
    "epoch": 1.3685550604710375,
    "step": 2150
  },
  {
    "loss": 3.5436,
    "grad_norm": 1.4521616697311401,
    "learning_rate": 0.000322,
    "epoch": 1.400381922342457,
    "step": 2200
  },
  {
    "loss": 3.4459,
    "grad_norm": 1.6532436609268188,
    "learning_rate": 0.000302,
    "epoch": 1.4322087842138764,
    "step": 2250
  },
  {
    "loss": 3.5194,
    "grad_norm": 1.1053410768508911,
    "learning_rate": 0.00028199999999999997,
    "epoch": 1.464035646085296,
    "step": 2300
  },
  {
    "loss": 3.5355,
    "grad_norm": 1.515645146369934,
    "learning_rate": 0.000262,
    "epoch": 1.4958625079567156,
    "step": 2350
  },
  {
    "loss": 3.5187,
    "grad_norm": 2.0032806396484375,
    "learning_rate": 0.000242,
    "epoch": 1.5276893698281349,
    "step": 2400
  },
  {
    "loss": 3.4943,
    "grad_norm": 1.5398756265640259,
    "learning_rate": 0.000222,
    "epoch": 1.5595162316995546,
    "step": 2450
  },
  {
    "loss": 3.4574,
    "grad_norm": 1.3489675521850586,
    "learning_rate": 0.000202,
    "epoch": 1.5913430935709738,
    "step": 2500
  },
  {
    "loss": 3.4667,
    "grad_norm": 1.4033453464508057,
    "learning_rate": 0.000182,
    "epoch": 1.6231699554423935,
    "step": 2550
  },
  {
    "loss": 3.4771,
    "grad_norm": 1.4091641902923584,
    "learning_rate": 0.000162,
    "epoch": 1.6549968173138128,
    "step": 2600
  },
  {
    "loss": 3.4386,
    "grad_norm": 1.3760007619857788,
    "learning_rate": 0.00014199999999999998,
    "epoch": 1.6868236791852325,
    "step": 2650
  },
  {
    "loss": 3.3846,
    "grad_norm": 1.385353684425354,
    "learning_rate": 0.000122,
    "epoch": 1.7186505410566517,
    "step": 2700
  },
  {
    "loss": 3.3877,
    "grad_norm": 1.7099902629852295,
    "learning_rate": 0.000102,
    "epoch": 1.7504774029280714,
    "step": 2750
  },
  {
    "loss": 3.4843,
    "grad_norm": 1.463066577911377,
    "learning_rate": 8.2e-05,
    "epoch": 1.7823042647994907,
    "step": 2800
  },
  {
    "loss": 3.3927,
    "grad_norm": 1.4445905685424805,
    "learning_rate": 6.2e-05,
    "epoch": 1.8141311266709104,
    "step": 2850
  },
  {
    "loss": 3.4092,
    "grad_norm": 1.4373623132705688,
    "learning_rate": 4.2000000000000004e-05,
    "epoch": 1.8459579885423296,
    "step": 2900
  },
  {
    "loss": 3.4341,
    "grad_norm": 1.5426995754241943,
    "learning_rate": 2.2e-05,
    "epoch": 1.8777848504137493,
    "step": 2950
  },
  {
    "loss": 3.4114,
    "grad_norm": 1.3798503875732422,
    "learning_rate": 2e-06,
    "epoch": 1.9096117122851686,
    "step": 3000
  },
  {
    "train_runtime": 9679.1238,
    "train_samples_per_second": 2.48,
    "train_steps_per_second": 0.31,
    "total_flos": 7.04718078640128e+18,
    "train_loss": 3.631657305399577,
    "epoch": 1.9096117122851686,
    "step": 3000
  }
]