[
  {
    "loss": 4.0932,
    "grad_norm": 2.068079710006714,
    "learning_rate": 9.800000000000001e-05,
    "epoch": 0.031826861871419476,
    "step": 50
  },
  {
    "loss": 2.376,
    "grad_norm": 2.1193149089813232,
    "learning_rate": 0.00019800000000000002,
    "epoch": 0.06365372374283895,
    "step": 100
  },
  {
    "loss": 1.832,
    "grad_norm": 2.6618711948394775,
    "learning_rate": 0.000298,
    "epoch": 0.09548058561425843,
    "step": 150
  },
  {
    "loss": 1.6526,
    "grad_norm": 2.3447039127349854,
    "learning_rate": 0.000398,
    "epoch": 0.1273074474856779,
    "step": 200
  },
  {
    "loss": 1.5297,
    "grad_norm": 1.572648048400879,
    "learning_rate": 0.000498,
    "epoch": 0.15913430935709738,
    "step": 250
  },
  {
    "loss": 1.5269,
    "grad_norm": 1.8869599103927612,
    "learning_rate": 0.000598,
    "epoch": 0.19096117122851686,
    "step": 300
  },
  {
    "loss": 1.5731,
    "grad_norm": 2.2364206314086914,
    "learning_rate": 0.0006979999999999999,
    "epoch": 0.22278803309993633,
    "step": 350
  },
  {
    "loss": 1.6151,
    "grad_norm": 1.8653918504714966,
    "learning_rate": 0.0007980000000000001,
    "epoch": 0.2546148949713558,
    "step": 400
  },
  {
    "loss": 1.9842,
    "grad_norm": 2.442237138748169,
    "learning_rate": 0.000892,
    "epoch": 0.2864417568427753,
    "step": 450
  },
  {
    "loss": 1.5942,
    "grad_norm": 3.1483280658721924,
    "learning_rate": 0.000992,
    "epoch": 0.31826861871419476,
    "step": 500
  },
  {
    "loss": 1.5998,
    "grad_norm": 3.1143200397491455,
    "learning_rate": 0.0009816,
    "epoch": 0.35009548058561424,
    "step": 550
  },
  {
    "loss": 1.6793,
    "grad_norm": 3.0609495639801025,
    "learning_rate": 0.0009616000000000001,
    "epoch": 0.3819223424570337,
    "step": 600
  },
  {
    "loss": 1.7366,
    "grad_norm": 3.066903591156006,
    "learning_rate": 0.0009416,
    "epoch": 0.4137492043284532,
    "step": 650
  },
  {
    "loss": 1.6047,
    "grad_norm": 3.3753437995910645,
    "learning_rate": 0.0009216,
    "epoch": 0.44557606619987267,
    "step": 700
  },
  {
    "loss": 1.7233,
    "grad_norm": 3.515737295150757,
    "learning_rate": 0.0009016,
    "epoch": 0.47740292807129214,
    "step": 750
  },
  {
    "loss": 1.5978,
    "grad_norm": 3.825981855392456,
    "learning_rate": 0.0008816000000000001,
    "epoch": 0.5092297899427116,
    "step": 800
  },
  {
    "loss": 1.5581,
    "grad_norm": 2.422363519668579,
    "learning_rate": 0.0008616,
    "epoch": 0.5410566518141311,
    "step": 850
  },
  {
    "loss": 1.582,
    "grad_norm": 2.5461504459381104,
    "learning_rate": 0.0008416000000000001,
    "epoch": 0.5728835136855506,
    "step": 900
  },
  {
    "loss": 1.5183,
    "grad_norm": 3.3671317100524902,
    "learning_rate": 0.0008216,
    "epoch": 0.60471037555697,
    "step": 950
  },
  {
    "loss": 1.5291,
    "grad_norm": 3.4708869457244873,
    "learning_rate": 0.0008016,
    "epoch": 0.6365372374283895,
    "step": 1000
  },
  {
    "loss": 1.5306,
    "grad_norm": 2.4726617336273193,
    "learning_rate": 0.0007816,
    "epoch": 0.668364099299809,
    "step": 1050
  },
  {
    "loss": 1.5923,
    "grad_norm": 2.4545605182647705,
    "learning_rate": 0.0007616000000000001,
    "epoch": 0.7001909611712285,
    "step": 1100
  },
  {
    "loss": 1.4839,
    "grad_norm": 2.1140036582946777,
    "learning_rate": 0.0007416,
    "epoch": 0.732017823042648,
    "step": 1150
  },
  {
    "loss": 1.5892,
    "grad_norm": 3.284132242202759,
    "learning_rate": 0.0007216000000000001,
    "epoch": 0.7638446849140674,
    "step": 1200
  },
  {
    "loss": 1.4585,
    "grad_norm": 2.6186561584472656,
    "learning_rate": 0.0007016,
    "epoch": 0.7956715467854869,
    "step": 1250
  },
  {
    "loss": 1.4588,
    "grad_norm": 3.4403553009033203,
    "learning_rate": 0.0006816,
    "epoch": 0.8274984086569064,
    "step": 1300
  },
  {
    "loss": 1.4901,
    "grad_norm": 2.6112136840820312,
    "learning_rate": 0.0006615999999999999,
    "epoch": 0.8593252705283259,
    "step": 1350
  },
  {
    "loss": 1.4946,
    "grad_norm": 2.584719181060791,
    "learning_rate": 0.0006416,
    "epoch": 0.8911521323997453,
    "step": 1400
  },
  {
    "loss": 1.4313,
    "grad_norm": 3.177412271499634,
    "learning_rate": 0.0006216,
    "epoch": 0.9229789942711648,
    "step": 1450
  },
  {
    "loss": 1.4961,
    "grad_norm": 2.8063790798187256,
    "learning_rate": 0.0006016,
    "epoch": 0.9548058561425843,
    "step": 1500
  },
  {
    "loss": 1.4636,
    "grad_norm": 4.712013244628906,
    "learning_rate": 0.0005816,
    "epoch": 0.9866327180140039,
    "step": 1550
  },
  {
    "loss": 4.7321,
    "grad_norm": 2.6126997470855713,
    "learning_rate": 0.0005616,
    "epoch": 1.0184595798854232,
    "step": 1600
  },
  {
    "loss": 1.2998,
    "grad_norm": 3.412630081176758,
    "learning_rate": 0.0005415999999999999,
    "epoch": 1.0502864417568427,
    "step": 1650
  },
  {
    "loss": 1.195,
    "grad_norm": 2.7424678802490234,
    "learning_rate": 0.0005216,
    "epoch": 1.0821133036282622,
    "step": 1700
  },
  {
    "loss": 1.2218,
    "grad_norm": 3.5848751068115234,
    "learning_rate": 0.0005016,
    "epoch": 1.1139401654996817,
    "step": 1750
  },
  {
    "loss": 1.3046,
    "grad_norm": 2.7384583950042725,
    "learning_rate": 0.0004816,
    "epoch": 1.1457670273711011,
    "step": 1800
  },
  {
    "loss": 1.2655,
    "grad_norm": 2.96517014503479,
    "learning_rate": 0.0004616,
    "epoch": 1.1775938892425206,
    "step": 1850
  },
  {
    "loss": 1.2773,
    "grad_norm": 2.840569019317627,
    "learning_rate": 0.0004416,
    "epoch": 1.20942075111394,
    "step": 1900
  },
  {
    "loss": 1.2796,
    "grad_norm": 2.274104356765747,
    "learning_rate": 0.0004216,
    "epoch": 1.2412476129853596,
    "step": 1950
  },
  {
    "loss": 1.2557,
    "grad_norm": 2.716576099395752,
    "learning_rate": 0.0004016,
    "epoch": 1.273074474856779,
    "step": 2000
  },
  {
    "loss": 1.2361,
    "grad_norm": 2.3952882289886475,
    "learning_rate": 0.0003816,
    "epoch": 1.3049013367281985,
    "step": 2050
  },
  {
    "loss": 1.2521,
    "grad_norm": 2.339120626449585,
    "learning_rate": 0.0003616,
    "epoch": 1.336728198599618,
    "step": 2100
  },
  {
    "loss": 1.1871,
    "grad_norm": 1.7202666997909546,
    "learning_rate": 0.0003416,
    "epoch": 1.3685550604710375,
    "step": 2150
  },
  {
    "loss": 1.2651,
    "grad_norm": 2.300281047821045,
    "learning_rate": 0.0003216,
    "epoch": 1.400381922342457,
    "step": 2200
  },
  {
    "loss": 1.2877,
    "grad_norm": 2.3316917419433594,
    "learning_rate": 0.00030159999999999996,
    "epoch": 1.4322087842138764,
    "step": 2250
  },
  {
    "loss": 1.2602,
    "grad_norm": 2.129770517349243,
    "learning_rate": 0.0002816,
    "epoch": 1.464035646085296,
    "step": 2300
  },
  {
    "loss": 1.1199,
    "grad_norm": 2.535768985748291,
    "learning_rate": 0.0002616,
    "epoch": 1.4958625079567156,
    "step": 2350
  },
  {
    "loss": 1.0819,
    "grad_norm": 2.796251058578491,
    "learning_rate": 0.00024160000000000002,
    "epoch": 1.5276893698281349,
    "step": 2400
  },
  {
    "loss": 1.2256,
    "grad_norm": 1.9928622245788574,
    "learning_rate": 0.0002216,
    "epoch": 1.5595162316995546,
    "step": 2450
  },
  {
    "loss": 1.1779,
    "grad_norm": 2.5305280685424805,
    "learning_rate": 0.0002016,
    "epoch": 1.5913430935709738,
    "step": 2500
  },
  {
    "loss": 1.1402,
    "grad_norm": 2.4409801959991455,
    "learning_rate": 0.00018160000000000002,
    "epoch": 1.6231699554423935,
    "step": 2550
  },
  {
    "loss": 1.1137,
    "grad_norm": 3.104377508163452,
    "learning_rate": 0.0001616,
    "epoch": 1.6549968173138128,
    "step": 2600
  },
  {
    "loss": 1.1848,
    "grad_norm": 3.3948237895965576,
    "learning_rate": 0.0001416,
    "epoch": 1.6868236791852325,
    "step": 2650
  },
  {
    "loss": 1.1042,
    "grad_norm": 1.9620765447616577,
    "learning_rate": 0.0001216,
    "epoch": 1.7186505410566517,
    "step": 2700
  },
  {
    "loss": 1.1262,
    "grad_norm": 2.440648317337036,
    "learning_rate": 0.0001016,
    "epoch": 1.7504774029280714,
    "step": 2750
  },
  {
    "loss": 1.1311,
    "grad_norm": 2.4610586166381836,
    "learning_rate": 8.16e-05,
    "epoch": 1.7823042647994907,
    "step": 2800
  },
  {
    "loss": 1.1016,
    "grad_norm": 1.8200007677078247,
    "learning_rate": 6.16e-05,
    "epoch": 1.8141311266709104,
    "step": 2850
  },
  {
    "loss": 1.103,
    "grad_norm": 2.5204851627349854,
    "learning_rate": 4.16e-05,
    "epoch": 1.8459579885423296,
    "step": 2900
  },
  {
    "loss": 1.1638,
    "grad_norm": 2.1061391830444336,
    "learning_rate": 2.1600000000000003e-05,
    "epoch": 1.8777848504137493,
    "step": 2950
  },
  {
    "loss": 1.1559,
    "grad_norm": 2.113422155380249,
    "learning_rate": 1.6000000000000001e-06,
    "epoch": 1.9096117122851686,
    "step": 3000
  },
  {
    "train_runtime": 9852.1476,
    "train_samples_per_second": 2.436,
    "train_steps_per_second": 0.305,
    "total_flos": 7.04718078640128e+18,
    "train_loss": 1.510740119934082,
    "epoch": 1.9096117122851686,
    "step": 3000
  }
]