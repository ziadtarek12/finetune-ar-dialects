[
  {
    "loss": 4.0363,
    "grad_norm": 2.3000428676605225,
    "learning_rate": 9.6e-05,
    "epoch": 0.031826861871419476,
    "step": 50
  },
  {
    "loss": 2.3919,
    "grad_norm": 2.172055244445801,
    "learning_rate": 0.00019600000000000002,
    "epoch": 0.06365372374283895,
    "step": 100
  },
  {
    "loss": 1.8805,
    "grad_norm": 2.294435501098633,
    "learning_rate": 0.000296,
    "epoch": 0.09548058561425843,
    "step": 150
  },
  {
    "loss": 1.5347,
    "grad_norm": 2.515768051147461,
    "learning_rate": 0.00039600000000000003,
    "epoch": 0.1273074474856779,
    "step": 200
  },
  {
    "loss": 1.5011,
    "grad_norm": 1.97316312789917,
    "learning_rate": 0.000494,
    "epoch": 0.15913430935709738,
    "step": 250
  },
  {
    "loss": 1.6317,
    "grad_norm": 2.1907761096954346,
    "learning_rate": 0.000594,
    "epoch": 0.19096117122851686,
    "step": 300
  },
  {
    "loss": 1.5818,
    "grad_norm": 1.9786409139633179,
    "learning_rate": 0.000694,
    "epoch": 0.22278803309993633,
    "step": 350
  },
  {
    "loss": 1.5187,
    "grad_norm": 2.170177698135376,
    "learning_rate": 0.0007940000000000001,
    "epoch": 0.2546148949713558,
    "step": 400
  },
  {
    "loss": 1.6311,
    "grad_norm": 2.786592483520508,
    "learning_rate": 0.000894,
    "epoch": 0.2864417568427753,
    "step": 450
  },
  {
    "loss": 1.5484,
    "grad_norm": 2.632298231124878,
    "learning_rate": 0.000994,
    "epoch": 0.31826861871419476,
    "step": 500
  },
  {
    "loss": 1.5792,
    "grad_norm": 2.623875379562378,
    "learning_rate": 0.0009812,
    "epoch": 0.35009548058561424,
    "step": 550
  },
  {
    "loss": 5.6156,
    "grad_norm": 2.0001585483551025,
    "learning_rate": 0.000962,
    "epoch": 0.3819223424570337,
    "step": 600
  },
  {
    "loss": 4.7891,
    "grad_norm": 0.8600912690162659,
    "learning_rate": 0.000942,
    "epoch": 0.4137492043284532,
    "step": 650
  },
  {
    "loss": 4.5031,
    "grad_norm": 0.9485581517219543,
    "learning_rate": 0.0009220000000000001,
    "epoch": 0.44557606619987267,
    "step": 700
  },
  {
    "loss": 4.3509,
    "grad_norm": 1.6100008487701416,
    "learning_rate": 0.000902,
    "epoch": 0.47740292807129214,
    "step": 750
  },
  {
    "loss": 4.2919,
    "grad_norm": 1.0085641145706177,
    "learning_rate": 0.000882,
    "epoch": 0.5092297899427116,
    "step": 800
  },
  {
    "loss": 4.1638,
    "grad_norm": 1.425808310508728,
    "learning_rate": 0.000862,
    "epoch": 0.5410566518141311,
    "step": 850
  },
  {
    "loss": 3.9778,
    "grad_norm": 3.1432249546051025,
    "learning_rate": 0.000842,
    "epoch": 0.5728835136855506,
    "step": 900
  },
  {
    "loss": 3.1186,
    "grad_norm": 3.6346852779388428,
    "learning_rate": 0.0008219999999999999,
    "epoch": 0.60471037555697,
    "step": 950
  },
  {
    "loss": 1.7813,
    "grad_norm": 3.1038320064544678,
    "learning_rate": 0.0008020000000000001,
    "epoch": 0.6365372374283895,
    "step": 1000
  },
  {
    "loss": 1.8104,
    "grad_norm": 3.507328748703003,
    "learning_rate": 0.000782,
    "epoch": 0.668364099299809,
    "step": 1050
  },
  {
    "loss": 1.7213,
    "grad_norm": 3.325559139251709,
    "learning_rate": 0.000762,
    "epoch": 0.7001909611712285,
    "step": 1100
  },
  {
    "loss": 1.5473,
    "grad_norm": 3.249124765396118,
    "learning_rate": 0.000742,
    "epoch": 0.732017823042648,
    "step": 1150
  },
  {
    "loss": 1.5779,
    "grad_norm": 2.7498576641082764,
    "learning_rate": 0.000722,
    "epoch": 0.7638446849140674,
    "step": 1200
  },
  {
    "loss": 1.5702,
    "grad_norm": 2.812812089920044,
    "learning_rate": 0.0007019999999999999,
    "epoch": 0.7956715467854869,
    "step": 1250
  },
  {
    "loss": 1.5447,
    "grad_norm": 3.11810040473938,
    "learning_rate": 0.0006820000000000001,
    "epoch": 0.8274984086569064,
    "step": 1300
  },
  {
    "loss": 1.5592,
    "grad_norm": 3.3576266765594482,
    "learning_rate": 0.000662,
    "epoch": 0.8593252705283259,
    "step": 1350
  },
  {
    "loss": 1.561,
    "grad_norm": 3.212571859359741,
    "learning_rate": 0.000642,
    "epoch": 0.8911521323997453,
    "step": 1400
  },
  {
    "loss": 1.492,
    "grad_norm": 2.835757255554199,
    "learning_rate": 0.000622,
    "epoch": 0.9229789942711648,
    "step": 1450
  },
  {
    "loss": 1.4323,
    "grad_norm": 2.6017069816589355,
    "learning_rate": 0.000602,
    "epoch": 0.9548058561425843,
    "step": 1500
  },
  {
    "loss": 1.5161,
    "grad_norm": 2.6377973556518555,
    "learning_rate": 0.0005819999999999999,
    "epoch": 0.9866327180140039,
    "step": 1550
  },
  {
    "loss": 1.3944,
    "grad_norm": 3.1323554515838623,
    "learning_rate": 0.0005620000000000001,
    "epoch": 1.0184595798854232,
    "step": 1600
  },
  {
    "loss": 1.2733,
    "grad_norm": 2.5551185607910156,
    "learning_rate": 0.0005420000000000001,
    "epoch": 1.0502864417568427,
    "step": 1650
  },
  {
    "loss": 1.3234,
    "grad_norm": 2.4494965076446533,
    "learning_rate": 0.000522,
    "epoch": 1.0821133036282622,
    "step": 1700
  },
  {
    "loss": 1.2761,
    "grad_norm": 3.30340576171875,
    "learning_rate": 0.0005020000000000001,
    "epoch": 1.1139401654996817,
    "step": 1750
  },
  {
    "loss": 1.3378,
    "grad_norm": 2.642831563949585,
    "learning_rate": 0.000482,
    "epoch": 1.1457670273711011,
    "step": 1800
  },
  {
    "loss": 1.3533,
    "grad_norm": 1.8747005462646484,
    "learning_rate": 0.000462,
    "epoch": 1.1775938892425206,
    "step": 1850
  },
  {
    "loss": 1.3681,
    "grad_norm": 3.339212417602539,
    "learning_rate": 0.000442,
    "epoch": 1.20942075111394,
    "step": 1900
  },
  {
    "loss": 1.3398,
    "grad_norm": 3.1819276809692383,
    "learning_rate": 0.000422,
    "epoch": 1.2412476129853596,
    "step": 1950
  },
  {
    "loss": 1.2868,
    "grad_norm": 2.4106802940368652,
    "learning_rate": 0.000402,
    "epoch": 1.273074474856779,
    "step": 2000
  },
  {
    "loss": 1.2911,
    "grad_norm": 2.9441781044006348,
    "learning_rate": 0.000382,
    "epoch": 1.3049013367281985,
    "step": 2050
  },
  {
    "loss": 1.2562,
    "grad_norm": 2.672335147857666,
    "learning_rate": 0.000362,
    "epoch": 1.336728198599618,
    "step": 2100
  },
  {
    "loss": 1.2828,
    "grad_norm": 1.6444568634033203,
    "learning_rate": 0.000342,
    "epoch": 1.3685550604710375,
    "step": 2150
  },
  {
    "loss": 1.2545,
    "grad_norm": 2.5507736206054688,
    "learning_rate": 0.000322,
    "epoch": 1.400381922342457,
    "step": 2200
  },
  {
    "loss": 1.2523,
    "grad_norm": 2.2537178993225098,
    "learning_rate": 0.000302,
    "epoch": 1.4322087842138764,
    "step": 2250
  },
  {
    "loss": 1.2453,
    "grad_norm": 2.6768903732299805,
    "learning_rate": 0.00028199999999999997,
    "epoch": 1.464035646085296,
    "step": 2300
  },
  {
    "loss": 1.2865,
    "grad_norm": 2.3311007022857666,
    "learning_rate": 0.000262,
    "epoch": 1.4958625079567156,
    "step": 2350
  },
  {
    "loss": 1.2859,
    "grad_norm": 2.1598193645477295,
    "learning_rate": 0.000242,
    "epoch": 1.5276893698281349,
    "step": 2400
  },
  {
    "loss": 1.213,
    "grad_norm": 2.3773856163024902,
    "learning_rate": 0.000222,
    "epoch": 1.5595162316995546,
    "step": 2450
  },
  {
    "loss": 1.2056,
    "grad_norm": 2.0311479568481445,
    "learning_rate": 0.000202,
    "epoch": 1.5913430935709738,
    "step": 2500
  },
  {
    "loss": 1.1282,
    "grad_norm": 2.2086539268493652,
    "learning_rate": 0.000182,
    "epoch": 1.6231699554423935,
    "step": 2550
  },
  {
    "loss": 1.2274,
    "grad_norm": 1.9709604978561401,
    "learning_rate": 0.000162,
    "epoch": 1.6549968173138128,
    "step": 2600
  },
  {
    "loss": 1.2545,
    "grad_norm": 2.030836582183838,
    "learning_rate": 0.00014199999999999998,
    "epoch": 1.6868236791852325,
    "step": 2650
  },
  {
    "loss": 1.1947,
    "grad_norm": 2.4186513423919678,
    "learning_rate": 0.000122,
    "epoch": 1.7186505410566517,
    "step": 2700
  },
  {
    "loss": 1.1926,
    "grad_norm": 2.6331021785736084,
    "learning_rate": 0.000102,
    "epoch": 1.7504774029280714,
    "step": 2750
  },
  {
    "loss": 1.1746,
    "grad_norm": 2.245744228363037,
    "learning_rate": 8.2e-05,
    "epoch": 1.7823042647994907,
    "step": 2800
  },
  {
    "loss": 1.2063,
    "grad_norm": 2.0004618167877197,
    "learning_rate": 6.2e-05,
    "epoch": 1.8141311266709104,
    "step": 2850
  },
  {
    "loss": 1.1519,
    "grad_norm": 2.652353525161743,
    "learning_rate": 4.2000000000000004e-05,
    "epoch": 1.8459579885423296,
    "step": 2900
  },
  {
    "loss": 1.2308,
    "grad_norm": 2.388362407684326,
    "learning_rate": 2.2e-05,
    "epoch": 1.8777848504137493,
    "step": 2950
  },
  {
    "loss": 1.1789,
    "grad_norm": 2.0227150917053223,
    "learning_rate": 2e-06,
    "epoch": 1.9096117122851686,
    "step": 3000
  },
  {
    "train_runtime": 9598.0349,
    "train_samples_per_second": 2.501,
    "train_steps_per_second": 0.313,
    "total_flos": 7.04718078640128e+18,
    "train_loss": 1.853769064585368,
    "epoch": 1.9096117122851686,
    "step": 3000
  }
]