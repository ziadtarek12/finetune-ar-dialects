[
  {
    "loss": 4.0259,
    "grad_norm": 2.2722866535186768,
    "learning_rate": 9.800000000000001e-05,
    "epoch": 0.031826861871419476,
    "step": 50
  },
  {
    "loss": 2.3918,
    "grad_norm": 2.344414472579956,
    "learning_rate": 0.00019800000000000002,
    "epoch": 0.06365372374283895,
    "step": 100
  },
  {
    "loss": 1.8899,
    "grad_norm": 2.1818785667419434,
    "learning_rate": 0.000298,
    "epoch": 0.09548058561425843,
    "step": 150
  },
  {
    "loss": 1.5337,
    "grad_norm": 2.473536491394043,
    "learning_rate": 0.000398,
    "epoch": 0.1273074474856779,
    "step": 200
  },
  {
    "loss": 5.5505,
    "grad_norm": 2.143906831741333,
    "learning_rate": 0.000486,
    "epoch": 0.15913430935709738,
    "step": 250
  },
  {
    "loss": 6.5262,
    "grad_norm": 1.6322802305221558,
    "learning_rate": 0.0005859999999999999,
    "epoch": 0.19096117122851686,
    "step": 300
  },
  {
    "loss": 4.537,
    "grad_norm": 1.7248255014419556,
    "learning_rate": 0.0006860000000000001,
    "epoch": 0.22278803309993633,
    "step": 350
  },
  {
    "loss": 4.3515,
    "grad_norm": 4.305453300476074,
    "learning_rate": 0.000786,
    "epoch": 0.2546148949713558,
    "step": 400
  },
  {
    "loss": 2.2462,
    "grad_norm": 3.587379217147827,
    "learning_rate": 0.0008860000000000001,
    "epoch": 0.2864417568427753,
    "step": 450
  },
  {
    "loss": 1.691,
    "grad_norm": 3.2009153366088867,
    "learning_rate": 0.0009860000000000001,
    "epoch": 0.31826861871419476,
    "step": 500
  },
  {
    "loss": 1.6864,
    "grad_norm": 3.4163928031921387,
    "learning_rate": 0.0009828,
    "epoch": 0.35009548058561424,
    "step": 550
  },
  {
    "loss": 1.7786,
    "grad_norm": 2.868835210800171,
    "learning_rate": 0.0009628,
    "epoch": 0.3819223424570337,
    "step": 600
  },
  {
    "loss": 1.7099,
    "grad_norm": 3.633357524871826,
    "learning_rate": 0.0009428,
    "epoch": 0.4137492043284532,
    "step": 650
  },
  {
    "loss": 1.7366,
    "grad_norm": 2.9878804683685303,
    "learning_rate": 0.0009228,
    "epoch": 0.44557606619987267,
    "step": 700
  },
  {
    "loss": 1.7438,
    "grad_norm": 3.1973273754119873,
    "learning_rate": 0.0009028,
    "epoch": 0.47740292807129214,
    "step": 750
  },
  {
    "loss": 1.6765,
    "grad_norm": 2.6570513248443604,
    "learning_rate": 0.0008828000000000001,
    "epoch": 0.5092297899427116,
    "step": 800
  },
  {
    "loss": 1.7315,
    "grad_norm": 3.444647789001465,
    "learning_rate": 0.0008628,
    "epoch": 0.5410566518141311,
    "step": 850
  },
  {
    "loss": 1.6459,
    "grad_norm": 2.4746463298797607,
    "learning_rate": 0.0008428,
    "epoch": 0.5728835136855506,
    "step": 900
  },
  {
    "loss": 1.5947,
    "grad_norm": 2.4231929779052734,
    "learning_rate": 0.0008227999999999999,
    "epoch": 0.60471037555697,
    "step": 950
  },
  {
    "loss": 1.5789,
    "grad_norm": 3.8202524185180664,
    "learning_rate": 0.0008028,
    "epoch": 0.6365372374283895,
    "step": 1000
  },
  {
    "loss": 1.6829,
    "grad_norm": 2.9820587635040283,
    "learning_rate": 0.0007828,
    "epoch": 0.668364099299809,
    "step": 1050
  },
  {
    "loss": 1.6468,
    "grad_norm": 3.061793327331543,
    "learning_rate": 0.0007628,
    "epoch": 0.7001909611712285,
    "step": 1100
  },
  {
    "loss": 1.4705,
    "grad_norm": 3.5729520320892334,
    "learning_rate": 0.0007428000000000001,
    "epoch": 0.732017823042648,
    "step": 1150
  },
  {
    "loss": 1.529,
    "grad_norm": 2.7140517234802246,
    "learning_rate": 0.0007228,
    "epoch": 0.7638446849140674,
    "step": 1200
  },
  {
    "loss": 1.5385,
    "grad_norm": 2.575308322906494,
    "learning_rate": 0.0007028,
    "epoch": 0.7956715467854869,
    "step": 1250
  },
  {
    "loss": 1.5013,
    "grad_norm": 2.704627275466919,
    "learning_rate": 0.0006828,
    "epoch": 0.8274984086569064,
    "step": 1300
  },
  {
    "loss": 1.5186,
    "grad_norm": 3.4752156734466553,
    "learning_rate": 0.0006628,
    "epoch": 0.8593252705283259,
    "step": 1350
  },
  {
    "loss": 1.5301,
    "grad_norm": 2.828559160232544,
    "learning_rate": 0.0006428,
    "epoch": 0.8911521323997453,
    "step": 1400
  },
  {
    "loss": 1.4551,
    "grad_norm": 3.172903299331665,
    "learning_rate": 0.0006228000000000001,
    "epoch": 0.9229789942711648,
    "step": 1450
  },
  {
    "loss": 1.3946,
    "grad_norm": 2.680553913116455,
    "learning_rate": 0.0006028,
    "epoch": 0.9548058561425843,
    "step": 1500
  },
  {
    "loss": 1.4953,
    "grad_norm": 2.744558572769165,
    "learning_rate": 0.0005828,
    "epoch": 0.9866327180140039,
    "step": 1550
  },
  {
    "loss": 1.3516,
    "grad_norm": 3.1117985248565674,
    "learning_rate": 0.0005628,
    "epoch": 1.0184595798854232,
    "step": 1600
  },
  {
    "loss": 1.2263,
    "grad_norm": 2.5488486289978027,
    "learning_rate": 0.0005428,
    "epoch": 1.0502864417568427,
    "step": 1650
  },
  {
    "loss": 1.2722,
    "grad_norm": 2.255014657974243,
    "learning_rate": 0.0005228,
    "epoch": 1.0821133036282622,
    "step": 1700
  },
  {
    "loss": 1.2345,
    "grad_norm": 2.852388620376587,
    "learning_rate": 0.0005028000000000001,
    "epoch": 1.1139401654996817,
    "step": 1750
  },
  {
    "loss": 1.3047,
    "grad_norm": 2.88610577583313,
    "learning_rate": 0.0004828,
    "epoch": 1.1457670273711011,
    "step": 1800
  },
  {
    "loss": 1.2949,
    "grad_norm": 2.059270143508911,
    "learning_rate": 0.0004628,
    "epoch": 1.1775938892425206,
    "step": 1850
  },
  {
    "loss": 1.3135,
    "grad_norm": 3.2115087509155273,
    "learning_rate": 0.00044280000000000003,
    "epoch": 1.20942075111394,
    "step": 1900
  },
  {
    "loss": 1.3016,
    "grad_norm": 3.4254679679870605,
    "learning_rate": 0.00042280000000000003,
    "epoch": 1.2412476129853596,
    "step": 1950
  },
  {
    "loss": 1.2421,
    "grad_norm": 2.442309856414795,
    "learning_rate": 0.0004028,
    "epoch": 1.273074474856779,
    "step": 2000
  },
  {
    "loss": 1.2703,
    "grad_norm": 2.730861186981201,
    "learning_rate": 0.0003828,
    "epoch": 1.3049013367281985,
    "step": 2050
  },
  {
    "loss": 1.227,
    "grad_norm": 2.518772602081299,
    "learning_rate": 0.00036280000000000004,
    "epoch": 1.336728198599618,
    "step": 2100
  },
  {
    "loss": 1.2472,
    "grad_norm": 1.728708267211914,
    "learning_rate": 0.0003428,
    "epoch": 1.3685550604710375,
    "step": 2150
  },
  {
    "loss": 1.2102,
    "grad_norm": 2.7643253803253174,
    "learning_rate": 0.0003228,
    "epoch": 1.400381922342457,
    "step": 2200
  },
  {
    "loss": 1.2114,
    "grad_norm": 2.1084437370300293,
    "learning_rate": 0.00030280000000000004,
    "epoch": 1.4322087842138764,
    "step": 2250
  },
  {
    "loss": 1.2134,
    "grad_norm": 2.3422770500183105,
    "learning_rate": 0.0002828,
    "epoch": 1.464035646085296,
    "step": 2300
  },
  {
    "loss": 1.2563,
    "grad_norm": 2.244666337966919,
    "learning_rate": 0.0002628,
    "epoch": 1.4958625079567156,
    "step": 2350
  },
  {
    "loss": 1.25,
    "grad_norm": 1.9567025899887085,
    "learning_rate": 0.0002428,
    "epoch": 1.5276893698281349,
    "step": 2400
  },
  {
    "loss": 1.1916,
    "grad_norm": 2.3685991764068604,
    "learning_rate": 0.0002228,
    "epoch": 1.5595162316995546,
    "step": 2450
  },
  {
    "loss": 1.1687,
    "grad_norm": 2.495831251144409,
    "learning_rate": 0.00020280000000000002,
    "epoch": 1.5913430935709738,
    "step": 2500
  },
  {
    "loss": 1.1102,
    "grad_norm": 2.3823184967041016,
    "learning_rate": 0.0001828,
    "epoch": 1.6231699554423935,
    "step": 2550
  },
  {
    "loss": 1.2023,
    "grad_norm": 2.1170284748077393,
    "learning_rate": 0.0001628,
    "epoch": 1.6549968173138128,
    "step": 2600
  },
  {
    "loss": 1.221,
    "grad_norm": 2.0388755798339844,
    "learning_rate": 0.0001428,
    "epoch": 1.6868236791852325,
    "step": 2650
  },
  {
    "loss": 1.1703,
    "grad_norm": 2.7443859577178955,
    "learning_rate": 0.0001228,
    "epoch": 1.7186505410566517,
    "step": 2700
  },
  {
    "loss": 1.16,
    "grad_norm": 2.6219711303710938,
    "learning_rate": 0.0001028,
    "epoch": 1.7504774029280714,
    "step": 2750
  },
  {
    "loss": 1.1417,
    "grad_norm": 2.235085964202881,
    "learning_rate": 8.280000000000001e-05,
    "epoch": 1.7823042647994907,
    "step": 2800
  },
  {
    "loss": 1.1667,
    "grad_norm": 2.0081586837768555,
    "learning_rate": 6.28e-05,
    "epoch": 1.8141311266709104,
    "step": 2850
  },
  {
    "loss": 1.1254,
    "grad_norm": 2.185378074645996,
    "learning_rate": 4.28e-05,
    "epoch": 1.8459579885423296,
    "step": 2900
  },
  {
    "loss": 1.1968,
    "grad_norm": 2.255389451980591,
    "learning_rate": 2.2800000000000002e-05,
    "epoch": 1.8777848504137493,
    "step": 2950
  },
  {
    "loss": 1.1492,
    "grad_norm": 1.9809144735336304,
    "learning_rate": 2.8e-06,
    "epoch": 1.9096117122851686,
    "step": 3000
  },
  {
    "train_runtime": 9066.621,
    "train_samples_per_second": 2.647,
    "train_steps_per_second": 0.331,
    "total_flos": 7.04718078640128e+18,
    "train_loss": 1.7303465868632,
    "epoch": 1.9096117122851686,
    "step": 3000
  }
]