[
  {
    "loss": 4.0686,
    "grad_norm": 1.5943409204483032,
    "learning_rate": 9.6e-05,
    "epoch": 0.031826861871419476,
    "step": 50
  },
  {
    "loss": 2.3555,
    "grad_norm": 1.8983619213104248,
    "learning_rate": 0.00019600000000000002,
    "epoch": 0.06365372374283895,
    "step": 100
  },
  {
    "loss": 1.879,
    "grad_norm": 1.7474476099014282,
    "learning_rate": 0.000296,
    "epoch": 0.09548058561425843,
    "step": 150
  },
  {
    "loss": 1.6018,
    "grad_norm": 1.6382814645767212,
    "learning_rate": 0.00039600000000000003,
    "epoch": 0.1273074474856779,
    "step": 200
  },
  {
    "loss": 1.6165,
    "grad_norm": 2.525465488433838,
    "learning_rate": 0.000496,
    "epoch": 0.15913430935709738,
    "step": 250
  },
  {
    "loss": 1.5403,
    "grad_norm": 2.1450462341308594,
    "learning_rate": 0.000596,
    "epoch": 0.19096117122851686,
    "step": 300
  },
  {
    "loss": 1.5407,
    "grad_norm": 2.6311590671539307,
    "learning_rate": 0.000696,
    "epoch": 0.22278803309993633,
    "step": 350
  },
  {
    "loss": 1.5796,
    "grad_norm": 2.304661273956299,
    "learning_rate": 0.000796,
    "epoch": 0.2546148949713558,
    "step": 400
  },
  {
    "loss": 1.5757,
    "grad_norm": 2.0329365730285645,
    "learning_rate": 0.000894,
    "epoch": 0.2864417568427753,
    "step": 450
  },
  {
    "loss": 1.6437,
    "grad_norm": 3.121371030807495,
    "learning_rate": 0.000994,
    "epoch": 0.31826861871419476,
    "step": 500
  },
  {
    "loss": 1.5997,
    "grad_norm": 2.762888193130493,
    "learning_rate": 0.0009812,
    "epoch": 0.35009548058561424,
    "step": 550
  },
  {
    "loss": 1.6681,
    "grad_norm": 2.437708616256714,
    "learning_rate": 0.0009612,
    "epoch": 0.3819223424570337,
    "step": 600
  },
  {
    "loss": 1.555,
    "grad_norm": 2.715770959854126,
    "learning_rate": 0.0009412000000000001,
    "epoch": 0.4137492043284532,
    "step": 650
  },
  {
    "loss": 1.5714,
    "grad_norm": 2.631337881088257,
    "learning_rate": 0.0009212000000000001,
    "epoch": 0.44557606619987267,
    "step": 700
  },
  {
    "loss": 1.649,
    "grad_norm": 3.9023361206054688,
    "learning_rate": 0.0009012,
    "epoch": 0.47740292807129214,
    "step": 750
  },
  {
    "loss": 1.5848,
    "grad_norm": 2.6285359859466553,
    "learning_rate": 0.0008812,
    "epoch": 0.5092297899427116,
    "step": 800
  },
  {
    "loss": 1.5154,
    "grad_norm": 3.590073585510254,
    "learning_rate": 0.0008612,
    "epoch": 0.5410566518141311,
    "step": 850
  },
  {
    "loss": 1.5554,
    "grad_norm": 3.246530532836914,
    "learning_rate": 0.0008412,
    "epoch": 0.5728835136855506,
    "step": 900
  },
  {
    "loss": 1.5448,
    "grad_norm": 2.690692186355591,
    "learning_rate": 0.0008212,
    "epoch": 0.60471037555697,
    "step": 950
  },
  {
    "loss": 1.6429,
    "grad_norm": 2.8881607055664062,
    "learning_rate": 0.0008012000000000001,
    "epoch": 0.6365372374283895,
    "step": 1000
  },
  {
    "loss": 1.4491,
    "grad_norm": 2.2572617530822754,
    "learning_rate": 0.0007812,
    "epoch": 0.668364099299809,
    "step": 1050
  },
  {
    "loss": 1.5183,
    "grad_norm": 3.6326534748077393,
    "learning_rate": 0.0007612,
    "epoch": 0.7001909611712285,
    "step": 1100
  },
  {
    "loss": 1.5524,
    "grad_norm": 2.3707926273345947,
    "learning_rate": 0.0007412,
    "epoch": 0.732017823042648,
    "step": 1150
  },
  {
    "loss": 1.5727,
    "grad_norm": 2.4133715629577637,
    "learning_rate": 0.0007212,
    "epoch": 0.7638446849140674,
    "step": 1200
  },
  {
    "loss": 1.5545,
    "grad_norm": 3.0379152297973633,
    "learning_rate": 0.0007012,
    "epoch": 0.7956715467854869,
    "step": 1250
  },
  {
    "loss": 1.5221,
    "grad_norm": 1.9120861291885376,
    "learning_rate": 0.0006812000000000001,
    "epoch": 0.8274984086569064,
    "step": 1300
  },
  {
    "loss": 1.5095,
    "grad_norm": 3.481346368789673,
    "learning_rate": 0.0006612,
    "epoch": 0.8593252705283259,
    "step": 1350
  },
  {
    "loss": 1.3945,
    "grad_norm": 3.1546502113342285,
    "learning_rate": 0.0006412,
    "epoch": 0.8911521323997453,
    "step": 1400
  },
  {
    "loss": 5.3018,
    "grad_norm": 39.22539520263672,
    "learning_rate": 0.0006216,
    "epoch": 0.9229789942711648,
    "step": 1450
  },
  {
    "loss": 4.8649,
    "grad_norm": 0.7041285634040833,
    "learning_rate": 0.0006016,
    "epoch": 0.9548058561425843,
    "step": 1500
  },
  {
    "loss": 3.0748,
    "grad_norm": 3.460646867752075,
    "learning_rate": 0.0005816,
    "epoch": 0.9866327180140039,
    "step": 1550
  },
  {
    "loss": 1.4528,
    "grad_norm": 3.5177109241485596,
    "learning_rate": 0.0005616,
    "epoch": 1.0184595798854232,
    "step": 1600
  },
  {
    "loss": 1.2574,
    "grad_norm": 2.245285987854004,
    "learning_rate": 0.0005415999999999999,
    "epoch": 1.0502864417568427,
    "step": 1650
  },
  {
    "loss": 1.3221,
    "grad_norm": 5.088410377502441,
    "learning_rate": 0.0005216,
    "epoch": 1.0821133036282622,
    "step": 1700
  },
  {
    "loss": 1.2959,
    "grad_norm": 3.041205406188965,
    "learning_rate": 0.0005016,
    "epoch": 1.1139401654996817,
    "step": 1750
  },
  {
    "loss": 1.3446,
    "grad_norm": 2.8244664669036865,
    "learning_rate": 0.0004816,
    "epoch": 1.1457670273711011,
    "step": 1800
  },
  {
    "loss": 1.226,
    "grad_norm": 2.8642232418060303,
    "learning_rate": 0.0004616,
    "epoch": 1.1775938892425206,
    "step": 1850
  },
  {
    "loss": 1.2448,
    "grad_norm": 2.4229557514190674,
    "learning_rate": 0.0004416,
    "epoch": 1.20942075111394,
    "step": 1900
  },
  {
    "loss": 1.2737,
    "grad_norm": 2.926873207092285,
    "learning_rate": 0.0004216,
    "epoch": 1.2412476129853596,
    "step": 1950
  },
  {
    "loss": 1.3161,
    "grad_norm": 1.5307776927947998,
    "learning_rate": 0.0004016,
    "epoch": 1.273074474856779,
    "step": 2000
  },
  {
    "loss": 1.1797,
    "grad_norm": 1.9720842838287354,
    "learning_rate": 0.0003816,
    "epoch": 1.3049013367281985,
    "step": 2050
  },
  {
    "loss": 1.2303,
    "grad_norm": 2.4398508071899414,
    "learning_rate": 0.0003616,
    "epoch": 1.336728198599618,
    "step": 2100
  },
  {
    "loss": 1.1733,
    "grad_norm": 2.330728769302368,
    "learning_rate": 0.0003416,
    "epoch": 1.3685550604710375,
    "step": 2150
  },
  {
    "loss": 1.2505,
    "grad_norm": 2.802446126937866,
    "learning_rate": 0.0003216,
    "epoch": 1.400381922342457,
    "step": 2200
  },
  {
    "loss": 1.225,
    "grad_norm": 3.6211862564086914,
    "learning_rate": 0.00030159999999999996,
    "epoch": 1.4322087842138764,
    "step": 2250
  },
  {
    "loss": 1.1947,
    "grad_norm": 2.3566789627075195,
    "learning_rate": 0.0002816,
    "epoch": 1.464035646085296,
    "step": 2300
  },
  {
    "loss": 1.2407,
    "grad_norm": 2.642136812210083,
    "learning_rate": 0.0002616,
    "epoch": 1.4958625079567156,
    "step": 2350
  },
  {
    "loss": 1.2078,
    "grad_norm": 2.2058393955230713,
    "learning_rate": 0.00024160000000000002,
    "epoch": 1.5276893698281349,
    "step": 2400
  },
  {
    "loss": 1.2432,
    "grad_norm": 2.890641450881958,
    "learning_rate": 0.0002216,
    "epoch": 1.5595162316995546,
    "step": 2450
  },
  {
    "loss": 1.1927,
    "grad_norm": 2.2902164459228516,
    "learning_rate": 0.0002016,
    "epoch": 1.5913430935709738,
    "step": 2500
  },
  {
    "loss": 1.1704,
    "grad_norm": 2.3153934478759766,
    "learning_rate": 0.00018160000000000002,
    "epoch": 1.6231699554423935,
    "step": 2550
  },
  {
    "loss": 1.1752,
    "grad_norm": 2.0786962509155273,
    "learning_rate": 0.0001616,
    "epoch": 1.6549968173138128,
    "step": 2600
  },
  {
    "loss": 1.1462,
    "grad_norm": 2.6432864665985107,
    "learning_rate": 0.0001416,
    "epoch": 1.6868236791852325,
    "step": 2650
  },
  {
    "loss": 1.1826,
    "grad_norm": 2.255906105041504,
    "learning_rate": 0.0001216,
    "epoch": 1.7186505410566517,
    "step": 2700
  },
  {
    "loss": 1.1846,
    "grad_norm": 2.3653860092163086,
    "learning_rate": 0.0001016,
    "epoch": 1.7504774029280714,
    "step": 2750
  },
  {
    "loss": 1.1934,
    "grad_norm": 2.49794340133667,
    "learning_rate": 8.16e-05,
    "epoch": 1.7823042647994907,
    "step": 2800
  },
  {
    "loss": 1.1396,
    "grad_norm": 2.987905979156494,
    "learning_rate": 6.16e-05,
    "epoch": 1.8141311266709104,
    "step": 2850
  },
  {
    "loss": 1.1093,
    "grad_norm": 2.5035226345062256,
    "learning_rate": 4.16e-05,
    "epoch": 1.8459579885423296,
    "step": 2900
  },
  {
    "loss": 1.0832,
    "grad_norm": 1.689342737197876,
    "learning_rate": 2.1600000000000003e-05,
    "epoch": 1.8777848504137493,
    "step": 2950
  },
  {
    "loss": 1.1306,
    "grad_norm": 2.227712869644165,
    "learning_rate": 1.6000000000000001e-06,
    "epoch": 1.9096117122851686,
    "step": 3000
  },
  {
    "train_runtime": 9579.4796,
    "train_samples_per_second": 2.505,
    "train_steps_per_second": 0.313,
    "total_flos": 7.04718078640128e+18,
    "train_loss": 1.5998167775472005,
    "epoch": 1.9096117122851686,
    "step": 3000
  }
]