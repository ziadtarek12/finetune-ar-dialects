[
  {
    "loss": 4.1635,
    "grad_norm": 2.1314120292663574,
    "learning_rate": 9.6e-05,
    "epoch": 0.031826861871419476,
    "step": 50
  },
  {
    "loss": 2.3887,
    "grad_norm": 2.2104458808898926,
    "learning_rate": 0.00019600000000000002,
    "epoch": 0.06365372374283895,
    "step": 100
  },
  {
    "loss": 1.8634,
    "grad_norm": 2.7171144485473633,
    "learning_rate": 0.000296,
    "epoch": 0.09548058561425843,
    "step": 150
  },
  {
    "loss": 1.6568,
    "grad_norm": 2.5432987213134766,
    "learning_rate": 0.00039600000000000003,
    "epoch": 0.1273074474856779,
    "step": 200
  },
  {
    "loss": 1.529,
    "grad_norm": 1.5901707410812378,
    "learning_rate": 0.000496,
    "epoch": 0.15913430935709738,
    "step": 250
  },
  {
    "loss": 1.5246,
    "grad_norm": 2.1382341384887695,
    "learning_rate": 0.000596,
    "epoch": 0.19096117122851686,
    "step": 300
  },
  {
    "loss": 1.571,
    "grad_norm": 1.971246600151062,
    "learning_rate": 0.000696,
    "epoch": 0.22278803309993633,
    "step": 350
  },
  {
    "loss": 1.6077,
    "grad_norm": 2.0374183654785156,
    "learning_rate": 0.000796,
    "epoch": 0.2546148949713558,
    "step": 400
  },
  {
    "loss": 1.561,
    "grad_norm": 2.612983465194702,
    "learning_rate": 0.000896,
    "epoch": 0.2864417568427753,
    "step": 450
  },
  {
    "loss": 1.5952,
    "grad_norm": 3.7339484691619873,
    "learning_rate": 0.000996,
    "epoch": 0.31826861871419476,
    "step": 500
  },
  {
    "loss": 1.6121,
    "grad_norm": 4.2569966316223145,
    "learning_rate": 0.0009808,
    "epoch": 0.35009548058561424,
    "step": 550
  },
  {
    "loss": 1.6629,
    "grad_norm": 2.637874126434326,
    "learning_rate": 0.0009608,
    "epoch": 0.3819223424570337,
    "step": 600
  },
  {
    "loss": 1.5679,
    "grad_norm": 3.0513370037078857,
    "learning_rate": 0.0009408,
    "epoch": 0.4137492043284532,
    "step": 650
  },
  {
    "loss": 1.5962,
    "grad_norm": 2.9296295642852783,
    "learning_rate": 0.0009207999999999999,
    "epoch": 0.44557606619987267,
    "step": 700
  },
  {
    "loss": 1.7182,
    "grad_norm": 3.753538131713867,
    "learning_rate": 0.0009008000000000001,
    "epoch": 0.47740292807129214,
    "step": 750
  },
  {
    "loss": 1.5845,
    "grad_norm": 3.3028619289398193,
    "learning_rate": 0.0008808,
    "epoch": 0.5092297899427116,
    "step": 800
  },
  {
    "loss": 1.5475,
    "grad_norm": 2.776803970336914,
    "learning_rate": 0.0008608,
    "epoch": 0.5410566518141311,
    "step": 850
  },
  {
    "loss": 1.5769,
    "grad_norm": 2.326761245727539,
    "learning_rate": 0.0008408000000000001,
    "epoch": 0.5728835136855506,
    "step": 900
  },
  {
    "loss": 1.5131,
    "grad_norm": 3.3681960105895996,
    "learning_rate": 0.0008208,
    "epoch": 0.60471037555697,
    "step": 950
  },
  {
    "loss": 1.5417,
    "grad_norm": 3.245661735534668,
    "learning_rate": 0.0008008,
    "epoch": 0.6365372374283895,
    "step": 1000
  },
  {
    "loss": 1.5207,
    "grad_norm": 2.9009368419647217,
    "learning_rate": 0.0007808000000000001,
    "epoch": 0.668364099299809,
    "step": 1050
  },
  {
    "loss": 1.5935,
    "grad_norm": 2.3682360649108887,
    "learning_rate": 0.0007608000000000001,
    "epoch": 0.7001909611712285,
    "step": 1100
  },
  {
    "loss": 1.483,
    "grad_norm": 2.3727688789367676,
    "learning_rate": 0.0007408,
    "epoch": 0.732017823042648,
    "step": 1150
  },
  {
    "loss": 1.5794,
    "grad_norm": 3.7016117572784424,
    "learning_rate": 0.0007208000000000001,
    "epoch": 0.7638446849140674,
    "step": 1200
  },
  {
    "loss": 1.4691,
    "grad_norm": 3.4132578372955322,
    "learning_rate": 0.0007008,
    "epoch": 0.7956715467854869,
    "step": 1250
  },
  {
    "loss": 1.4524,
    "grad_norm": 3.98140811920166,
    "learning_rate": 0.0006808,
    "epoch": 0.8274984086569064,
    "step": 1300
  },
  {
    "loss": 1.492,
    "grad_norm": 2.815234661102295,
    "learning_rate": 0.0006608,
    "epoch": 0.8593252705283259,
    "step": 1350
  },
  {
    "loss": 1.4859,
    "grad_norm": 2.7509355545043945,
    "learning_rate": 0.0006408000000000001,
    "epoch": 0.8911521323997453,
    "step": 1400
  },
  {
    "loss": 1.4465,
    "grad_norm": 3.2786805629730225,
    "learning_rate": 0.0006208,
    "epoch": 0.9229789942711648,
    "step": 1450
  },
  {
    "loss": 1.4921,
    "grad_norm": 2.5798227787017822,
    "learning_rate": 0.0006008,
    "epoch": 0.9548058561425843,
    "step": 1500
  },
  {
    "loss": 1.4365,
    "grad_norm": 2.7732090950012207,
    "learning_rate": 0.0005808,
    "epoch": 0.9866327180140039,
    "step": 1550
  },
  {
    "loss": 1.2678,
    "grad_norm": 2.4757931232452393,
    "learning_rate": 0.0005608,
    "epoch": 1.0184595798854232,
    "step": 1600
  },
  {
    "loss": 1.2504,
    "grad_norm": 2.7129034996032715,
    "learning_rate": 0.0005407999999999999,
    "epoch": 1.0502864417568427,
    "step": 1650
  },
  {
    "loss": 1.1629,
    "grad_norm": 2.926011323928833,
    "learning_rate": 0.0005208000000000001,
    "epoch": 1.0821133036282622,
    "step": 1700
  },
  {
    "loss": 1.2133,
    "grad_norm": 4.0995097160339355,
    "learning_rate": 0.0005008,
    "epoch": 1.1139401654996817,
    "step": 1750
  },
  {
    "loss": 1.2818,
    "grad_norm": 2.013693332672119,
    "learning_rate": 0.00048080000000000003,
    "epoch": 1.1457670273711011,
    "step": 1800
  },
  {
    "loss": 1.2464,
    "grad_norm": 2.7158055305480957,
    "learning_rate": 0.0004608,
    "epoch": 1.1775938892425206,
    "step": 1850
  },
  {
    "loss": 1.2616,
    "grad_norm": 3.693862199783325,
    "learning_rate": 0.00044080000000000004,
    "epoch": 1.20942075111394,
    "step": 1900
  },
  {
    "loss": 1.2765,
    "grad_norm": 2.356374740600586,
    "learning_rate": 0.00042080000000000004,
    "epoch": 1.2412476129853596,
    "step": 1950
  },
  {
    "loss": 1.2376,
    "grad_norm": 2.6313462257385254,
    "learning_rate": 0.0004008,
    "epoch": 1.273074474856779,
    "step": 2000
  },
  {
    "loss": 1.2225,
    "grad_norm": 2.080808401107788,
    "learning_rate": 0.00038080000000000004,
    "epoch": 1.3049013367281985,
    "step": 2050
  },
  {
    "loss": 1.2451,
    "grad_norm": 2.2544105052948,
    "learning_rate": 0.00036080000000000004,
    "epoch": 1.336728198599618,
    "step": 2100
  },
  {
    "loss": 1.1693,
    "grad_norm": 1.867034912109375,
    "learning_rate": 0.0003408,
    "epoch": 1.3685550604710375,
    "step": 2150
  },
  {
    "loss": 1.259,
    "grad_norm": 2.142573833465576,
    "learning_rate": 0.0003208,
    "epoch": 1.400381922342457,
    "step": 2200
  },
  {
    "loss": 1.2942,
    "grad_norm": 2.3438379764556885,
    "learning_rate": 0.0003008,
    "epoch": 1.4322087842138764,
    "step": 2250
  },
  {
    "loss": 1.2523,
    "grad_norm": 2.25262451171875,
    "learning_rate": 0.0002808,
    "epoch": 1.464035646085296,
    "step": 2300
  },
  {
    "loss": 1.0884,
    "grad_norm": 2.621497392654419,
    "learning_rate": 0.0002608,
    "epoch": 1.4958625079567156,
    "step": 2350
  },
  {
    "loss": 1.0734,
    "grad_norm": 2.7863409519195557,
    "learning_rate": 0.0002408,
    "epoch": 1.5276893698281349,
    "step": 2400
  },
  {
    "loss": 1.2098,
    "grad_norm": 2.151627540588379,
    "learning_rate": 0.0002208,
    "epoch": 1.5595162316995546,
    "step": 2450
  },
  {
    "loss": 1.1713,
    "grad_norm": 2.7271697521209717,
    "learning_rate": 0.0002008,
    "epoch": 1.5913430935709738,
    "step": 2500
  },
  {
    "loss": 1.1334,
    "grad_norm": 2.1881039142608643,
    "learning_rate": 0.0001808,
    "epoch": 1.6231699554423935,
    "step": 2550
  },
  {
    "loss": 1.1027,
    "grad_norm": 2.943446159362793,
    "learning_rate": 0.0001608,
    "epoch": 1.6549968173138128,
    "step": 2600
  },
  {
    "loss": 1.1648,
    "grad_norm": 3.2713587284088135,
    "learning_rate": 0.0001408,
    "epoch": 1.6868236791852325,
    "step": 2650
  },
  {
    "loss": 1.0987,
    "grad_norm": 3.179935932159424,
    "learning_rate": 0.00012080000000000001,
    "epoch": 1.7186505410566517,
    "step": 2700
  },
  {
    "loss": 1.1177,
    "grad_norm": 2.3489503860473633,
    "learning_rate": 0.0001008,
    "epoch": 1.7504774029280714,
    "step": 2750
  },
  {
    "loss": 1.1072,
    "grad_norm": 2.5022623538970947,
    "learning_rate": 8.08e-05,
    "epoch": 1.7823042647994907,
    "step": 2800
  },
  {
    "loss": 1.0859,
    "grad_norm": 1.858527660369873,
    "learning_rate": 6.08e-05,
    "epoch": 1.8141311266709104,
    "step": 2850
  },
  {
    "loss": 1.0899,
    "grad_norm": 2.5263335704803467,
    "learning_rate": 4.08e-05,
    "epoch": 1.8459579885423296,
    "step": 2900
  },
  {
    "loss": 1.1628,
    "grad_norm": 2.317502498626709,
    "learning_rate": 2.08e-05,
    "epoch": 1.8777848504137493,
    "step": 2950
  },
  {
    "loss": 1.1478,
    "grad_norm": 2.1811888217926025,
    "learning_rate": 8.000000000000001e-07,
    "epoch": 1.9096117122851686,
    "step": 3000
  },
  {
    "train_runtime": 9402.6891,
    "train_samples_per_second": 2.552,
    "train_steps_per_second": 0.319,
    "total_flos": 7.04718078640128e+18,
    "train_loss": 1.4371312052408853,
    "epoch": 1.9096117122851686,
    "step": 3000
  }
]