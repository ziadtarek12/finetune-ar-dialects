[
  {
    "loss": 4.0405,
    "grad_norm": 1.5820187330245972,
    "learning_rate": 9.800000000000001e-05,
    "epoch": 0.031826861871419476,
    "step": 50
  },
  {
    "loss": 2.3521,
    "grad_norm": 1.904404640197754,
    "learning_rate": 0.00019800000000000002,
    "epoch": 0.06365372374283895,
    "step": 100
  },
  {
    "loss": 1.8739,
    "grad_norm": 1.8472228050231934,
    "learning_rate": 0.000298,
    "epoch": 0.09548058561425843,
    "step": 150
  },
  {
    "loss": 1.6028,
    "grad_norm": 1.809281349182129,
    "learning_rate": 0.000398,
    "epoch": 0.1273074474856779,
    "step": 200
  },
  {
    "loss": 1.6139,
    "grad_norm": 2.4066054821014404,
    "learning_rate": 0.000498,
    "epoch": 0.15913430935709738,
    "step": 250
  },
  {
    "loss": 1.5428,
    "grad_norm": 1.9138623476028442,
    "learning_rate": 0.000598,
    "epoch": 0.19096117122851686,
    "step": 300
  },
  {
    "loss": 1.5447,
    "grad_norm": 2.823643684387207,
    "learning_rate": 0.0006979999999999999,
    "epoch": 0.22278803309993633,
    "step": 350
  },
  {
    "loss": 1.5841,
    "grad_norm": 2.5078649520874023,
    "learning_rate": 0.0007980000000000001,
    "epoch": 0.2546148949713558,
    "step": 400
  },
  {
    "loss": 1.5721,
    "grad_norm": 2.4785566329956055,
    "learning_rate": 0.000898,
    "epoch": 0.2864417568427753,
    "step": 450
  },
  {
    "loss": 1.6398,
    "grad_norm": 2.998387575149536,
    "learning_rate": 0.000998,
    "epoch": 0.31826861871419476,
    "step": 500
  },
  {
    "loss": 1.6314,
    "grad_norm": 3.1361827850341797,
    "learning_rate": 0.0009804,
    "epoch": 0.35009548058561424,
    "step": 550
  },
  {
    "loss": 1.6639,
    "grad_norm": 2.2821602821350098,
    "learning_rate": 0.0009604,
    "epoch": 0.3819223424570337,
    "step": 600
  },
  {
    "loss": 1.5433,
    "grad_norm": 2.718041181564331,
    "learning_rate": 0.0009404,
    "epoch": 0.4137492043284532,
    "step": 650
  },
  {
    "loss": 1.5891,
    "grad_norm": 3.1967644691467285,
    "learning_rate": 0.0009204,
    "epoch": 0.44557606619987267,
    "step": 700
  },
  {
    "loss": 1.6677,
    "grad_norm": 3.449985980987549,
    "learning_rate": 0.0009004,
    "epoch": 0.47740292807129214,
    "step": 750
  },
  {
    "loss": 1.611,
    "grad_norm": 2.5075254440307617,
    "learning_rate": 0.0008803999999999999,
    "epoch": 0.5092297899427116,
    "step": 800
  },
  {
    "loss": 1.5138,
    "grad_norm": 2.6311752796173096,
    "learning_rate": 0.0008604000000000001,
    "epoch": 0.5410566518141311,
    "step": 850
  },
  {
    "loss": 1.5476,
    "grad_norm": 3.1396870613098145,
    "learning_rate": 0.0008404,
    "epoch": 0.5728835136855506,
    "step": 900
  },
  {
    "loss": 1.5499,
    "grad_norm": 3.062411308288574,
    "learning_rate": 0.0008204,
    "epoch": 0.60471037555697,
    "step": 950
  },
  {
    "loss": 1.6419,
    "grad_norm": 2.5829408168792725,
    "learning_rate": 0.0008004,
    "epoch": 0.6365372374283895,
    "step": 1000
  },
  {
    "loss": 1.4325,
    "grad_norm": 2.355818510055542,
    "learning_rate": 0.0007804,
    "epoch": 0.668364099299809,
    "step": 1050
  },
  {
    "loss": 1.5251,
    "grad_norm": 3.6431100368499756,
    "learning_rate": 0.0007603999999999999,
    "epoch": 0.7001909611712285,
    "step": 1100
  },
  {
    "loss": 1.557,
    "grad_norm": 2.214449167251587,
    "learning_rate": 0.0007404,
    "epoch": 0.732017823042648,
    "step": 1150
  },
  {
    "loss": 1.5707,
    "grad_norm": 2.176091432571411,
    "learning_rate": 0.0007204000000000001,
    "epoch": 0.7638446849140674,
    "step": 1200
  },
  {
    "loss": 1.554,
    "grad_norm": 3.3383936882019043,
    "learning_rate": 0.0007004,
    "epoch": 0.7956715467854869,
    "step": 1250
  },
  {
    "loss": 1.5212,
    "grad_norm": 2.1603446006774902,
    "learning_rate": 0.0006804000000000001,
    "epoch": 0.8274984086569064,
    "step": 1300
  },
  {
    "loss": 1.5099,
    "grad_norm": 2.8484110832214355,
    "learning_rate": 0.0006604,
    "epoch": 0.8593252705283259,
    "step": 1350
  },
  {
    "loss": 1.4208,
    "grad_norm": 3.695148468017578,
    "learning_rate": 0.0006408000000000001,
    "epoch": 0.8911521323997453,
    "step": 1400
  },
  {
    "loss": 1.4866,
    "grad_norm": 2.3245561122894287,
    "learning_rate": 0.0006208,
    "epoch": 0.9229789942711648,
    "step": 1450
  },
  {
    "loss": 1.4767,
    "grad_norm": 2.7197930812835693,
    "learning_rate": 0.0006008,
    "epoch": 0.9548058561425843,
    "step": 1500
  },
  {
    "loss": 1.4354,
    "grad_norm": 3.850795269012451,
    "learning_rate": 0.0005808,
    "epoch": 0.9866327180140039,
    "step": 1550
  },
  {
    "loss": 1.3696,
    "grad_norm": 3.3986454010009766,
    "learning_rate": 0.0005608,
    "epoch": 1.0184595798854232,
    "step": 1600
  },
  {
    "loss": 1.1955,
    "grad_norm": 2.23772931098938,
    "learning_rate": 0.0005407999999999999,
    "epoch": 1.0502864417568427,
    "step": 1650
  },
  {
    "loss": 1.2577,
    "grad_norm": 3.4250988960266113,
    "learning_rate": 0.0005208000000000001,
    "epoch": 1.0821133036282622,
    "step": 1700
  },
  {
    "loss": 1.2379,
    "grad_norm": 2.735074281692505,
    "learning_rate": 0.0005008,
    "epoch": 1.1139401654996817,
    "step": 1750
  },
  {
    "loss": 1.2876,
    "grad_norm": 2.4683825969696045,
    "learning_rate": 0.00048080000000000003,
    "epoch": 1.1457670273711011,
    "step": 1800
  },
  {
    "loss": 1.1902,
    "grad_norm": 3.1274940967559814,
    "learning_rate": 0.0004608,
    "epoch": 1.1775938892425206,
    "step": 1850
  },
  {
    "loss": 1.2191,
    "grad_norm": 2.1979575157165527,
    "learning_rate": 0.00044080000000000004,
    "epoch": 1.20942075111394,
    "step": 1900
  },
  {
    "loss": 1.2457,
    "grad_norm": 2.2832889556884766,
    "learning_rate": 0.00042080000000000004,
    "epoch": 1.2412476129853596,
    "step": 1950
  },
  {
    "loss": 1.2738,
    "grad_norm": 1.5621610879898071,
    "learning_rate": 0.0004008,
    "epoch": 1.273074474856779,
    "step": 2000
  },
  {
    "loss": 1.1585,
    "grad_norm": 2.4688303470611572,
    "learning_rate": 0.00038080000000000004,
    "epoch": 1.3049013367281985,
    "step": 2050
  },
  {
    "loss": 1.1947,
    "grad_norm": 2.019928455352783,
    "learning_rate": 0.00036080000000000004,
    "epoch": 1.336728198599618,
    "step": 2100
  },
  {
    "loss": 1.138,
    "grad_norm": 2.3717539310455322,
    "learning_rate": 0.0003408,
    "epoch": 1.3685550604710375,
    "step": 2150
  },
  {
    "loss": 1.2248,
    "grad_norm": 2.498134136199951,
    "learning_rate": 0.0003208,
    "epoch": 1.400381922342457,
    "step": 2200
  },
  {
    "loss": 1.2028,
    "grad_norm": 2.9699833393096924,
    "learning_rate": 0.0003008,
    "epoch": 1.4322087842138764,
    "step": 2250
  },
  {
    "loss": 1.1785,
    "grad_norm": 2.4898431301116943,
    "learning_rate": 0.0002808,
    "epoch": 1.464035646085296,
    "step": 2300
  },
  {
    "loss": 1.2214,
    "grad_norm": 2.557583808898926,
    "learning_rate": 0.0002608,
    "epoch": 1.4958625079567156,
    "step": 2350
  },
  {
    "loss": 1.1899,
    "grad_norm": 2.7180800437927246,
    "learning_rate": 0.0002408,
    "epoch": 1.5276893698281349,
    "step": 2400
  },
  {
    "loss": 1.2217,
    "grad_norm": 2.729390859603882,
    "learning_rate": 0.0002208,
    "epoch": 1.5595162316995546,
    "step": 2450
  },
  {
    "loss": 1.1806,
    "grad_norm": 2.1300339698791504,
    "learning_rate": 0.0002008,
    "epoch": 1.5913430935709738,
    "step": 2500
  },
  {
    "loss": 1.1382,
    "grad_norm": 2.4626710414886475,
    "learning_rate": 0.0001808,
    "epoch": 1.6231699554423935,
    "step": 2550
  },
  {
    "loss": 1.1421,
    "grad_norm": 2.0568435192108154,
    "learning_rate": 0.0001608,
    "epoch": 1.6549968173138128,
    "step": 2600
  },
  {
    "loss": 1.1294,
    "grad_norm": 3.0310728549957275,
    "learning_rate": 0.0001408,
    "epoch": 1.6868236791852325,
    "step": 2650
  },
  {
    "loss": 1.15,
    "grad_norm": 2.2642452716827393,
    "learning_rate": 0.00012080000000000001,
    "epoch": 1.7186505410566517,
    "step": 2700
  },
  {
    "loss": 1.1563,
    "grad_norm": 2.4885339736938477,
    "learning_rate": 0.0001008,
    "epoch": 1.7504774029280714,
    "step": 2750
  },
  {
    "loss": 1.1649,
    "grad_norm": 2.4267561435699463,
    "learning_rate": 8.08e-05,
    "epoch": 1.7823042647994907,
    "step": 2800
  },
  {
    "loss": 1.1348,
    "grad_norm": 3.13053560256958,
    "learning_rate": 6.08e-05,
    "epoch": 1.8141311266709104,
    "step": 2850
  },
  {
    "loss": 1.0848,
    "grad_norm": 1.8459481000900269,
    "learning_rate": 4.08e-05,
    "epoch": 1.8459579885423296,
    "step": 2900
  },
  {
    "loss": 1.0636,
    "grad_norm": 1.43915855884552,
    "learning_rate": 2.08e-05,
    "epoch": 1.8777848504137493,
    "step": 2950
  },
  {
    "loss": 1.1002,
    "grad_norm": 2.191082239151001,
    "learning_rate": 8.000000000000001e-07,
    "epoch": 1.9096117122851686,
    "step": 3000
  },
  {
    "train_runtime": 9617.4797,
    "train_samples_per_second": 2.495,
    "train_steps_per_second": 0.312,
    "total_flos": 7.04718078640128e+18,
    "train_loss": 1.437813138326009,
    "epoch": 1.9096117122851686,
    "step": 3000
  }
]